{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "25e4a38c465543b98ec3da10e967bb44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9cda96459344c13ad46148cc659a7d7",
              "IPY_MODEL_31f24a09cc2e41209e9c19324c4d3456",
              "IPY_MODEL_a016028a85e44cadae95d8649a26f7a9"
            ],
            "layout": "IPY_MODEL_967d1d10d467423498d0e275b9450644"
          }
        },
        "e9cda96459344c13ad46148cc659a7d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe66eb2ea1194ca8be601fd15d02146a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_839181f37aba4502b412b3fa5019a85b",
            "value": "Batches:‚Äá100%"
          }
        },
        "31f24a09cc2e41209e9c19324c4d3456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32bcb9c9c17f49a181c1d2e9895b5b3a",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4756b96585c54217b4cd62934396f508",
            "value": 10
          }
        },
        "a016028a85e44cadae95d8649a26f7a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_29ac9d00ea8c45e8856ce8f857455c41",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_92289c9d17524bb095364e5dfc7efb61",
            "value": "‚Äá10/10‚Äá[00:01&lt;00:00,‚Äá10.02it/s]"
          }
        },
        "967d1d10d467423498d0e275b9450644": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe66eb2ea1194ca8be601fd15d02146a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "839181f37aba4502b412b3fa5019a85b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "32bcb9c9c17f49a181c1d2e9895b5b3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4756b96585c54217b4cd62934396f508": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "29ac9d00ea8c45e8856ce8f857455c41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92289c9d17524bb095364e5dfc7efb61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Using Push Bullet"
      ],
      "metadata": {
        "id": "WTqUEZzUqzei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pushbullet.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izHDDF0j1rOd",
        "outputId": "132fdaa1-a48d-4a5c-c37b-4f0c40775361",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pushbullet.py\n",
            "  Downloading pushbullet.py-0.12.0-py2.py3-none-any.whl.metadata (945 bytes)\n",
            "Requirement already satisfied: requests>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from pushbullet.py) (2.32.4)\n",
            "Collecting python-magic (from pushbullet.py)\n",
            "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: websocket-client>=0.53.0 in /usr/local/lib/python3.12/dist-packages (from pushbullet.py) (1.9.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=1.0.0->pushbullet.py) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=1.0.0->pushbullet.py) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=1.0.0->pushbullet.py) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=1.0.0->pushbullet.py) (2025.11.12)\n",
            "Downloading pushbullet.py-0.12.0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
            "Installing collected packages: python-magic, pushbullet.py\n",
            "Successfully installed pushbullet.py-0.12.0 python-magic-0.4.27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJpnh5L31ESo"
      },
      "outputs": [],
      "source": [
        "# Standard Python Libaries\n",
        "import urllib.request\n",
        "import os\n",
        "\n",
        "# Third Party Modules\n",
        "import pandas as pd # pip install pandas openpyxl\n",
        "from pushbullet import Pushbullet # pip install pushbullet.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# API KEY PushBullet (https://www.pushbullet.com/)\n",
        "API_KEY = \"o.RaRj7wULMgVpGA43wzcnwLgb4m8t5uwd\""
      ],
      "metadata": {
        "id": "vvwkzlOO1x_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://pypi.org/project/pushbullet.py/0.9.1/\n",
        "pb = Pushbullet(API_KEY)\n",
        "\n",
        "# List of pushed file\n",
        "pushes = pb.get_pushes()\n",
        "\n",
        "# Get latest file [First Element in List]\n",
        "latest = pushes[0]\n",
        "\n",
        "# # Get Link to Chatfile\n",
        "# url = latest['file_url']\n",
        "# url"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "VX2GwjQ-2qui",
        "outputId": "b7db2ca2-037f-442a-ec6f-9678fa952407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://dl4.pushbulletusercontent2.com/lz6iRMXRF5XsVEDEWagHXhTOMLqusrVQ/WhatsApp%20Chat%20with%20Prof%20Bigi.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Chatfile\n",
        "# url = latest['file_url']\n",
        "# file_path = \"chat.txt\"\n",
        "\n",
        "# urllib.request.urlretrieve(url, file_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qtU14f3u3CTh",
        "outputId": "655fc7a7-2728-4e49-e257-361df0b64ac7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('chat.txt', <http.client.HTTPMessage at 0x7d80b57ced20>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import WhatsApp Chat"
      ],
      "metadata": {
        "id": "DTXpwOS_q8ko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"chat_without_media.txt\"\n",
        "\n",
        "# Read file by line by line\n",
        "with open(file_path, mode='r', encoding=\"utf8\") as f:\n",
        "    data = f.readlines()"
      ],
      "metadata": {
        "id": "gRP8USOQ3WqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print Data\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rUCMvOl-4ym9",
        "outputId": "1981668c-22a1-41f5-be5d-0852d20816de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['04/03/2024, 21:36 - ~\\u202fAzeez created group \"UM6P 2024 Admission & Scholarshp\"\\n',\n",
              " '04/03/2024, 21:36 - You were added\\n',\n",
              " '03/06/2024, 09:14 - +234\\xa0810\\xa0387\\xa09881 changed to +234\\xa0703\\xa0451\\xa06743\\n',\n",
              " '03/06/2024, 11:04 - Mr Obasanjo Fajemirokun UM6P: I shared 10 lessons from my first year at UM6P.\\n',\n",
              " '\\n',\n",
              " 'Click on the below link, read and learn as you prepare for graduate school https://www.linkedin.com/posts/obasanjofajemirokun_10-lessons-from-my-first-year-at-um6p-africa-activity-7203332958357700610-ky1B?utm_source=share&utm_medium=member_ios\\n',\n",
              " '03/06/2024, 12:38 - My Number: Collectiive intelligence mail landed\\n',\n",
              " '03/06/2024, 12:42 - Bala bashar um6p WL: Same here\\n',\n",
              " '03/06/2024, 12:43 - +234 902 097 1082: Just received mine\\n',\n",
              " '03/06/2024, 12:45 - Joy: Hmmmmmm\\n',\n",
              " '03/06/2024, 12:50 - +234 806 798 4051: Best of luck guys\\n',\n",
              " '03/06/2024, 12:50 - +212 700-167603: Lucky you! Very unfair for us here. How am I supposed to arrive by 10 a.m.? So ridiculous!\\n',\n",
              " '03/06/2024, 12:51 - Joy: Oh oh you are in Morocco?\\n',\n",
              " '03/06/2024, 12:51 - Samuel Kobina Gyasi SCI: It was the same last here so you can write for accomodation if need be\\n',\n",
              " '03/06/2024, 12:51 - Khalifa UM6P: Have you done your interview??\\n',\n",
              " '03/06/2024, 12:51 - +212 700-167603: Yes, I mean, Abs was so good at organizing this.\\n',\n",
              " \"03/06/2024, 12:52 - +212 700-167603: I asked they said no we can't\\n\",\n",
              " '03/06/2024, 12:52 - +212 700-167603: Being a UM6P student, I was told, ‚ÄúSorry, we can‚Äôt.‚Äù So sad to be honest\\n',\n",
              " '03/06/2024, 12:52 - Bala bashar um6p WL: Thanks ma.\\n',\n",
              " '\\n',\n",
              " 'Is there any clue about the written test, I mean the expected questions\\n',\n",
              " \"03/06/2024, 12:53 - Joy: It's in the mail na\\n\",\n",
              " '03/06/2024, 12:53 - Samuel Kobina Gyasi SCI: When did you write the mail ?\\n',\n",
              " '03/06/2024, 12:54 - +234 813 424 8246: Na love letter we get for hereü•∫ but we meuve regardless <This message was edited>\\n',\n",
              " '03/06/2024, 12:54 - +212 700-167603: Now, I asked, and they said no.\\n',\n",
              " '03/06/2024, 12:55 - Samuel Kobina Gyasi SCI: Oküëå\\n',\n",
              " '03/06/2024, 12:55 - Joy: You did MIM?\\n',\n",
              " '03/06/2024, 12:55 - Samuel Kobina Gyasi SCI: You are BG campus ?..\\n',\n",
              " '\\n',\n",
              " 'It happened to us but still able to find accomodation on the campus last year .Last year was in BG <This message was edited>\\n',\n",
              " '03/06/2024, 12:57 - +212 700-167603: Yes\\n',\n",
              " \"03/06/2024, 12:57 - +234 813 424 8246: Yea but didn't get mail for interview or test\\n\",\n",
              " '03/06/2024, 12:58 - Joy: Oh oh... we try again next time\\n',\n",
              " '03/06/2024, 12:59 - +234 813 424 8246: Right.\\n',\n",
              " '03/06/2024, 13:34 - Ahmed Salami UM6P: https://www.linkedin.com/posts/kofi-osei-frimpong-11a6305_are-you-considering-a-phd-program-in-the-activity-7203355620891115520-XiYD?utm_source=share&utm_medium=member_android\\n',\n",
              " '03/06/2024, 14:07 - +234 810 313 2989: Best wishes\\n',\n",
              " '03/06/2024, 14:19 - iWAHABüéá UM6P: CI love letter landed‚úÖ\\n',\n",
              " '\\n',\n",
              " 'We win some and we loss some ü§ù\\n',\n",
              " '03/06/2024, 14:22 - +234 810 763 1480: CI love letter well received\\n',\n",
              " '*TILL WE ALL WIN*üöÄ\\n',\n",
              " '03/06/2024, 14:45 - +234 806 798 4051: @\\u2068Samuel Kobina Gyasi SCI\\u2069\\n',\n",
              " '\\n',\n",
              " 'Please drop the SCI exam prep here too\\n',\n",
              " '03/06/2024, 14:55 - My Number: üôèüèΩ\\n',\n",
              " '03/06/2024, 15:22 - +234 810 313 2989: Same hereüí™üèæ‚úåüèæüíØ\\n',\n",
              " '03/06/2024, 21:35 - +234 806 893 4852: Same\\n',\n",
              " '04/06/2024, 09:41 - Mirad: @\\u2068~Africanlady\\u2069  \\n',\n",
              " \"Good morning Ma! I didn't receive any mail either positive or negative from CI yesterday. Should I be worried?\\n\",\n",
              " '04/06/2024, 09:42 - Samuel Kobina Gyasi SCI: This is a YouTube channel that provides tips for standardized exams.Some of us used it and it helped a lot\\n',\n",
              " '\\n',\n",
              " '*The channel itself*.\\n',\n",
              " 'https://youtube.com/@careerrideofficial?si=_wwwmD2wTRy8ViE9\\n',\n",
              " '\\n',\n",
              " '‚ùóSome important and r√©v√©lant playlist for the exams preparation \\n',\n",
              " '\\n',\n",
              " '*Verbal Abilities  part* \\n',\n",
              " 'https://youtube.com/playlist?list=PLpyc33gOcbVBbD8Vfy-gCbivjSSHbMpUX&si=pS1bwk0TH8KYpmt-\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '*Quantitative Aptitude Test:*\\n',\n",
              " '\\n',\n",
              " 'https://youtube.com/playlist?list=PLpyc33gOcbVA4qXMoQ5vmhefTruk5t9lt&si=XFhsXf0SzdKp4kGD\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '*Logical reasoning:*\\n',\n",
              " 'https://youtube.com/playlist?list=PLpyc33gOcbVADMKqylI__O_O_RMeHTyNK&si=5lGTlpxFGWMQUzme\\n',\n",
              " '04/06/2024, 09:46 - My Number: @\\u2068~Africanlady\\u2069\\n',\n",
              " '04/06/2024, 09:52 - +243 814 114 208: Good morning! Can someone help us about this?üëÜüëÜ üëÜ\\n',\n",
              " \"04/06/2024, 14:48 - +212 700-167603: Has anyone received any emails from Agri? I haven't heard from them.\\n\",\n",
              " '04/06/2024, 14:50 - Kehinde Olawale Victoria UM6P: Not yet\\n',\n",
              " '04/06/2024, 14:51 - +234 806 798 4051: The might have a reason for not sending you email yet.\\n',\n",
              " '04/06/2024, 14:51 - +234 813 453 6479: ....\\n',\n",
              " \"04/06/2024, 14:57 - +234 806 798 4051: Please give them a little bit of them. It's possible they are still checking your documents and I hope you will be contacted soon.\\n\",\n",
              " '\\n',\n",
              " 'Thank you\\n',\n",
              " '04/06/2024, 15:07 - Mirad: No problem‚Ä¶thank you ma\\n',\n",
              " \"04/06/2024, 19:47 - +234 806 798 4051: Please anyone that didn't get email from SCI, send me an email to confirm.\\n\",\n",
              " '\\n',\n",
              " 'christianah.oyewale@um6p.ma\\n',\n",
              " '04/06/2024, 20:31 - +243 814 114 208: SCI what does it mean please?\\n',\n",
              " '04/06/2024, 20:35 - Mr jumah toheeb: School of Collective Intelligence\\n',\n",
              " '04/06/2024, 20:36 - +243 814 114 208: Okay thanks dear @\\u2068Mr jumah toheeb\\u2069\\n',\n",
              " '04/06/2024, 21:27 - +234 703 688 6353: School of collective intelligence\\n',\n",
              " '05/06/2024, 14:29 - Kehinde Olawale Victoria UM6P: Good day everyone\\n',\n",
              " 'Please, has anyone received MIM Interview link yet?\\n',\n",
              " '05/06/2024, 14:32 - Uzi UM6P: It was included in the previous mail they sent\\n',\n",
              " '05/06/2024, 14:32 - Uzi UM6P: The Interview invitation mail\\n',\n",
              " '05/06/2024, 14:32 - Kehinde Olawale Victoria UM6P: This message was deleted\\n',\n",
              " '05/06/2024, 14:34 - Uzi UM6P: <Media omitted>\\n',\n",
              " '05/06/2024, 14:35 - Khalifa UM6P: How was the interview??\\n',\n",
              " '05/06/2024, 14:36 - Kehinde Olawale Victoria UM6P: Not yet\\n',\n",
              " '05/06/2024, 14:36 - +212 700-167603: Let me explain: some people here have received notification that they have advanced to the next stage, but not everyone has received the email with the link yet. It is an ongoing process.\\n',\n",
              " '05/06/2024, 14:37 - Khalifa UM6P: Okay we now understand, thanks for the clarity\\n',\n",
              " '05/06/2024, 14:38 - Kehinde Olawale Victoria UM6P: I got a mail that the interview is in batches.\\n',\n",
              " '\\n',\n",
              " 'No cause for alarm...\\n',\n",
              " '05/06/2024, 14:38 - Kehinde Olawale Victoria UM6P: <Media omitted>\\n',\n",
              " '05/06/2024, 14:38 - Khalifa UM6P: Alryt\\n',\n",
              " '05/06/2024, 14:45 - +234 903 934 0119: This message was deleted\\n',\n",
              " '05/06/2024, 14:46 - Uzi UM6P: Not bad.\\n',\n",
              " '\\n',\n",
              " 'Some of the questions were random (based on my introduction), but it was mostly surrounding my educational and work experience, why the course was selected by me and how it aligns with my future career goals.\\n',\n",
              " '\\n',\n",
              " 'They also asked me about a recent challenge I faced and how I overcame it.\\n',\n",
              " '05/06/2024, 14:47 - Uzi UM6P: You guys should also be prepared to answer \"where do you see yourself in the next 5 to 10 years\" üôÉ\\n',\n",
              " '05/06/2024, 14:50 - Paul Popoola UM6P: Thank you for these pointers, Uzoma. \\n',\n",
              " '\\n',\n",
              " 'Were you asked any technical question(s) relating to International Management as a course? \\n',\n",
              " '\\n',\n",
              " 'Something like \"What\\'s your current understanding about International Management?\"\\n',\n",
              " '05/06/2024, 14:50 - Uzi UM6P: Nope\\n',\n",
              " '05/06/2024, 14:50 - Paul Popoola UM6P: Okay. Thank you.\\n',\n",
              " '05/06/2024, 14:51 - Khalifa UM6P: Thank u\\n',\n",
              " '05/06/2024, 15:12 - +234 806 612 7153: They should also prepare a telescope üî≠ for me o! Make I use am view am\\n',\n",
              " \"05/06/2024, 15:44 - +234 806 444 8972: I haven't gotten any message for my interview date\\n\",\n",
              " \"05/06/2024, 15:49 - +212 700-167603: They have different rounds, that's what I'm saying.\\n\",\n",
              " \"05/06/2024, 15:52 - Ahmed Salami UM6P: You'll get a date, it's in batches.\\n\",\n",
              " '05/06/2024, 16:09 - +234 806 444 8972: Ok\\n',\n",
              " '05/06/2024, 16:09 - +234 806 444 8972: Thank you\\n',\n",
              " '05/06/2024, 16:13 - +212 687-356123: This message was deleted\\n',\n",
              " '05/06/2024, 16:39 - Meike: This message was deleted\\n',\n",
              " '05/06/2024, 17:09 - Ahmed Salami UM6P: https://www.linkedin.com/posts/faculty-of-medical-sciences_transfer-admissions-to-doctorate-in-pharmacy-activity-7203689652812169216-LWjQ?utm_source=share&utm_medium=member_android\\n',\n",
              " '05/06/2024, 17:10 - Ahmed Salami UM6P: Transfer admission to doctorate in Pharmacy. \\n',\n",
              " '\\n',\n",
              " 'Deadline: June 30th\\n',\n",
              " '05/06/2024, 20:13 - Samuel Kobina Gyasi SCI: *üî∞SCI Applicants*\\n',\n",
              " '\\n',\n",
              " \"If you applied for SCI and haven't received any feedback about whether you were accepted for exams or not selected, please send your full name to me.\\n\",\n",
              " '\\n',\n",
              " 'Thank you.\\n',\n",
              " '05/06/2024, 20:13 - Samuel Kobina Gyasi SCI pinned a message\\n',\n",
              " '06/06/2024, 01:00 - +234 806 798 4051: *SCI APPLICANTS WITH NO FEEDBACK*\\n',\n",
              " '\\n',\n",
              " '1.Hammed Oseni\\n',\n",
              " '2.Samuel Nii Nortei Dowuonah Nortey\\n',\n",
              " '3.Assogba Yadolli Jean Batiste\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Please, these candidates should send me the email address they used to register\\n',\n",
              " '06/06/2024, 01:14 - +234 703 564 7432: Please, what about MIM?\\n',\n",
              " \"06/06/2024, 01:19 - +234 806 798 4051: You didn't hear any feedback from them too?\\n\",\n",
              " '06/06/2024, 01:19 - +234 703 564 7432: Yes\\n',\n",
              " '06/06/2024, 01:32 - +234 806 798 4051: Please edit this with your name and email\\n',\n",
              " \"06/06/2024, 07:22 - +234 806 444 8972: I was sent congratulations message but I haven't gotten any message for interview invite\\n\",\n",
              " \"06/06/2024, 07:44 - Joy: They have been explaining that it's in batches ....\\n\",\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Many have not recieved too....\\n',\n",
              " '\\n',\n",
              " 'They said June and we just started June ....\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'üòÅüòÅüòÅSo just relax you will get I think...\\n',\n",
              " '\\n',\n",
              " 'I have not recieved interview mail too but I am not bothered because its an ongoing process\\n',\n",
              " '06/06/2024, 08:01 - Supreme UM6P: Okay üëç\\n',\n",
              " '06/06/2024, 08:14 - +234 813 453 6479: *SCI APPLICANTS WITH NO FEEDBACK*\\n',\n",
              " '\\n',\n",
              " '1.Hammed Oseni\\n',\n",
              " '2.Samuel Nii Nortei Dowuonah Nortey\\n',\n",
              " '3.Assogba Yadolli Jean Batiste\\n',\n",
              " '4.Usman Hakeem osigbeme  \\n',\n",
              " 'usmanhakeem1960@gmail.com \\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Please, these candidates should send me the email address they used to register\\n',\n",
              " '06/06/2024, 08:31 - +234 806 798 4051: By who?\\n',\n",
              " '06/06/2024, 08:32 - +234 806 444 8972: ABS (MIM)\\n',\n",
              " '06/06/2024, 08:32 - +234 806 798 4051: Ok, I will confirm\\n',\n",
              " '06/06/2024, 08:33 - +234 806 444 8972: Thank you\\n',\n",
              " '06/06/2024, 08:41 - +234 813 424 8246: Me too, no mail from MIM\\n',\n",
              " '06/06/2024, 08:49 - +234 818 676 8841: *SCI APPLICANTS WITH NO FEEDBACK*\\n',\n",
              " '\\n',\n",
              " '1.Hammed Oseni\\n',\n",
              " '2.Samuel Nii Nortei Dowuonah Nortey\\n',\n",
              " '3.Assogba Yadolli Jean Batiste\\n',\n",
              " '4.Usman Hakeem osigbeme  \\n',\n",
              " 'usmanhakeem1960@gmail.com.                                5. Adelani Opeoluwa Christopher opeoluwaadelani.1@gmail.com\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Please, these candidates should send me the email address they used to register\\n',\n",
              " '06/06/2024, 11:17 - Supreme UM6P: This message was deleted\\n',\n",
              " '06/06/2024, 11:17 - Supreme UM6P: This message was deleted\\n',\n",
              " '06/06/2024, 11:25 - Supreme UM6P: Who else joined the Zoom meeting?\\n',\n",
              " \"06/06/2024, 11:30 - My Number: I didn't even know they sent mail yesterday, I just checked my inbox now and saw the mailüòå\\n\",\n",
              " '06/06/2024, 11:33 - Supreme UM6P: The meeting just ended\\n',\n",
              " \"06/06/2024, 11:35 - Joy: We're you able to attend?\\n\",\n",
              " '06/06/2024, 11:36 - RightMinds um6p: This message was deleted\\n',\n",
              " '06/06/2024, 11:36 - Supreme UM6P: Yes\\n',\n",
              " '06/06/2024, 11:38 - Supreme UM6P: So, we‚Äôre to take a demonstration test on the Canvas platform\\n',\n",
              " '06/06/2024, 11:38 - Supreme UM6P: The demonstration test is in French but the exam will be in English. The demonstration due time is 18:00 today\\n',\n",
              " '06/06/2024, 11:39 - +234 909 851 1482: For SCI?\\n',\n",
              " '06/06/2024, 11:40 - Supreme UM6P: Yes\\n',\n",
              " '06/06/2024, 11:45 - Joy: Has the demo text started?\\n',\n",
              " '06/06/2024, 11:45 - Joy: If we login we will see it?\\n',\n",
              " '06/06/2024, 11:46 - Supreme UM6P: <Media omitted>\\n',\n",
              " '06/06/2024, 11:46 - Supreme UM6P: Yea, you have till 6 pm\\n',\n",
              " '06/06/2024, 11:47 - Joy: Seen\\n',\n",
              " '06/06/2024, 11:47 - Joy: Thanks\\n',\n",
              " '06/06/2024, 11:47 - Joy: Now that it is in French how do we translate\\n',\n",
              " '06/06/2024, 11:48 - Supreme UM6P: I plan to use google translate\\n',\n",
              " '06/06/2024, 11:49 - My Number: 5points?\\n',\n",
              " '06/06/2024, 11:49 - Supreme UM6P: It doesn‚Äôt count\\n',\n",
              " '06/06/2024, 11:49 - Supreme UM6P: I think it means 5 questions\\n',\n",
              " '06/06/2024, 11:49 - Mirad: <Media omitted>\\n',\n",
              " '06/06/2024, 11:49 - Supreme UM6P: I asked the man, he said it‚Äôs just a demo\\n',\n",
              " \"06/06/2024, 11:52 - youngmusty7 UM6P: Yes it's just a demonstration to familiarise you with the platform\\n\",\n",
              " '06/06/2024, 11:53 - Supreme UM6P: Yes\\n',\n",
              " '06/06/2024, 11:54 - Supreme UM6P: The man made mention of a marking system, something like, if you get the answer correct +1 and -1 for incorrect answer\\n',\n",
              " '06/06/2024, 11:54 - My Number: Negative marking\\n',\n",
              " '06/06/2024, 11:54 - Supreme UM6P: Something like that‚Ä¶ Is that true?\\n',\n",
              " '06/06/2024, 11:56 - Samuel Kobina Gyasi SCI: Yes that is true.\\n',\n",
              " '\\n',\n",
              " 'If it is correct + 1 ,wrong  -1. <This message was edited>\\n',\n",
              " '06/06/2024, 11:59 - Supreme UM6P: Okay\\n',\n",
              " '06/06/2024, 12:01 - youngmusty7 UM6P: Yes Negative marking\\n',\n",
              " '06/06/2024, 12:05 - +234 902 097 1082: <Media omitted>\\n',\n",
              " '06/06/2024, 12:32 - +234 813 541 3233: This message was deleted\\n',\n",
              " '06/06/2024, 13:11 - Mr Obasanjo Fajemirokun UM6P: Canadian marking style\\n',\n",
              " '06/06/2024, 13:16 - +212 700-167603: CI is a Canadian system?ü•≤\\n',\n",
              " '06/06/2024, 13:17 - +212 700-167603: Is there any way to access that demonstration test? I speak French and I just need to train myself a bit.\\n',\n",
              " '06/06/2024, 13:18 - Supreme UM6P: Yes\\n',\n",
              " '06/06/2024, 13:18 - Supreme UM6P: Login on the Canvas platform\\n',\n",
              " '06/06/2024, 13:18 - Samuel Kobina Gyasi SCI: Yes\\n',\n",
              " \"06/06/2024, 13:20 - +212 700-167603: I have an um6p canvas but can't see it.\\n\",\n",
              " '06/06/2024, 13:21 - Supreme UM6P: @\\u2068~Ouissal\\u2069\\n',\n",
              " '06/06/2024, 13:21 - Supreme UM6P: It‚Äôs like this\\n',\n",
              " '06/06/2024, 14:02 - +229 94 05 11 78: This message was deleted\\n',\n",
              " '06/06/2024, 14:04 - +234 818 676 8841: üëÜüèΩ\\n',\n",
              " '06/06/2024, 14:08 - +229 94 05 11 78: *SCI APPLICANTS WITH NO FEEDBACK*\\n',\n",
              " '\\n',\n",
              " '1.Hammed Oseni\\n',\n",
              " '2.Samuel Nii Nortei Dowuonah Nortey\\n',\n",
              " '3.Assogba Yadolli Jean Batiste\\n',\n",
              " '4.Usman Hakeem osigbeme  \\n',\n",
              " 'usmanhakeem1960@gmail.com.                                5. Adelani Opeoluwa Christopher opeoluwaadelani.1@gmail.com\\n',\n",
              " '6. MONGBE Marc Merlot,\\n',\n",
              " 'mongbemarcmerlot@gmail.com\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Please, these candidates should send me the email address they used to register\\n',\n",
              " '06/06/2024, 14:10 - Joy: Me I have taken their demo test\\n',\n",
              " '06/06/2024, 14:10 - Joy: Just 5 questions\\n',\n",
              " '06/06/2024, 14:10 - Joy: And I doubt that is how the questions will beüê•üê•üê•\\n',\n",
              " \"06/06/2024, 14:11 - Ahmed Salami UM6P: It's a prototype\\n\",\n",
              " '06/06/2024, 15:04 - +212 661-506649: Link please\\n',\n",
              " \"06/06/2024, 16:49 - Paul Popoola UM6P: Good evening. I'd like to confirm something. \\n\",\n",
              " '\\n',\n",
              " 'Please, do we use the same time zone with Morocco?\\n',\n",
              " '06/06/2024, 16:49 - Khalifa UM6P: Yes\\n',\n",
              " '06/06/2024, 16:50 - Supreme UM6P: Yes\\n',\n",
              " '06/06/2024, 16:51 - Paul Popoola UM6P: Alright, thank you. üôåüèæ\\n',\n",
              " '06/06/2024, 16:52 - Boaz: Yes for now though\\n',\n",
              " '06/06/2024, 16:52 - Boaz: It changes\\n',\n",
              " '06/06/2024, 16:55 - Paul Popoola UM6P: Okay, no problem.\\n',\n",
              " '06/06/2024, 17:16 - My Number: Guys check your mail for MIM interview date\\n',\n",
              " '06/06/2024, 17:20 - Supreme UM6P: Have you received yours?\\n',\n",
              " '06/06/2024, 17:21 - My Number: Yes\\n',\n",
              " '06/06/2024, 17:22 - Mr jumah toheeb: Same time zone but during fasting (Ramadan) only, the time difference changes to Morocco going 1 hour earlier than Nigeria.\\n',\n",
              " '06/06/2024, 17:24 - +212 700-167603: Not everyone will receive the same date we are still waiting\\n',\n",
              " '06/06/2024, 17:31 - +234 813 907 1216: Agribusiness nko?\\n',\n",
              " '06/06/2024, 18:08 - Joy: Yeah..\\n',\n",
              " '06/06/2024, 20:54 - My Number: The demonstration test has been locked, hope no problem if one was unable to do it before it got locked?\\n',\n",
              " '06/06/2024, 20:55 - My Number: @\\u2068~Africanlady\\u2069\\n',\n",
              " '06/06/2024, 20:57 - +234 806 798 4051: No problem at all\\n',\n",
              " '06/06/2024, 20:58 - Supreme UM6P: No problem.. Just to get familiar <This message was edited>\\n',\n",
              " '06/06/2024, 20:58 - My Number: Alright, thank you ma\\n',\n",
              " '06/06/2024, 20:58 - My Number: Thank youüôèüèΩ\\n',\n",
              " '06/06/2024, 22:06 - +234 902 097 1082: Plss could you shade a bit of light about the demo test?\\n',\n",
              " \"I didn't get to do it\\n\",\n",
              " '07/06/2024, 02:13 - Joy: From what I did... it was general kind of questions and it involved me selecting more than one answers... its the only thing I noticed...\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'All the 5 questions set as demo were like that...\\n',\n",
              " '\\n',\n",
              " 'One question I remember is\\n',\n",
              " '\"Which of this is a type of rock(choose all that apply)\\n',\n",
              " 'Another one was \\n',\n",
              " 'Which of this is a respiratory part of the human(choose all that apply)\\n',\n",
              " 'An\\n',\n",
              " '\\n',\n",
              " 'Cannot recall the rest 3üòÅüòÅ\\n',\n",
              " '07/06/2024, 05:33 - Deborah A. UM6P: Did you or anyone else got fixed for 3:00am\\n',\n",
              " '07/06/2024, 05:54 - +234 704 901 2889: \\n',\n",
              " '07/06/2024, 07:35 - My Number: 3amüò≥\\n',\n",
              " '07/06/2024, 07:35 - My Number: Mine is 11am\\n',\n",
              " \"07/06/2024, 08:09 - +234 813 907 1216: Send an email to @\\u2068~Africanlady\\u2069  to confirm the time for you so that you'll not encounter any problem\\n\",\n",
              " '07/06/2024, 08:17 - Supreme UM6P: What date?\\n',\n",
              " '07/06/2024, 08:24 - Deborah A. UM6P: June 10\\n',\n",
              " '07/06/2024, 08:25 - Supreme UM6P: Alright\\n',\n",
              " '07/06/2024, 08:32 - Deborah A. UM6P: Thank you\\n',\n",
              " '07/06/2024, 08:33 - Supreme UM6P: I‚Äôm yet to receive MIM interview date email though <This message was edited>\\n',\n",
              " '07/06/2024, 09:16 - +234 810 081 1965 joined using a group link.\\n',\n",
              " '08/06/2024, 12:38 - Uzi UM6P: Please are there any GMAT questions on computer science and statistics?\\n',\n",
              " '08/06/2024, 12:39 - Supreme UM6P: Yes, past questions we can use to prepare for SCI exams tomorrow\\n',\n",
              " '08/06/2024, 12:39 - +234 815 283 8906: Share if you have any\\n',\n",
              " '09/06/2024, 08:56 - Abdulghaniyy JIMOHüë®\\u200düíª added +234 806 219 4590\\n',\n",
              " '09/06/2024, 09:34 - +234 703 329 5757: <Media omitted>\\n',\n",
              " '09/06/2024, 13:56 - +234 805 222 1180: Can you take the gift and accept my invitation? Only 2 steps, take your free gifts from top-notch activity TEMU Free Gifts and help me get mine!\\n',\n",
              " 'https://temu.com/s/Eii8UA7zz5RAtSq\\n',\n",
              " '09/06/2024, 14:04 - +234 703 221 9924: Is anybody doing sci exam today\\n',\n",
              " '09/06/2024, 14:57 - +234 815 283 8906: Yes\\n',\n",
              " '09/06/2024, 14:58 - Bala bashar um6p WL: Yes, I have done mine\\n',\n",
              " '09/06/2024, 14:59 - Acquah Nana Yeboah: Done. ü•π\\n',\n",
              " '09/06/2024, 14:59 - Joy: Monitored??\\n',\n",
              " '09/06/2024, 14:59 - My Number: ü•µ\\n',\n",
              " '09/06/2024, 15:06 - +234 813 907 1216: üòØüòØ\\n',\n",
              " 'You finished before time?\\n',\n",
              " '09/06/2024, 15:07 - +234 815 283 8906: 15 questions\\n',\n",
              " '09/06/2024, 15:08 - My Number: You received any mail?\\n',\n",
              " '09/06/2024, 15:08 - My Number: Did anyone receive mail after submitting?\\n',\n",
              " '09/06/2024, 15:08 - My Number: @\\u2068Joy\\u2069 @\\u2068~Ouissal\\u2069\\n',\n",
              " '09/06/2024, 15:10 - +212 700-167603: In person for me\\n',\n",
              " '09/06/2024, 15:10 - +212 700-167603: But that was so difficult ü•≤\\n',\n",
              " '09/06/2024, 15:10 - My Number: Oh! You wrote physically\\n',\n",
              " '09/06/2024, 15:10 - My Number: üò©\\n',\n",
              " '09/06/2024, 15:19 - Joy: No\\n',\n",
              " '09/06/2024, 15:19 - Joy: I did not\\n',\n",
              " '09/06/2024, 15:20 - Joy: Ewww sorry sweet... u will pass sh\\n',\n",
              " '09/06/2024, 15:20 - Joy: It was a difficult one.... even me online\\n',\n",
              " '09/06/2024, 15:36 - Funtua UM6P: Please they Tell them that we r not applying for p.hd program. The questions are very tough naaüòÇüòÇ\\n',\n",
              " '09/06/2024, 15:36 - Samuel Kobina Gyasi SCI: üòÇüòÇüòÇ\\n',\n",
              " '09/06/2024, 15:37 - Samuel Kobina Gyasi SCI: 15 questions 90 minutes +1 -1  is a trap in itself üëåüòÅ\\n',\n",
              " '09/06/2024, 15:37 - My Number: Lol, even PhD applicants will feel it, little did we know that Gorilla was gentleü•≤\\n',\n",
              " '09/06/2024, 15:38 - Samuel Kobina Gyasi SCI: You will be fine üòÉüòÅ\\n',\n",
              " '09/06/2024, 15:42 - Funtua UM6P: By God willing Sir. We still have hopeü•∏\\n',\n",
              " '09/06/2024, 15:44 - Samuel Kobina Gyasi SCI: üòÅüòÅü•≥üëå\\n',\n",
              " 'See you in October\\n',\n",
              " '09/06/2024, 15:45 - Funtua UM6P: Ameen\\n',\n",
              " '09/06/2024, 15:47 - Mirad: üòÇüòÇ\\n',\n",
              " '09/06/2024, 15:51 - Ahmed Salami UM6P: The test is to prepare you for the task ahead.\\n',\n",
              " '09/06/2024, 15:51 - youngmusty7 UM6P: üòÖüòÖüòÖüòÖ\\n',\n",
              " '09/06/2024, 15:56 - Funtua UM6P: Prepare me for the task ahead without prior knowledge üôÑ\\n',\n",
              " '09/06/2024, 15:56 - +234 813 541 3233: This message was deleted\\n',\n",
              " '09/06/2024, 15:59 - Mirad: <Media omitted>\\n',\n",
              " '09/06/2024, 16:03 - +234 814 268 6169: <Media omitted>\\n',\n",
              " '09/06/2024, 16:53 - Mr jumah toheeb: Welcome to SCI\\n',\n",
              " '09/06/2024, 17:17 - +234 813 255 9222: Ha ...\\n',\n",
              " '10/06/2024, 14:45 - +234\\xa0703\\xa0451\\xa06743 changed to +234\\xa0810\\xa0387\\xa09881\\n',\n",
              " '10/06/2024, 16:39 - iWAHABüéá UM6P: How interview dey be\\n',\n",
              " '10/06/2024, 16:42 - +234 810 498 8022: When is ur interview?\\n',\n",
              " '10/06/2024, 16:59 - +234 813 907 1216: Agribusiness??\\n',\n",
              " \"10/06/2024, 20:47 - +212 700-167603: Guys are you sure agri haven't sent to anyone I mean it's weird\\n\",\n",
              " \"10/06/2024, 20:51 - +234 903 544 8153: I don't think so, patience and composure guys. üòÖüòÖ Let's hope for the best.\\n\",\n",
              " '11/06/2024, 09:56 - +234 810 498 8022: This message was deleted\\n',\n",
              " '11/06/2024, 14:38 - +234 706 653 4141 changed their phone number to a new number. Tap to message or add the new number.\\n',\n",
              " '11/06/2024, 15:25 - +234\\xa0915\\xa0211\\xa03859 changed to +234\\xa0706\\xa0653\\xa04141\\n',\n",
              " '11/06/2024, 20:03 - +212 700-167603: <Media omitted>\\n',\n",
              " '11/06/2024, 20:04 - +234 903 737 6797: Congrats\\n',\n",
              " '11/06/2024, 20:05 - +234 810 498 8022: Wow congratulations üéâ\\n',\n",
              " '11/06/2024, 20:06 - Golden Wheels Consults Ltd: Congratulations\\n',\n",
              " '11/06/2024, 20:16 - youngmusty7 UM6P: <Media omitted>\\n',\n",
              " '11/06/2024, 20:16 - youngmusty7 UM6P: üéâ congrats\\n',\n",
              " '11/06/2024, 20:18 - +234 903 737 6797: Congrats\\n',\n",
              " '11/06/2024, 20:22 - youngmusty7 UM6P: Thanks oo\\n',\n",
              " '11/06/2024, 20:24 - +234 708 782 8495: <Media omitted>\\n',\n",
              " '11/06/2024, 20:24 - +234 708 782 8495: <Media omitted>\\n',\n",
              " '11/06/2024, 20:24 - +234 708 782 8495: <Media omitted>\\n',\n",
              " '11/06/2024, 20:24 - +234 708 782 8495: \\n',\n",
              " '11/06/2024, 20:26 - +234 814 660 2267: Scammers\\n',\n",
              " '11/06/2024, 20:26 - +234 814 660 2267: beware\\n',\n",
              " '11/06/2024, 20:26 - Abdulmajid Babale: @\\u2068~Africanlady\\u2069 @\\u2068Mr Obasanjo Fajemirokun UM6P\\u2069 \\n',\n",
              " 'This is a scam\\n',\n",
              " '11/06/2024, 20:26 - Abdulmajid Babale: The account was hacked\\n',\n",
              " '11/06/2024, 20:27 - Abdulmajid Babale: Please do the needful @\\u2068Mr Obasanjo Fajemirokun UM6P\\u2069 @\\u2068~Africanlady\\u2069 @\\u2068CAPESTONE ROYAL COMPANY\\u2069\\n',\n",
              " '11/06/2024, 20:27 - +234 814 660 2267: <Media omitted>\\n',\n",
              " '11/06/2024, 20:27 - +234 814 660 2267: <Media omitted>\\n',\n",
              " '11/06/2024, 20:28 - Mr Obasanjo Fajemirokun UM6P removed ~\\u202fKhaleelTronics\\n',\n",
              " '11/06/2024, 20:28 - youngmusty7 UM6P: Scammers\\n',\n",
              " '11/06/2024, 20:29 - Mr Obasanjo Fajemirokun UM6P removed ~\\u202fCc\\n',\n",
              " '11/06/2024, 20:30 - Abdulmajid Babale: @\\u2068Mr Obasanjo Fajemirokun UM6P\\u2069 you remove the wrong person üòÇ\\n',\n",
              " '11/06/2024, 20:30 - Abdulmajid Babale: He is trying to show that the guy is a Scammer üòÉ\\n',\n",
              " '11/06/2024, 20:30 - Mr Obasanjo Fajemirokun UM6P: Yes üòÜ adding him now\\n',\n",
              " '11/06/2024, 20:30 - Mr Obasanjo Fajemirokun UM6P: Scammer have now been removed\\n',\n",
              " '11/06/2024, 20:31 - Abdulmajid Babale: Okay üòÄ\\n',\n",
              " '11/06/2024, 20:31 - +234 810 313 2989: Congratulations\\n',\n",
              " '11/06/2024, 20:31 - youngmusty7 UM6P: üòÖüòÖüòÖüòÖ\\n',\n",
              " '11/06/2024, 20:31 - Deborah A. UM6P: Congratulations\\n',\n",
              " '11/06/2024, 20:31 - +234 810 313 2989: Congratulations\\n',\n",
              " '11/06/2024, 20:31 - Deborah A. UM6P: Congratulations\\n',\n",
              " '11/06/2024, 20:32 - Mr Obasanjo Fajemirokun UM6P added ~\\u202fKhaleelTronics\\n',\n",
              " '11/06/2024, 20:33 - Mr Obasanjo Fajemirokun UM6P: Welcome back @\\u2068~Khaleel Tronics.\\u2069\\n',\n",
              " '11/06/2024, 20:34 - youngmusty7 UM6P: üòÖüòÖüòÖüòÖüòÖ\\n',\n",
              " '11/06/2024, 20:34 - Abdulmajid Babale: üòÇ\\n',\n",
              " '11/06/2024, 20:37 - +234 815 283 8906: Congratulations\\n',\n",
              " '11/06/2024, 20:37 - Joy: <Media omitted>\\n',\n",
              " '11/06/2024, 20:38 - youngmusty7 UM6P: Congratulations üéâ\\n',\n",
              " '11/06/2024, 20:38 - RightMinds um6p: Congrats üéâ\\n',\n",
              " '11/06/2024, 20:39 - +234 903 934 0119: Agribusiness no send message all this while\\n',\n",
              " '11/06/2024, 20:41 - +234 813 907 1216: Yuppp\\n',\n",
              " '@\\u2068~Africanlady\\u2069 can you enquire??üò©\\n',\n",
              " '11/06/2024, 20:41 - +234 903 934 0119: Tor\\n',\n",
              " '11/06/2024, 20:43 - +234 706 653 4141 changed their phone number to a new number. Tap to message or add the new number.\\n',\n",
              " '11/06/2024, 20:52 - +234 810 313 2989: Congratulations\\n',\n",
              " '11/06/2024, 20:58 - Funtua UM6P: <Media omitted>\\n',\n",
              " '11/06/2024, 20:58 - Funtua UM6P: .\\n',\n",
              " '11/06/2024, 20:58 - youngmusty7 UM6P: Masha Allah congratulations boss\\n',\n",
              " '11/06/2024, 20:59 - Funtua UM6P: Thank u sir. Congrats too oo\\n',\n",
              " '11/06/2024, 20:59 - youngmusty7 UM6P: Mp sir\\n',\n",
              " '11/06/2024, 21:01 - Funtua UM6P: Now to d next phase Sir.\\n',\n",
              " '\\n',\n",
              " 'The interview..\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'U know that PDF they sent to us about the\\n',\n",
              " '11/06/2024, 21:18 - +234 806 798 4051: Please send them email. I have called but they seems busy.\\n',\n",
              " '11/06/2024, 21:19 - +234 810 313 2989: Congratulations\\n',\n",
              " \"11/06/2024, 21:19 - +234 813 907 1216: No problem Ma'am \\n\",\n",
              " \"We'll wait.....sorry for the disturbance\\n\",\n",
              " '11/06/2024, 21:22 - +234 903 081 7012: Congratulations!\\n',\n",
              " '11/06/2024, 21:22 - +234 903 081 7012: Congratulations!\\n',\n",
              " '11/06/2024, 21:23 - +234 903 081 7012: Congratulations!\\n',\n",
              " '11/06/2024, 21:24 - youngmusty7 UM6P: Yes\\n',\n",
              " \"11/06/2024, 21:29 - +234 703 688 6353: Good evening... I'm yet to receive an invitation for an interview for MIM\\n\",\n",
              " '12/06/2024, 09:47 - +234\\xa0915\\xa0211\\xa03859 changed to +234\\xa0706\\xa0653\\xa04141\\n',\n",
              " '12/06/2024, 11:53 - +234 706 653 4141 changed their phone number to a new number. Tap to message or add the new number.\\n',\n",
              " '12/06/2024, 12:47 - +234 806 798 4051: Best of luck to you all in your interview.\\n',\n",
              " '\\n',\n",
              " \"My heart is with you. Unfortunately, it's a very busy time for us. But I have faith in your abilities.\\n\",\n",
              " '\\n',\n",
              " \"Be confident, our lecturers are friendly, so don't be afraid.\\n\",\n",
              " '\\n',\n",
              " 'Connect all dots together (past, present and future)\\n',\n",
              " '\\n',\n",
              " 'Let your expression speak along with you.\\n',\n",
              " '\\n',\n",
              " 'Get familiar with the courses offered and how they will help you to achieve your set goals.\\n',\n",
              " '\\n',\n",
              " 'Mention related skills you have and how you will use and improve on them.\\n',\n",
              " '\\n',\n",
              " 'Draw motivation from one or two professors. You maybe lucky the person you read about might be your interviewer.\\n',\n",
              " '\\n',\n",
              " 'Ask them questions (please be careful). \\n',\n",
              " 'Avoid telling them you will combine work with school.\\n',\n",
              " \"Don't be too desperate.\\n\",\n",
              " '\\n',\n",
              " 'Do a friendly discussion like @\\u2068Mr jumah toheeb\\u2069 üòÄ\\n',\n",
              " '12/06/2024, 12:49 - +234 803 283 3980: Congratulations\\n',\n",
              " '13/06/2024, 12:52 - Supreme UM6P: Pls, I‚Äôm trying to start my interview fixes for 12:45-1:00, but no response\\n',\n",
              " '13/06/2024, 12:52 - Deborah A. UM6P: Have you been able to join the link\\n',\n",
              " '13/06/2024, 12:52 - Supreme UM6P: <Media omitted>\\n',\n",
              " '13/06/2024, 12:53 - Samuel Kobina Gyasi SCI: They will let you enter\\n',\n",
              " '13/06/2024, 12:53 - Samuel Kobina Gyasi SCI: They are interviewing someone\\n',\n",
              " '13/06/2024, 12:53 - Deborah A. UM6P: I equally had to wait on the call for another 15mins\\n',\n",
              " '13/06/2024, 12:53 - Ahmed Salami UM6P: Remain there, no log out ooo\\n',\n",
              " '13/06/2024, 12:53 - Deborah A. UM6P: Yes\\n',\n",
              " '13/06/2024, 12:53 - Supreme UM6P: Okay\\n',\n",
              " '13/06/2024, 12:53 - Supreme UM6P: I‚Äôll remain there\\n',\n",
              " '13/06/2024, 12:54 - Supreme UM6P: I actually thought it has been shifted to 1:45\\n',\n",
              " '13/06/2024, 12:55 - +234 807 717 9932: Hmmm, Fatima Zahra\\n',\n",
              " '13/06/2024, 12:57 - Supreme UM6P: Why?\\n',\n",
              " '13/06/2024, 12:58 - +234 807 717 9932: She is among  the jury <This message was edited>\\n',\n",
              " '13/06/2024, 13:03 - Supreme UM6P: Okay\\n',\n",
              " \"13/06/2024, 13:05 - +234 806 798 4051: She doesn't have any issue and Prof Lex\\n\",\n",
              " \"13/06/2024, 13:06 - +234 806 798 4051: It's good you guys know your interviewers. You can do well to read about them.\\n\",\n",
              " '\\n',\n",
              " 'Prof Lex may ask you something related to History. He is going to teach you History and Philosophy of Collective Intelligence ü•∞\\n',\n",
              " '13/06/2024, 13:07 - +234 806 798 4051: Prof Fatima has good smile, you can take courage from her smile\\n',\n",
              " '13/06/2024, 13:08 - Joy: Yes... Prof Lex is cool too\\n',\n",
              " '13/06/2024, 13:08 - Joy: Just finished and they r both niceüòÅüòÅ\\n',\n",
              " '13/06/2024, 13:09 - +234 806 798 4051: Waoh, congratulations dear. Maybe you will be the next AsabyaüòÄ\\n',\n",
              " '\\n',\n",
              " '@\\u2068Samuel Kobina Gyasi SCI\\u2069 will train you üòÄ <This message was edited>\\n',\n",
              " '13/06/2024, 13:09 - Supreme UM6P: Nice\\n',\n",
              " '13/06/2024, 13:09 - Supreme UM6P: I‚Äôm still there ooo\\n',\n",
              " '13/06/2024, 13:09 - Joy: Thanks maü´∂ü´∂\\n',\n",
              " '13/06/2024, 13:09 - Supreme UM6P: They are yet to attend to me\\n',\n",
              " '13/06/2024, 13:09 - +234 806 798 4051: They will\\n',\n",
              " '13/06/2024, 13:09 - Supreme UM6P: Okay\\n',\n",
              " '13/06/2024, 13:12 - +234 806 798 4051: I love the combination they gave you guys, Prof Lex and Prof Fatima. Very simple and easy going people.\\n',\n",
              " '\\n',\n",
              " \"In fact none of our Prof get wahala. All of them are cool. Please feel relaxed and don't be tensed\\n\",\n",
              " '13/06/2024, 13:23 - youngmusty7 UM6P: Exactly oooüòÖüòÖüòÖ\\n',\n",
              " '13/06/2024, 13:24 - youngmusty7 UM6P: üòÖüòÖüòÖ\\n',\n",
              " '13/06/2024, 13:27 - +234 806 798 4051: Who are those still experiencing issues with link and your time already passed?\\n',\n",
              " '13/06/2024, 14:08 - +234 806 798 4051: *UPDATE FOR ABS APPLICANTS*\\n',\n",
              " '\\n',\n",
              " '*MIM*: If you received email for next step, you will receive your interview email by next week. Lots of interviews are ongoing. If you neither received email for next step nor rejection, please send me your details.\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '*ABI:* Lot of people applied to MIM. They want to finish with MIM applicants before moving to ABI. If all things go well, you will be interviewed by ending of June. \\n',\n",
              " '\\n',\n",
              " '*QFM:* You will be interviewed by next month after ABI interview.\\n',\n",
              " '13/06/2024, 14:08 - ~\\u202fAfricanlady pinned a message\\n',\n",
              " \"13/06/2024, 14:24 - +234 703 564 7432: Please, people that didn't get email from the beginning, should we still  send in our details?\\n\",\n",
              " '13/06/2024, 14:27 - Mr jumah toheeb: professor Lex and Fatima. You are very lucky bro...\\n',\n",
              " '\\n',\n",
              " 'Hope you enjoy a wonderful conversation with them.\\n',\n",
              " '13/06/2024, 14:45 - Supreme UM6P: Sure üëç‚Ä¶ We had an interactive interview. I hope the result will be positive.\\n',\n",
              " \"13/06/2024, 16:30 - +234 806 798 4051: Yes, please be very sure you applied for the course. We had similar issues with a candidate, the admission team wasn't happy for the time being wasted.\\n\",\n",
              " '\\n',\n",
              " 'Full name, program applied for and email used to apply. <This message was edited>\\n',\n",
              " \"13/06/2024, 16:39 - Adeüëë‚úåüèΩ: *Hello everyone, just a heads up regarding your upcoming SCI interviews. If you're asked whether you've applied to other courses besides SCI, please feel free to answer truthfully. The interviewers may already have access to this information or be able to find out anyway, so it's best to be honest. Alternatively, you can also choose to exercise your discretion and answer in a way that feels comfortable for you. Good luck with your interviews!*\\n\",\n",
              " \"13/06/2024, 16:41 - +234 813 453 6479: What of those that hasn't received a mail yet, either positive or negative?\\n\",\n",
              " '13/06/2024, 18:55 - +234\\xa0915\\xa0211\\xa03859 changed to +234\\xa0706\\xa0653\\xa04141\\n',\n",
              " '14/06/2024, 10:01 - Meike: https://www.youtube.com/live/ZuEOdY_9WRY?si=LXCLmPomypKdlrd6\\n',\n",
              " '14/06/2024, 10:02 - Meike: PhD webinar , join now .\\n',\n",
              " '14/06/2024, 11:16 - +234 816 386 1179: Thanks\\n',\n",
              " '14/06/2024, 11:23 - Ahmed Salami UM6P: <Media omitted>\\n',\n",
              " '14/06/2024, 11:59 - +234 810 325 0021: Link plz?\\n',\n",
              " '14/06/2024, 12:10 - RightMinds um6p: This message was deleted\\n',\n",
              " '14/06/2024, 12:10 - RightMinds um6p: This message was deleted\\n',\n",
              " '14/06/2024, 14:52 - Paul Popoola UM6P: <Media omitted>\\n',\n",
              " '14/06/2024, 14:57 - +234 806 798 4051: ABI\\n',\n",
              " '14/06/2024, 15:04 - Mr Feja. Um6p: Congratulations\\n',\n",
              " '14/06/2024, 15:08 - Khalifa UM6P: Yes\\n',\n",
              " '14/06/2024, 15:35 - +234 903 081 7012: Congratulations!\\n',\n",
              " '14/06/2024, 15:51 - +234 903 737 6797: Congrat\\n',\n",
              " '14/06/2024, 15:51 - +234 903 737 6797: Congrat üéä\\n',\n",
              " '14/06/2024, 15:52 - +234 810 763 1480: Congratulations!üëç\\n',\n",
              " \"14/06/2024, 16:28 - +212 700-167603: Am I the only one who haven't received anything for ABI üôÉ\\n\",\n",
              " '14/06/2024, 16:28 - +234 810 763 1480: ‚úåÔ∏è\\n',\n",
              " '14/06/2024, 16:28 - Mirad: Same here oüíî\\n',\n",
              " '14/06/2024, 16:28 - +234 810 763 1480: Yet to receive too\\n',\n",
              " '14/06/2024, 16:40 - Supreme UM6P: Chill‚Ä¶ They just started sending mails\\n',\n",
              " '14/06/2024, 16:51 - +212 700-167603: Rejected fineüôÉ  üòÖ\\n',\n",
              " '14/06/2024, 16:52 - Mr Feja. Um6p: nah...it can be in batches\\n',\n",
              " '14/06/2024, 16:54 - +234 810 763 1480: Love letter\\n',\n",
              " 'Thank you everyone\\n',\n",
              " '*Till we all win*ü•∞\\n',\n",
              " '14/06/2024, 16:55 - +234 806 893 4852: Rejected fine\\n',\n",
              " '14/06/2024, 16:56 - +234 816 309 1201: Rejected, and we moveüòä <This message was edited>\\n',\n",
              " '14/06/2024, 17:01 - Meike: I thought you have SCi and MiM already yk üòÖ??\\n',\n",
              " '14/06/2024, 17:02 - +212 700-167603: Yes, but I need three of them so I can have one choice by the end. üòÇüòÇ\\n',\n",
              " '14/06/2024, 17:02 - +234 810 763 1480: <Media omitted>\\n',\n",
              " '14/06/2024, 17:03 - Joy: I know that feeling... its not even about having choice to make..\\n',\n",
              " '\\n',\n",
              " 'But that feeling that you made it in all....\\n',\n",
              " '\\n',\n",
              " 'There is the joy that comes with it...\\n',\n",
              " '14/06/2024, 17:04 - youngmusty7 UM6P: üòÖüòÖüòÖüòÖ\\n',\n",
              " '14/06/2024, 17:04 - Joy: Anyways you guys should just hope SCI and MIM interviews turns out and then you will have two to make a choice fromü§óü§ó\\n',\n",
              " '14/06/2024, 17:06 - +233 54 806 2428: We move together broüôèüèª\\n',\n",
              " '14/06/2024, 17:12 - +234 806 893 4852: This is my time\\n',\n",
              " '14/06/2024, 17:12 - +234 806 893 4852: I Quit\\n',\n",
              " '14/06/2024, 17:12 - +212 700-167603: Why?ü•≤\\n',\n",
              " '14/06/2024, 17:13 - +234 810 763 1480: Why?\\n',\n",
              " '14/06/2024, 17:13 - +234 810 763 1480: Be Encouraged Bro\\n',\n",
              " '14/06/2024, 17:13 - +234 810 763 1480: Beautiful thing will happen again ü•∞\\n',\n",
              " \"14/06/2024, 17:14 - +234 806 798 4051: You don't have to. @\\u2068Mr Obasanjo Fajemirokun UM6P\\u2069 will tell you how many rejections he had.\\n\",\n",
              " '15/06/2024, 18:12 - +234 806 798 4051: Hello, please the person that spoke with me about Green Bee should chat me.\\n',\n",
              " '15/06/2024, 18:15 - +234 806 798 4051: On choice of language to be used for interview\\n',\n",
              " '15/06/2024, 18:18 - +234 802 688 1539: @\\u2068~Africanlady\\u2069 with your experience from UM6P and other scholars.\\n',\n",
              " '\\n',\n",
              " 'Is there a way recommendation letters could be submitted to UM6P from the recommender themselves as against writing it and giving it to you to upload by yourself.\\n',\n",
              " '\\n',\n",
              " 'Thank you\\n',\n",
              " '15/06/2024, 18:21 - +234 806 798 4051: Some schools prefer the recommendation letter to be uploaded by the applicants while some prefer the professor or whoever to upload themselves.\\n',\n",
              " '15/06/2024, 18:42 - +234 802 688 1539: Game theory centre.\\n',\n",
              " '\\n',\n",
              " 'My recommender prefer sending it across though.\\n',\n",
              " '15/06/2024, 18:42 - +234 802 688 1539: Thank you\\n',\n",
              " '15/06/2024, 19:58 - Mr jumah toheeb: It is understandable, I was in the same situation sometimes back.\\n',\n",
              " '\\n',\n",
              " 'You just have to plead with your recommender, that Um6p format is for candidate to upload it, themselves.\\n',\n",
              " '\\n',\n",
              " 'And try to persuade him, but if the person insist. The best options is to look out for someone else; and keep the contact with them for other applications.\\n',\n",
              " '15/06/2024, 19:59 - Acquah Nana Yeboah: I suggest you use another person.\\n',\n",
              " '15/06/2024, 20:59 - +234 802 688 1539: Thank you\\n',\n",
              " '15/06/2024, 20:59 - +234 802 688 1539: Thanks\\n',\n",
              " '16/06/2024, 18:49 - +234 814 360 5662 joined using a group link.\\n',\n",
              " '17/06/2024, 04:26 - +212 605-634882 joined using a group link.\\n',\n",
              " '17/06/2024, 14:09 - +234 704 413 6854: Slm\\n',\n",
              " '17/06/2024, 14:11 - +234 810 498 8022: Waliekum salam\\n',\n",
              " '17/06/2024, 14:14 - +234 806 612 7153: Slm\\n',\n",
              " '19/06/2024, 19:49 - ~\\u202fRidwan Ibidunni added ~\\u202fThaabitah Ibidunni\\n',\n",
              " '21/06/2024, 16:59 - iWAHABüéá UM6P: <Media omitted>\\n',\n",
              " '21/06/2024, 16:59 - iWAHABüéá UM6P: Just got this famsü©∑\\n',\n",
              " '21/06/2024, 16:59 - iWAHABüéá UM6P: Please who has the English version\\n',\n",
              " '21/06/2024, 17:00 - Meike: I will share the English versions tonight \\n',\n",
              " 'If you can wait till then .\\n',\n",
              " '\\n',\n",
              " 'Thank you\\n',\n",
              " '21/06/2024, 17:01 - iWAHABüéá UM6P: Thanks\\n',\n",
              " '21/06/2024, 17:01 - +234 813 907 1216: Use Google lens\\n',\n",
              " '21/06/2024, 17:03 - Meike: yeah exactly\\n',\n",
              " '21/06/2024, 17:03 - Meike: <Media omitted>\\n',\n",
              " '21/06/2024, 17:04 - Meike: i hope this can help as well\\n',\n",
              " '21/06/2024, 17:05 - iWAHABüéá UM6P: 100‚úÖ\\n',\n",
              " '21/06/2024, 17:05 - iWAHABüéá UM6P: Thanks\\n',\n",
              " '21/06/2024, 17:07 - Meike: Anytime and please take your time when filing the forms üôèüèªif you don‚Äôt understand anything just ask .\\n',\n",
              " '21/06/2024, 17:08 - youngmusty7 UM6P: Which form boss\\n',\n",
              " '21/06/2024, 17:11 - +234 813 907 1216: You received it through email??\\n',\n",
              " '21/06/2024, 17:12 - Meike: Wetin be boss ? üòÇüòÇüòÇabeg \\n',\n",
              " '\\n',\n",
              " 'As said in the mail you received today , there will be portal to upload these documents but before then , you will need to fill some informations and please be attentive when doing so .. \\n',\n",
              " '\\n',\n",
              " 'Thank you\\n',\n",
              " '21/06/2024, 17:12 - iWAHABüéá UM6P: Yes\\n',\n",
              " '21/06/2024, 17:13 - +234 813 907 1216: SCI?üòØ\\n',\n",
              " \"I think it's a sign of being selected for admission üòØ\\n\",\n",
              " '21/06/2024, 17:14 - iWAHABüéá UM6P: No\\n',\n",
              " '\\n',\n",
              " 'MIM\\n',\n",
              " '21/06/2024, 17:14 - +234 813 907 1216: Ohhhh\\n',\n",
              " \"It's still a good sign\\n\",\n",
              " '21/06/2024, 17:19 - youngmusty7 UM6P: Not SCI oo\\n',\n",
              " '21/06/2024, 17:20 - +234 813 907 1216: OhhhhüòÖ\\n',\n",
              " '21/06/2024, 17:21 - youngmusty7 UM6P: Yes bro\\n',\n",
              " '21/06/2024, 17:35 - +234 810 498 8022: Hello guys\\n',\n",
              " 'Please who has received mail for the agribusiness interview?\\n',\n",
              " '21/06/2024, 17:52 - +212 700-167603: Not necessarily\\n',\n",
              " '21/06/2024, 18:12 - +234 813 907 1216: üôÜüèΩ\\u200d‚ôÇÔ∏è\\n',\n",
              " '21/06/2024, 18:34 - Joy: Lol... Allow the person hope na...ü§£ü§£ü§£ü§£ü§£\\n',\n",
              " '21/06/2024, 18:34 - Joy: You wanna kill the hope??\\n',\n",
              " \"21/06/2024, 18:36 - +212 700-167603: No, no, I'm not üòÇüòÇüòÇüòÇ, but everyone can still receive it.\\n\",\n",
              " '21/06/2024, 19:17 - +234 703 550 1372: All these stress for worldly stuffs ooo üòÇ \\n',\n",
              " 'God help us üôè\\n',\n",
              " '21/06/2024, 19:20 - +212\\xa0601-995145 changed to +212\\xa0707-622025\\n',\n",
              " \"21/06/2024, 20:48 - Joy: Just checked my mail sef I got same mail since 4....but I don't understand it.... I have not done interview on MIM or Agribusiness \\n\",\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Only SCI\\n',\n",
              " '21/06/2024, 21:08 - Dr. Shegz SCI M2: Be hopeful üí™\\n',\n",
              " \"21/06/2024, 21:24 - Khalifa UM6P: They said it's starting by 24th of June\\n\",\n",
              " '22/06/2024, 20:13 - Abdulmajid Babale: Hello Guys\\n',\n",
              " '\\n',\n",
              " 'Please is there anyone that received a mail for School of Hospitality and Business Management Exams (Undergraduate) ?\\n',\n",
              " '22/06/2024, 20:29 - +234 816 245 7781: No from my side.\\n',\n",
              " 'Did you?\\n',\n",
              " '22/06/2024, 20:30 - Abdulmajid Babale: Yeah. Someone did\\n',\n",
              " '22/06/2024, 20:36 - +234 806 612 7153: I did\\n',\n",
              " '22/06/2024, 20:37 - +234 806 612 7153: I have done it, na current affairs them asked past and stuff about the school and me no know any current except charge/time j√†re\\n',\n",
              " '22/06/2024, 20:37 - Abdulmajid Babale: They sent another mail last week\\n',\n",
              " '22/06/2024, 20:37 - Abdulmajid Babale: For a second exam\\n',\n",
              " '22/06/2024, 20:55 - +234 808 392 8655: Yes they did\\n',\n",
              " '22/06/2024, 20:56 - +234 808 392 8655: Did you have any materials that will help to prepare\\n',\n",
              " '23/06/2024, 16:21 - +234 813 907 1216: Did anyone receive an email regarding the Agribusiness and Innovation interview????\\n',\n",
              " '23/06/2024, 16:28 - Supreme UM6P: Yes\\n',\n",
              " '23/06/2024, 16:28 - Supreme UM6P: The interview is starting from tomorrow\\n',\n",
              " '23/06/2024, 16:33 - +234 813 907 1216: üòØüòØ\\n',\n",
              " '23/06/2024, 16:34 - +234 815 675 4199: Quite alright. But have you gotten any mail regarding the link and date for the interview?\\n',\n",
              " '23/06/2024, 16:38 - Supreme UM6P: Yes\\n',\n",
              " '23/06/2024, 16:58 - +234 815 675 4199: Wow\\n',\n",
              " '23/06/2024, 17:10 - Supreme UM6P: Who is having their ABI interview tomorrow?\\n',\n",
              " '23/06/2024, 18:26 - Muhammad Sani UM6P WL: \\n',\n",
              " '23/06/2024, 18:26 - Muhammad Sani UM6P WL: This is the last email I recieved. No link attached. Is it just me or it‚Äôs every one.? <This message was edited>\\n',\n",
              " \"23/06/2024, 18:28 - Adeüëë‚úåüèΩ: Means you haven't been scheduled yet, there's a second mail.\\n\",\n",
              " '23/06/2024, 18:29 - Muhammad Sani UM6P WL: Ok I understand. When did you guys received yours?\\n',\n",
              " '23/06/2024, 18:32 - Adeüëë‚úåüèΩ: Friday\\n',\n",
              " '24/06/2024, 03:59 - Muhammad Sani UM6P WL: Ok thsnks\\n',\n",
              " '24/06/2024, 08:06 - +234 810 854 3421: \\n',\n",
              " '24/06/2024, 15:06 - +234 806 798 4051: https://docs.google.com/forms/d/1QIUP6LtodEHpO00WMLTYHPaLeFwEVaEcow4uL8LoLwU/viewform?ts=66797c23&edit_requested=true\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Dear all, \\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Kindly help to fill the attached survey. Thanks.\\n',\n",
              " '24/06/2024, 15:13 - youngmusty7 UM6P: Done\\n',\n",
              " '24/06/2024, 15:26 - Ahmed Salami UM6P: Done!\\n',\n",
              " '24/06/2024, 15:36 - Joy: Done\\n',\n",
              " '24/06/2024, 18:09 - +234 810 498 8022: Good evening guys,\\n',\n",
              " 'Please who did  Agribusiness interview today?\\n',\n",
              " '24/06/2024, 18:33 - +212 661-506649: Good evening guys any news for the results of green building and energy efficiency??\\n',\n",
              " '24/06/2024, 18:33 - +212 661-506649: Master\\n',\n",
              " '24/06/2024, 20:32 - +212 713-402368: https://cedoc.um6p.ma/applications\\n',\n",
              " \"24/06/2024, 22:45 - +234 813 971 5677: Good evening, please I don't know if this question has been answered before:\\n\",\n",
              " '\\n',\n",
              " 'Does UM6P offer direct PhD. <This message was edited>\\n',\n",
              " '24/06/2024, 22:51 - +234 813 020 7733: <Media omitted>\\n',\n",
              " '25/06/2024, 00:04 - Ahmed Salami UM6P: No B.Sc to PhD application, you need an M.S to apply to virtually all the PhD programs.\\n',\n",
              " '25/06/2024, 00:07 - +234 706 069 7495: Some Universities offer direct P.hD without M.Sc. Provided you meet their requirements\\n',\n",
              " '25/06/2024, 00:08 - +234 706 069 7495: <Media omitted>\\n',\n",
              " '25/06/2024, 00:09 - +234 706 069 7495: Should incase you have interest..\\n',\n",
              " '\\n',\n",
              " 'Kick start immediately. \\n',\n",
              " 'All the best\\n',\n",
              " '25/06/2024, 00:10 - +234 813 971 5677: Thank you so much ü•πüôèüèæ\\n',\n",
              " '25/06/2024, 00:11 - Ahmed Salami UM6P: Hold your IELTS and GRE for hand!\\n',\n",
              " '25/06/2024, 10:05 - Supreme UM6P: I keep getting you‚Äôre denied access to the meeting\\n',\n",
              " '25/06/2024, 10:05 - Supreme UM6P: What could be the cause and solution?\\n',\n",
              " '25/06/2024, 10:06 - Supreme UM6P: Anybody please?\\n',\n",
              " '25/06/2024, 10:06 - Supreme UM6P: My interview time has started\\n',\n",
              " '25/06/2024, 10:09 - +91 70225 80990: My interview starts in an hour\\n',\n",
              " '25/06/2024, 10:09 - pastor DAN: Are you using your phone or laptop?\\n',\n",
              " '25/06/2024, 10:10 - iWAHABüéá UM6P: Were you given case study\\n',\n",
              " '25/06/2024, 10:11 - +91 70225 80990: Mim or Agri??\\n',\n",
              " '25/06/2024, 10:11 - iWAHABüéá UM6P: Agric\\n',\n",
              " '25/06/2024, 10:11 - +91 70225 80990: Oh \\n',\n",
              " 'I don‚Äôt know\\n',\n",
              " '25/06/2024, 10:25 - Supreme UM6P: I‚Äôm done. It was a success.\\n',\n",
              " '25/06/2024, 10:26 - +234 810 498 8022: Success\\n',\n",
              " '25/06/2024, 10:28 - Khalifa UM6P: How was it, how was the questions??\\n',\n",
              " '25/06/2024, 16:41 - +212 700-167603: Do guys know when they will issue results? MIM and CI\\n',\n",
              " '25/06/2024, 17:07 - +234 807 717 9932: Before July ending probably\\n',\n",
              " '25/06/2024, 17:58 - +234 813 051 4041: *2024 NNPC/NAOC/OANDO Scholarship*\\n',\n",
              " '\\n',\n",
              " '(i) NNPC in partnership with NAOC & OANDO invites students to apply for its 2024 Scholarship program.\\n',\n",
              " '\\n',\n",
              " '(ii) This scholarship is available for Nigeria students\\n',\n",
              " '\\n',\n",
              " '(iii) This scholarship offers ‚Ç¶200,000 per year\\n',\n",
              " '\\n',\n",
              " '(iv) The deadline for application is June 30, 2024\\n',\n",
              " '\\n',\n",
              " '‚ö°How to Apply\\n',\n",
              " '(i) Visit https://www.scholarshipregion.com/nnpc-naoc-oando-scholarship/ to learn more about this opportunity and apply.\\n',\n",
              " '\\n',\n",
              " '(ii) Remember to share with friends and family. Best of luck!\\n',\n",
              " '\\n',\n",
              " '*üéôÔ∏èSOURCE: Scholarship Region*\\n',\n",
              " '25/06/2024, 19:27 - +234 706 069 7495: Hi, sorry, wanna drop some useful opportunities if you guys no mind\\n',\n",
              " '\\n',\n",
              " 'Can I ?\\n',\n",
              " '25/06/2024, 19:28 - +212 713-402368: Is it on scholarship? If yes you can if no, please share it somewhere else\\n',\n",
              " '25/06/2024, 19:30 - +234 706 069 7495: <Media omitted>\\n',\n",
              " '25/06/2024, 19:30 - +234 706 069 7495: <Media omitted>\\n',\n",
              " '25/06/2024, 19:30 - +234 706 069 7495: <Media omitted>\\n',\n",
              " '25/06/2024, 19:30 - +234 706 069 7495: <Media omitted>\\n',\n",
              " '25/06/2024, 19:30 - +234 706 069 7495: <Media omitted>\\n',\n",
              " '25/06/2024, 19:30 - +234 706 069 7495: <Media omitted>\\n',\n",
              " '25/06/2024, 19:30 - +234 706 069 7495: <Media omitted>\\n',\n",
              " '25/06/2024, 19:30 - +234 706 069 7495: <Media omitted>\\n',\n",
              " '25/06/2024, 19:30 - +234 706 069 7495: <Media omitted>\\n',\n",
              " '25/06/2024, 19:30 - +234 706 069 7495: <Media omitted>\\n',\n",
              " '25/06/2024, 19:30 - +234 706 069 7495: <Media omitted>\\n',\n",
              " '25/06/2024, 19:30 - +234 706 069 7495: <Media omitted>\\n',\n",
              " '25/06/2024, 19:30 - +234 706 069 7495: <Media omitted>\\n',\n",
              " '25/06/2024, 19:30 - +234 706 069 7495: <Media omitted>\\n',\n",
              " '25/06/2024, 19:30 - +234 706 069 7495: <Media omitted>\\n',\n",
              " '25/06/2024, 19:30 - +234 706 069 7495: <Media omitted>\\n',\n",
              " '25/06/2024, 19:30 - +234 706 069 7495: <Media omitted>\\n',\n",
              " '25/06/2024, 19:30 - +234 706 069 7495: <Media omitted>\\n',\n",
              " '25/06/2024, 19:30 - +234 706 069 7495: <Media omitted>\\n',\n",
              " '25/06/2024, 19:30 - +234 706 069 7495: <Media omitted>\\n',\n",
              " '25/06/2024, 19:30 - +234 706 069 7495: <Media omitted>\\n',\n",
              " '25/06/2024, 19:30 - +234 706 069 7495: <Media omitted>\\n',\n",
              " '25/06/2024, 19:30 - +234 706 069 7495: <Media omitted>\\n',\n",
              " '25/06/2024, 22:01 - +233 55 430 5337: How was it\\n',\n",
              " '25/06/2024, 23:57 - +234 813 971 5677: All the best.\\n',\n",
              " '26/06/2024, 05:56 - Meike: https://youtu.be/beIS8QsYb3o?si=4RGwWTP6IYW13q4D \\n',\n",
              " '\\n',\n",
              " 'To those who may be interested in joining the African consulting club at UM6p watch this.\\n',\n",
              " '26/06/2024, 06:06 - Acquah Nana Yeboah: Non students can join?\\n',\n",
              " '26/06/2024, 17:19 - Joy: <Media omitted>\\n',\n",
              " '26/06/2024, 17:21 - Abdulmajid Babale: Congratulations\\n',\n",
              " '26/06/2024, 17:22 - Kehinde Olawale Victoria UM6P: Congratulations!!!ü•≥ü•≥ü•≥\\n',\n",
              " '26/06/2024, 17:24 - Rawphy@. UM6P: Stay calm for now \\n',\n",
              " '\\n',\n",
              " 'Congratulations üéâ\\n',\n",
              " '26/06/2024, 17:24 - Abdulmajid Babale: That will not be a problem\\n',\n",
              " '26/06/2024, 17:25 - +234 813 440 6883: Congratulations üéâ Joy\\n',\n",
              " '26/06/2024, 17:26 - Mr Obasanjo Fajemirokun UM6P: CI applicants check your emails\\n',\n",
              " '26/06/2024, 17:30 - +212 713-402368: Congratulations forget the payment scholars here will help you on how to go about it‚Ä¶\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Just a quick one to point out is that you don‚Äôt have to pay anyone for anything. If anyone comes to your dm and ask you to pay him/her shishi report d person here‚Ä¶.\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Congratulations in advance to those expectin their results\\n',\n",
              " '26/06/2024, 17:31 - +212 700-167603: Does not receiving an email mean something negative?\\n',\n",
              " '26/06/2024, 17:34 - Mr Obasanjo Fajemirokun UM6P: Just be patient \\n',\n",
              " '\\n',\n",
              " 'Everyone will receive either a congratulation email or a love letter.\\n',\n",
              " '26/06/2024, 17:34 - +234 810 139 9774: Pray against the love letter\\n',\n",
              " \"26/06/2024, 17:36 - +212 700-167603: It will not be rejection this time; it's a waiting list.\\n\",\n",
              " '26/06/2024, 17:36 - Mr Obasanjo Fajemirokun UM6P: Amen.\\n',\n",
              " '\\n',\n",
              " 'We hope to see you all in Morocco. Just have faith, pray and wait.\\n',\n",
              " \"26/06/2024, 17:38 - +234 806 798 4051: Don't worry we will discuss it. I will create another group once the admission team sends me the names of a the accepted students.\\n\",\n",
              " '\\n',\n",
              " 'Congratulations bae\\n',\n",
              " '26/06/2024, 17:44 - +234 806 798 4051: As you receive your letter, start looking for flight money. The school administrative requested you guys arrive in batches for easy logistics.\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " '*Late resumption is highly discouraged.*\\n',\n",
              " '\\n',\n",
              " \"We can't wait to see you guys soon.\\n\",\n",
              " '26/06/2024, 17:46 - +234 806 798 4051: *I might not wait for the list, send me your acceptance letter privately to take you to the other group.*\\n',\n",
              " '26/06/2024, 17:47 - Joy: ü§óü§óThank you\\n',\n",
              " '26/06/2024, 17:48 - Deborah A. UM6P: Congratulations üéâ\\n',\n",
              " '26/06/2024, 17:55 - +234 810 721 8361: Congratulations!ü•≥ü•≥üéâ\\n',\n",
              " '\\n',\n",
              " 'The same email changed my life 3 years ago. Welcome to a new dispensation üôèüèΩ\\n',\n",
              " '26/06/2024, 17:57 - CAPESTONE ROYAL COMPANY: üôåüèøüôåüèø\\n',\n",
              " '26/06/2024, 17:58 - +234 806 798 4051: Same here too\\n',\n",
              " '26/06/2024, 18:18 - +234 810 498 8022: Congratulations üéâ\\n',\n",
              " '26/06/2024, 18:19 - +234 815 675 4199: Congratulations üéâüéâüéâ\\n',\n",
              " '26/06/2024, 18:21 - Sanda taiwo: The rest that have gotten theirs should share the good news too \\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " \"Don't be shy üòä\\n\",\n",
              " '26/06/2024, 18:23 - +234 806 798 4051: Yeah, and those that have multiple, quickly make your choice and reject the rest\\n',\n",
              " '26/06/2024, 18:25 - Mr Obasanjo Fajemirokun UM6P: Let‚Äôs not forget, when rejecting a course of study (due to double offer), you can nominate someone else for it.\\n',\n",
              " '26/06/2024, 18:26 - +234 810 139 9774: The nomination dey work?\\n',\n",
              " '26/06/2024, 18:26 - Sanda taiwo: Yes (Someone on the waiting list)\\n',\n",
              " '\\n',\n",
              " '\\n',\n",
              " \"Because some would get a mail that they're on the waiting list\\n\",\n",
              " '26/06/2024, 18:26 - Dr. Shegz SCI M2: Congratulations üëè\\n',\n",
              " '26/06/2024, 18:28 - +234 813 453 6479: Any update on this pls\\n',\n",
              " '26/06/2024, 18:39 - +234 810 565 5888: Congratulations\\n',\n",
              " '26/06/2024, 18:42 - +234 906 074 1911: Congratulations üéâüéâ\\n',\n",
              " '26/06/2024, 18:50 - +234 813 907 1216: <Media omitted>\\n',\n",
              " '26/06/2024, 18:50 - +234 810 565 5888: Got this too.\\n',\n",
              " '26/06/2024, 18:51 - +234 813 907 1216: üòØüòØüòØ\\n',\n",
              " '26/06/2024, 18:54 - +212 700-167603: What happened\\n',\n",
              " \"26/06/2024, 18:56 - +234 813 907 1216: They said that they will initiate and conclude the selection process for master's in financial engineering in July\\n\",\n",
              " '26/06/2024, 19:37 - youngmusty7 UM6P: <Media omitted>\\n',\n",
              " '26/06/2024, 19:38 - +234 810 565 5888: Congratulations\\n',\n",
              " '26/06/2024, 19:38 - Dr. Shegz SCI M2: Congratulations brother, welcome to the family\\n',\n",
              " '26/06/2024, 19:39 - +234 813 907 1216: ü•≥ü•≥\\n',\n",
              " 'Congrats oga mustyü•≥üòÅ\\n',\n",
              " '26/06/2024, 19:40 - Abdurrahman Badmus: Congratulations\\n',\n",
              " '26/06/2024, 19:41 - Abdulghaniyy JIMOHüë®\\u200düíª: This message was deleted\\n',\n",
              " \"26/06/2024, 19:41 - Abdulghaniyy JIMOHüë®\\u200düíª: @\\u2068~OLANREWAJU\\u2069 if may get this correctly, it means there are some people asking money from potential scholars. Please if that happened to you immediately report the person then we'll take up from there. üôè\\n\",\n",
              " \"26/06/2024, 19:48 - CAPESTONE ROYAL COMPANY: I don't think so, it might be SCI fee, I think @\\u2068~Africanlady\\u2069 will handle that\\n\",\n",
              " '26/06/2024, 19:53 - Funtua UM6P: Congratulations boss\\n',\n",
              " '26/06/2024, 19:54 - iWAHABüéá UM6P: Congratulations scholars\\n',\n",
              " '26/06/2024, 19:56 - +234 810 498 8022: Congratulations\\n',\n",
              " '26/06/2024, 20:01 - +234 806 798 4051: Start looking for flight money, congratulations\\n',\n",
              " '26/06/2024, 20:06 - +234 806 444 8972: Congratulations\\n',\n",
              " '26/06/2024, 20:08 - +234 816 882 6319: I just love this atmosphere. You guys are fantastic. I have been observing how things run here. *I am coming next year* üôè\\n',\n",
              " \"26/06/2024, 20:08 - +212 700-167603: Just to explain, for us as Moroccans, we pay that tuition fee without exception. If the administration asks for it, you should pay. If you, as international students, will be exempted, that's another matter.\\n\",\n",
              " '26/06/2024, 20:11 - +234 816 724 6433: Congratulations to you all\\n',\n",
              " '26/06/2024, 20:12 - CAPESTONE ROYAL COMPANY: Thanks for your explanation and I understand perfectly\\n',\n",
              " '26/06/2024, 20:13 - +212 713-402368: My oga, I needed to state that because we have seen incidence in the past where people are been extorted. So my reason sir. \\n',\n",
              " '\\n',\n",
              " 'Because this is the time when the bad eggs will want to exploit people.\\n',\n",
              " '\\n',\n",
              " 'The 5000MAD payment always raise issue but for international students it is always sorted easily without issues\\n',\n",
              " '26/06/2024, 20:13 - +212 713-402368: Once the successful applicants all got their mails, they will be notified on how to proceed\\n',\n",
              " '26/06/2024, 20:21 - Abdulmajid Babale: I think even for Moroccan Students there will be a refund if you are on scholarship since your scholarship will cover the 5000 application fee\\n',\n",
              " \"26/06/2024, 20:22 - +212 700-167603: Yes, we do have a refund policy, but we pay for it. That's what I saw.\\n\",\n",
              " '26/06/2024, 20:23 - +234 703 550 1372: Wait, is it that scholarship or not, you pay first before the refund or how?\\n',\n",
              " '26/06/2024, 20:23 - +212 700-167603: Before applying to scholarship\\n',\n",
              " '26/06/2024, 20:24 - +234 703 550 1372: Okay, understood üëå\\n',\n",
              " '26/06/2024, 20:29 - +234 806 798 4051: Exactly, my mates were refunded.\\n',\n",
              " '\\n',\n",
              " \"@\\u2068Mehdi SCI\\u2069 bought laptop with his money. I like finding Mehdi's troubleüòÄ <This message was edited>\\n\",\n",
              " \"26/06/2024, 20:29 - CAPESTONE ROYAL COMPANY: @\\u2068~Ouissal\\u2069 , you don't have to keep repeating this, @\\u2068~Africanlady\\u2069 will handle this, It will spark more curiosity and some people might not understand the dynamic behind it.\\n\",\n",
              " '26/06/2024, 20:30 - Abdulmajid Babale: Yeah. All our mates were refunded too\\n',\n",
              " '26/06/2024, 20:31 - +234 806 798 4051: Exactly, so let everyone stay calm.\\n',\n",
              " '\\n',\n",
              " \"Get your letters and face the scholarship application. You will soon know why I'm laughing ü§£\\n\",\n",
              " '26/06/2024, 20:31 - +212 700-167603: I Just explained, not repeating ü´† <This message was edited>\\n',\n",
              " '26/06/2024, 20:39 - +234 807 717 9932: Hmmmm, for the laughter\\n',\n",
              " 'E get why truly üòÇ\\n',\n",
              " '26/06/2024, 20:40 - +234 809 999 7884: Congrats guys\\n',\n",
              " '26/06/2024, 20:46 - Abdulghaniyy JIMOHüë®\\u200düíª: Hello everyone just to mention to you all that got admitted. Listen üëÇ to your ambassador the University has choose them to guide you. @\\u2068~Africanlady\\u2069 will be guide likewise other senior scholars in group\\n',\n",
              " '26/06/2024, 20:48 - Abdulghaniyy JIMOHüë®\\u200düíª: The tradition is after all has received their admission notification, you will be automatically filter into a fresh group immediately. Then scholarship info goes there only international students whose scholarship documents might be complicated sometimes.\\n',\n",
              " '26/06/2024, 21:11 - Abdulghaniyy JIMOHüë®\\u200düíª: My boss @\\u2068~OLANREWAJU\\u2069 Jazakumllahi Khairan for mentioning this. The University has zero tolerance for this, I hope if anyone is reported who extort anyone the international community will take up the normal due procedure will be followed. I hope anyone planning to extort anyone the management will arrange accordingly.\\n',\n",
              " '26/06/2024, 21:11 - youngmusty7 UM6P: Thank you so much to everyone who has congratulated me! Your kind words mean a lot to me and have made this moment even more special. I truly appreciate your support and encouragement. üôèüôè\\n',\n",
              " '26/06/2024, 21:16 - Khalifa UM6P: Congrats Musty\\n',\n",
              " '26/06/2024, 21:16 - youngmusty7 UM6P: Thanks boss\\n',\n",
              " '26/06/2024, 21:18 - youngmusty7 UM6P: Congratulations @\\u2068Joy\\u2069\\n',\n",
              " '26/06/2024, 21:44 - +234 818 676 8841: Congratulations to the winners\\n',\n",
              " '26/06/2024, 22:32 - +234 902 700 2352: Congratulations ooh\\n',\n",
              " '27/06/2024, 04:40 - +233 55 430 5337: Great\\n',\n",
              " '27/06/2024, 04:40 - +233 55 430 5337: Greatest\\n',\n",
              " '27/06/2024, 06:06 - +234 813 527 3299: Congratulations üéâ\\n',\n",
              " '27/06/2024, 06:08 - +234 813 527 3299: Congratulations broüéâ\\n',\n",
              " '27/06/2024, 09:03 - +91 70225 80990: Is there anyone having their interview today?\\n',\n",
              " '27/06/2024, 11:06 - +234 703 713 0747: <Media omitted>\\n',\n",
              " '27/06/2024, 11:07 - +234 703 713 0747: Does this mean the Baccalaureate have been shortlisted?\\n',\n",
              " '27/06/2024, 11:10 - Abdulmajid Babale: This is for Moroccans only\\n',\n",
              " \"27/06/2024, 11:11 - Abdulmajid Babale: Because at the time of application those that are in the final year of their baccalaureate (High School) don't have their results\\n\",\n",
              " '27/06/2024, 11:16 - +234 703 713 0747: Okay, thank you.\\n',\n",
              " '27/06/2024, 11:44 - Oluwafemi Joseph: <Media omitted>\\n',\n",
              " \"27/06/2024, 11:46 - +234 807 717 9932: Proceed in preparing your scholarship documents as you have high chances of being offered admission... But currently, you're on waiting list\\n\",\n",
              " '27/06/2024, 11:47 - +234 806 470 9454: You have pending documents to submit\\n',\n",
              " '27/06/2024, 11:49 - Mr Feja. Um6p: Congratulation rain is about to fall... Stay positive\\n',\n",
              " '27/06/2024, 13:35 - Funtua UM6P: Same here\\n',\n",
              " '27/06/2024, 23:01 - +234 806 612 7153: Please I need an academic CV sampl;e\\n',\n",
              " '27/06/2024, 23:03 - +20 11 13952521: Open cv flow\\n',\n",
              " '27/06/2024, 23:04 - +20 11 13952521: You will build perfect one by Ai\\n',\n",
              " '27/06/2024, 23:16 - +234 806 612 7153: Thanks so much brother\\n',\n",
              " '28/06/2024, 12:27 - +212 700-167603: Hello everyone, I have an urgent request. Does anyone know a contact for the admissions office for undergraduate programs, such as medicine? I need to resolve an issue with the portal. Thank you!\\n',\n",
              " '28/06/2024, 12:29 - +234 816 245 7781: I recieved it also\\n',\n",
              " '28/06/2024, 12:38 - +212 700-167603: .\\n',\n",
              " '28/06/2024, 13:07 - +243 814 114 208: Same here.\\n',\n",
              " '29/06/2024, 08:04 - +212 713-701881: @\\u2068Joy\\u2069, please, find the scholarship documents on your application portal?\\n',\n",
              " ' (ANNEX BOURSE FIRSI)\\n',\n",
              " 'Other`s are not showing.\\n',\n",
              " '29/06/2024, 09:57 - Joy: Have not logged in... trying to...\\n',\n",
              " 'Good morning  to you\\n',\n",
              " '29/06/2024, 10:16 - +212 713-701881: Good morning Jhay.\\n',\n",
              " 'Kindly feedback when you do.\\n',\n",
              " '29/06/2024, 10:25 - Joy: Nothing is showing but are you done filling the details? Maybe the documents u r to upload will show once u r done\\n',\n",
              " '29/06/2024, 10:55 - +212 713-701881: I see. Let me try that. Thanks Jhay.\\n',\n",
              " '30/06/2024, 08:32 - +234\\xa0808\\xa0135\\xa04896 changed to +234\\xa0915\\xa0444\\xa02194\\n',\n",
              " '30/06/2024, 18:47 - +234 817 761 6519 joined using a group link.\\n',\n",
              " '30/06/2024, 18:57 - +234 806 798 4051: Hello, those gotten their SCI acceptance or waiting list email should chat me. I cant trace those that did some days ago\\n',\n",
              " '30/06/2024, 19:49 - +234 810 860 1080 joined using a group link.\\n',\n",
              " '30/06/2024, 19:49 - +234 903 802 7822 joined using a group link.\\n',\n",
              " '30/06/2024, 19:50 - +234 903 540 5537 joined using a group link.\\n',\n",
              " '30/06/2024, 19:51 - +234 703 010 8407 joined using a group link.\\n',\n",
              " '30/06/2024, 19:51 - +234 803 714 7816 joined using a group link.\\n',\n",
              " '30/06/2024, 19:51 - +234 706 886 1006 joined using a group link.\\n',\n",
              " '30/06/2024, 19:52 - +234 802 860 2889 joined using a group link.\\n',\n",
              " '30/06/2024, 19:53 - +234 916 130 6777 joined using a group link.\\n',\n",
              " '30/06/2024, 19:56 - +234 810 860 1080: Is this scholarship currently open for undergraduate?\\n',\n",
              " '30/06/2024, 20:05 - +234 810 955 2001 joined using a group link.\\n',\n",
              " '30/06/2024, 20:08 - +234 805 714 9875 joined using a group link.\\n',\n",
              " '30/06/2024, 20:09 - +234 706 643 5174 joined using a group link.\\n',\n",
              " '30/06/2024, 20:22 - +234 803 298 2843 joined using a group link.\\n',\n",
              " '30/06/2024, 23:11 - +234 902 700 2352: Please I need the email address of admission department for the School of Collective Intelligence\\n',\n",
              " '30/06/2024, 23:11 - +234 902 700 2352: My sister is finding it difficult to upload the required documents for the scholarship\\n',\n",
              " '30/06/2024, 23:25 - +212 700-167603: Ci admission@um6p.ma\\n',\n",
              " '30/06/2024, 23:50 - +234 902 700 2352: The Ci is separate?\\n',\n",
              " '01/07/2024, 06:59 - +234 706 069 7495: <Media omitted>\\n',\n",
              " '01/07/2024, 06:59 - +234 706 069 7495: <Media omitted>\\n',\n",
              " '01/07/2024, 06:59 - +234 706 069 7495: <Media omitted>\\n',\n",
              " '01/07/2024, 07:00 - +234 706 069 7495: <Media omitted>\\n',\n",
              " '01/07/2024, 07:01 - +234 706 069 7495: <Media omitted>\\n',\n",
              " '01/07/2024, 07:01 - +234 706 069 7495: <Media omitted>\\n',\n",
              " '01/07/2024, 07:02 - +234 706 069 7495: <Media omitted>\\n',\n",
              " '01/07/2024, 07:02 - +234 706 069 7495: <Media omitted>\\n',\n",
              " '01/07/2024, 07:03 - +234 706 069 7495: <Media omitted>\\n',\n",
              " '01/07/2024, 07:04 - +234 706 069 7495: <Media omitted>\\n',\n",
              " '01/07/2024, 14:14 - Golden Wheels Consults Ltd: <Media omitted>\\n',\n",
              " \"01/07/2024, 14:15 - +212 700-167603: It's not for youuuu\\n\",\n",
              " '01/07/2024, 14:15 - +234 813 453 6479: I also received same\\n',\n",
              " '01/07/2024, 14:16 - +234 813 453 6479: Any hope?\\n',\n",
              " '01/07/2024, 14:16 - +212 700-167603: Did Abs(mim) send any emails?\\n',\n",
              " '01/07/2024, 14:16 - Farhan...IDUNU: This message was deleted\\n',\n",
              " \"01/07/2024, 14:17 - +212 700-167603: Guys it's for undergraduate students ignore\\n\",\n",
              " '01/07/2024, 14:17 - Golden Wheels Consults Ltd: Okay\\n',\n",
              " '01/07/2024, 14:31 - +234 703 564 7432: OKAY\\n',\n",
              " '01/07/2024, 14:45 - +234 809 600 3499: Same with me\\n',\n",
              " '01/07/2024, 14:46 - +234 809 600 3499: <Media omitted>\\n',\n",
              " '01/07/2024, 14:47 - +234 816 028 7060: +234 816 231 0367\\n',\n",
              " '01/07/2024, 14:47 - +234 816 028 7060: Admin please kindly add this contact to the group.\\n',\n",
              " '\\n',\n",
              " 'Gratitude.\\n',\n",
              " '01/07/2024, 14:53 - +234 809 600 3499: <Media omitted>\\n',\n",
              " '01/07/2024, 15:01 - +234 816 231 0367 joined using a group link.\\n',\n",
              " '01/07/2024, 15:03 - +234 816 231 0367: Good afternoon.\\n',\n",
              " '01/07/2024, 15:07 - +234 816 231 0367: I just received a mail with a 3pm deadline to update my baccalaureate details. I need assistance please.\\n',\n",
              " \"01/07/2024, 15:08 - +212 700-167603: Guuuuuuys, please, it's for Moroccan undergraduate students\\n\",\n",
              " '01/07/2024, 16:21 - +234 814 795 2500 joined using a group link.\\n',\n",
              " '01/07/2024, 17:47 - Sanda taiwo added ~\\u202fIFEOLUWAPOSIMI_PSALMUELüìñüî•\\n',\n",
              " '01/07/2024, 18:41 - +212 700-167603: Guys anyone received an email from MIM?\\n',\n",
              " '01/07/2024, 18:48 - +212 713-402368: @\\u2068~üë±üèº\\u200d‚ôÇÔ∏è\\u2069\\n',\n",
              " '01/07/2024, 18:48 - +234 806 444 8972: This message was deleted\\n',\n",
              " '01/07/2024, 18:48 - +234 903 934 0119: Acknowledge\\n',\n",
              " '01/07/2024, 19:20 - +234 810 498 8022: No n you?\\n',\n",
              " '01/07/2024, 19:20 - +212 700-167603: If anyone has any information, please let us know. üôè\\n',\n",
              " '01/07/2024, 19:21 - +212 700-167603: It is curious that individuals on the waiting list have been contacted, yet I have not observed any recipients of acceptance letters.\\n',\n",
              " '01/07/2024, 19:32 - My Number: Which waiting list?\\n',\n",
              " '01/07/2024, 19:33 - +212 700-167603: MIM\\n',\n",
              " '01/07/2024, 19:34 - My Number: They sent mails to those on Waiting list?\\n',\n",
              " \"01/07/2024, 19:34 - My Number: Didn't hear bout that\\n\",\n",
              " '01/07/2024, 19:35 - +212 700-167603: Call\\n',\n",
              " '01/07/2024, 19:35 - My Number: Oh!\\n',\n",
              " '01/07/2024, 19:35 - My Number: Okay\\n',\n",
              " '01/07/2024, 19:59 - Paul Popoola UM6P: Were they all called today?\\n',\n",
              " '01/07/2024, 20:11 - Meike: Dear all,\\n',\n",
              " 'Please refrain from sharing unofficial information about admissions. \\n',\n",
              " '\\n',\n",
              " 'Let‚Äôs wait for the official process to communicate any updates.\\n',\n",
              " 'Thank you for your understanding.\\n',\n",
              " \"01/07/2024, 20:19 - +212 700-167603: I'm not sharing unofficial info. I'm sure of what I'm saying üôå\\n\",\n",
              " '01/07/2024, 20:21 - +212 700-167603: I only shared info from my colleagues and asked if anyone had a call today, but I would never mislead anyone. Thanks for understanding!\\n',\n",
              " '01/07/2024, 20:21 - +234 810 128 1313: Please, who else got a mail to reopening application and later got another one to disregard the initial mail today\\n',\n",
              " '01/07/2024, 20:22 - +212 700-167603: I would like to clarify that the message is intended for Moroccan undergraduate students, as there was an error from the university.\\n',\n",
              " '01/07/2024, 20:26 - Meike: I‚Äôm not against you sharing your news here as well, but as an ambassador for Africa Business School, I understand how it feels when such things are shared, although you are an alumni of UM6P, it doesn‚Äôt mean you know how things are done here at ABS. \\n',\n",
              " 'Until you receive your admission and scholarship letters, nothing is certain.\\n',\n",
              " '\\n',\n",
              " 'Thank you ouissal .\\n',\n",
              " '01/07/2024, 20:28 - +212 700-167603: This message was deleted\\n',\n",
              " '01/07/2024, 20:37 - +234 810 128 1313: Thank you\\n',\n",
              " '02/07/2024, 10:42 - +234 810 498 8022: Love letter\\n',\n",
              " '02/07/2024, 10:42 - +234 810 498 8022: Well served\\n',\n",
              " '02/07/2024, 10:43 - My Number: AGRI or MIM?\\n',\n",
              " '02/07/2024, 10:43 - +234 810 498 8022: Mim\\n',\n",
              " '02/07/2024, 10:43 - ...Maryam Mirad: MIM\\n',\n",
              " '02/07/2024, 10:44 - +212 700-167603: This message was deleted\\n',\n",
              " '02/07/2024, 10:44 - +212 700-167603: This message was deleted\\n',\n",
              " '02/07/2024, 11:14 - iWAHABüéá UM6P: MIM üíî\\n',\n",
              " '02/07/2024, 11:59 - +234 703 636 6683: Congratulations üéâ\\n',\n",
              " '02/07/2024, 12:00 - +234 813 453 6479: For love letter?\\n',\n",
              " '02/07/2024, 12:00 - Khalifa UM6P: Nawao\\n',\n",
              " '02/07/2024, 12:01 - +234 909 851 1482: Still congratulations\\n',\n",
              " 'You got far.\\n',\n",
              " 'Celeb it my person\\n',\n",
              " '02/07/2024, 12:01 - +234 810 498 8022: Oga oo\\n',\n",
              " \"02/07/2024, 12:02 - +234 703 636 6683: Doesn't mean... It's a little win and encouragement for more better offers.\\n\",\n",
              " '\\n',\n",
              " '\\n',\n",
              " 'Some of us did not get to the level of getting a love letter.\\n',\n",
              " \"02/07/2024, 12:02 - +234 813 453 6479: That's true\\n\",\n",
              " '02/07/2024, 12:02 - +234 810 565 5888: At least, it will be in record that you tried your best.\\n',\n",
              " '02/07/2024, 12:02 - +234 703 636 6683: Yes\\n',\n",
              " '02/07/2024, 12:03 - +234 813 453 6479: Yes\\n',\n",
              " '02/07/2024, 12:03 - +234 813 453 6479: Congratulations\\n',\n",
              " '02/07/2024, 12:04 - +234 810 498 8022: <Media omitted>\\n',\n",
              " '02/07/2024, 12:04 - +234 810 498 8022: <Media omitted>\\n',\n",
              " '02/07/2024, 12:04 - +234 909 851 1482: Congratulations\\n',\n",
              " '02/07/2024, 12:04 - +234 810 498 8022: Thank  youüòÜ\\n',\n",
              " '02/07/2024, 12:04 - +234 810 139 9774: The encouragement is in order üòÜ\\n',\n",
              " '02/07/2024, 12:05 - +234 810 498 8022: Congratulations ko congratulations  ni ü§£ü§£\\n',\n",
              " '02/07/2024, 12:05 - +234 703 636 6683: üòÜ\\n',\n",
              " '02/07/2024, 12:18 - ~\\u202fOuissal was added\\n',\n",
              " '02/07/2024, 12:06 - +212 700-167603: Thank you all. It is time for me to depart. I would like to extend my congratulations to those who have achieved their goals.\\n',\n",
              " '02/07/2024, 12:06 - +234 909 851 1482: <Media omitted>\\n',\n",
              " '02/07/2024, 12:06 - +234 909 851 1482: <Media omitted>\\n',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ukmUkF0U5yW8",
        "outputId": "0749fa5c-0da0-44de-9cff-103a26d29ed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'29/11/2025, 14:28 - Prof Bigi: Ya lbr\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Cleaning"
      ],
      "metadata": {
        "id": "rQ-3DfsI5_4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FOUND ON GITHUB: https://gist.github.com/kwcooper/a21ba58272d3cdf26310cc02ee4b168f\n",
        "# parse text, create list of lists structure & remove first whatsapp info message\n",
        "dataset = data[1:]\n",
        "cleaned_data = []\n",
        "for line in dataset:\n",
        "    # Check, whether it is a new line or not\n",
        "    # If the following characters are in the line -> assumption it is NOT a new line\n",
        "    if '/' in line and ':' in line and ',' in line and '-' in line:\n",
        "        # grab the info and cut it out\n",
        "        date = line.split(\",\")[0]\n",
        "        line2 = line[len(date):]\n",
        "        time = line2.split(\"-\")[0][2:]\n",
        "        line3 = line2[len(time):]\n",
        "        name = line3.split(\":\")[0][4:]\n",
        "        line4 = line3[len(name):]\n",
        "        message = line4[6:-1] # strip newline charactor\n",
        "        cleaned_data.append([date, time, name, message])\n",
        "\n",
        "    # else, assumption -> new line. Append new line to previous 'message'\n",
        "    else:\n",
        "        new = cleaned_data[-1][-1] + \" \" + line\n",
        "        cleaned_data[-1][-1] = new"
      ],
      "metadata": {
        "id": "H_F-SZRB5_S_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Create the DataFrame\n",
        "df = pd.DataFrame(cleaned_data, columns = ['Date', 'Time', 'Name', 'Message'])"
      ],
      "metadata": {
        "id": "TnuzEyag6VHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.shape)\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0raUlAZf6b6k",
        "outputId": "abd30fd9-9d47-4289-e3b4-5a11a6c1a54f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3352, 4)\n",
            "                      Date                                               Time  \\\n",
            "0               04/03/2024                                             21:36    \n",
            "1               03/06/2024                                             09:14    \n",
            "2               03/06/2024                                             11:04    \n",
            "3  Click on the below link  read and learn as you prepare for graduate sch...   \n",
            "4               03/06/2024                                             12:38    \n",
            "\n",
            "                                                Name  \\\n",
            "0                                   You were added\\n   \n",
            "1   +234¬†810¬†387¬†9881 changed to +234¬†703¬†451¬†6743\\n   \n",
            "2                       Mr Obasanjo Fajemirokun UM6P   \n",
            "3  essons-from-my-first-year-at-um6p-africa-activ...   \n",
            "4                                          My Number   \n",
            "\n",
            "                                             Message  \n",
            "0                                                     \n",
            "1                                                     \n",
            "2  I shared 10 lessons from my first year at UM6P...  \n",
            "3                                                     \n",
            "4               Collectiive intelligence mail landed  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save it to excel\n",
        "df.to_csv('chat_history.csv', index=False)"
      ],
      "metadata": {
        "id": "avLVwYGS7E5S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Eploring the data"
      ],
      "metadata": {
        "id": "KT2Gfyy-Xwfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Load the data\n",
        "df = pd.read_csv('chat_history.csv')\n",
        "\n",
        "# Basic overview\n",
        "print(\"Dataset Shape:\", df.shape)\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"First 10 rows:\")\n",
        "print(df.head(10))\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Data Types:\")\n",
        "print(df.dtypes)\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Missing Values:\")\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "06NaRVShX0ci",
        "outputId": "dd0b5c16-37bf-4806-9c34-4df2a289aa96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Shape: (3352, 4)\n",
            "\n",
            "==================================================\n",
            "First 10 rows:\n",
            "                      Date                                               Time  \\\n",
            "0               04/03/2024                                             21:36    \n",
            "1               03/06/2024                                             09:14    \n",
            "2               03/06/2024                                             11:04    \n",
            "3  Click on the below link  read and learn as you prepare for graduate sch...   \n",
            "4               03/06/2024                                             12:38    \n",
            "5               03/06/2024                                             12:42    \n",
            "6               03/06/2024                                             12:43    \n",
            "7               03/06/2024                                             12:45    \n",
            "8               03/06/2024                                             12:50    \n",
            "9               03/06/2024                                             12:50    \n",
            "\n",
            "                                                Name  \\\n",
            "0                                   You were added\\n   \n",
            "1   +234¬†810¬†387¬†9881 changed to +234¬†703¬†451¬†6743\\n   \n",
            "2                       Mr Obasanjo Fajemirokun UM6P   \n",
            "3  essons-from-my-first-year-at-um6p-africa-activ...   \n",
            "4                                          My Number   \n",
            "5                                Bala bashar um6p WL   \n",
            "6                                  +234 902 097 1082   \n",
            "7                                                Joy   \n",
            "8                                  +234 806 798 4051   \n",
            "9                                    +212 700-167603   \n",
            "\n",
            "                                             Message  \n",
            "0                                                NaN  \n",
            "1                                                NaN  \n",
            "2  I shared 10 lessons from my first year at UM6P...  \n",
            "3                                                NaN  \n",
            "4               Collectiive intelligence mail landed  \n",
            "5                                          Same here  \n",
            "6                                 Just received mine  \n",
            "7                                            Hmmmmmm  \n",
            "8                                  Best of luck guys  \n",
            "9  Lucky you! Very unfair for us here. How am I s...  \n",
            "\n",
            "==================================================\n",
            "Data Types:\n",
            "Date       object\n",
            "Time       object\n",
            "Name       object\n",
            "Message    object\n",
            "dtype: object\n",
            "\n",
            "==================================================\n",
            "Missing Values:\n",
            "Date         0\n",
            "Time         0\n",
            "Name         2\n",
            "Message    405\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's examine the missing data more closely\n",
        "print(\"Messages with missing Names:\")\n",
        "print(df[df['Name'].isnull()][['Date', 'Time', 'Message']].head(10))\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "# Messages with missing content\n",
        "print(\"Rows with missing Messages:\")\n",
        "print(df[df['Message'].isnull()][['Date', 'Time', 'Name']].head(10))\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "# Check for common system messages patterns\n",
        "print(\"Sample of unique messages (first 20):\")\n",
        "print(df['Message'].dropna().unique()[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YK0jl83nnoZg",
        "outputId": "af42e32c-2ac8-4205-ed8c-d97087167704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Messages with missing Names:\n",
            "                                                   Date  \\\n",
            "1078  Preselection Based on Application Review: Pre-...   \n",
            "1143  Preselection Based on Application Review: Pre-...   \n",
            "\n",
            "                                  Time  \\\n",
            "1078  2024. https://lnkd.in/e4EJUGq4\\n   \n",
            "1143  2024. https://lnkd.in/e4EJUGq4\\n   \n",
            "\n",
            "                                                Message  \n",
            "1078   \\n Required Documents:\\n \\n Copy of your nati...  \n",
            "1143   \\n Required Documents:\\n \\n Copy of your nati...  \n",
            "\n",
            "==================================================\n",
            "\n",
            "Rows with missing Messages:\n",
            "                        Date  \\\n",
            "0                 04/03/2024   \n",
            "1                 03/06/2024   \n",
            "3    Click on the below link   \n",
            "81                05/06/2024   \n",
            "172               07/06/2024   \n",
            "181               07/06/2024   \n",
            "185               09/06/2024   \n",
            "224               10/06/2024   \n",
            "231               11/06/2024   \n",
            "232               11/06/2024   \n",
            "\n",
            "                                                  Time  \\\n",
            "0                                               21:36    \n",
            "1                                               09:14    \n",
            "3    read and learn as you prepare for graduate sch...   \n",
            "81                                              20:13    \n",
            "172                                             05:54    \n",
            "181                                             09:16    \n",
            "185                                             08:56    \n",
            "224                                             14:45    \n",
            "231                                             14:38    \n",
            "232                                             15:25    \n",
            "\n",
            "                                                  Name  \n",
            "0                                     You were added\\n  \n",
            "1     +234¬†810¬†387¬†9881 changed to +234¬†703¬†451¬†6743\\n  \n",
            "3    essons-from-my-first-year-at-um6p-africa-activ...  \n",
            "81          Samuel Kobina Gyasi SCI pinned a message\\n  \n",
            "172                                  +234 704 901 2889  \n",
            "181     +234 810 081 1965 joined using a group link.\\n  \n",
            "185    Abdulghaniyy JIMOHüë®‚Äçüíª added +234 806 219 4590\\n  \n",
            "224   +234¬†703¬†451¬†6743 changed to +234¬†810¬†387¬†9881\\n  \n",
            "231  +234 706 653 4141 changed their phone number t...  \n",
            "232   +234¬†915¬†211¬†3859 changed to +234¬†706¬†653¬†4141\\n  \n",
            "\n",
            "==================================================\n",
            "\n",
            "Sample of unique messages (first 20):\n",
            "['I shared 10 lessons from my first year at UM6P. \\n'\n",
            " 'Collectiive intelligence mail landed' 'Same here' 'Just received mine'\n",
            " 'Hmmmmmm' 'Best of luck guys'\n",
            " 'Lucky you! Very unfair for us here. How am I supposed to arrive by 10 a.m.? So ridiculous!'\n",
            " 'Oh oh you are in Morocco?'\n",
            " 'It was the same last here so you can write for accomodation if need be'\n",
            " 'Have you done your interview??'\n",
            " 'Yes, I mean, Abs was so good at organizing this.'\n",
            " \"I asked they said no we can't\"\n",
            " 'Being a UM6P student, I was told, ‚ÄúSorry, we can‚Äôt.‚Äù So sad to be honest'\n",
            " 'Thanks ma. \\n Is there any clue about the written test, I mean the expected questions\\n'\n",
            " \"It's in the mail na\" 'When did you write the mail ?'\n",
            " 'Na love letter we get for hereü•∫ but we meuve regardless <This message was edited>'\n",
            " 'Now, I asked, and they said no.' 'Oküëå' 'You did MIM?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Layer 1 Cleaning: Remove System Messages & Noise"
      ],
      "metadata": {
        "id": "2Dy0v-1-sirg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "df = pd.read_csv('chat_history.csv')\n",
        "\n",
        "print(f\"Original dataset size: {df.shape}\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Step 1A: Remove rows where Message is null (system messages)\n",
        "df_clean = df[df['Message'].notna()].copy()\n",
        "print(f\"After removing null messages: {df_clean.shape}\")\n",
        "\n",
        "# Step 1B: Remove rows where Name is null (parsing errors or system messages)\n",
        "df_clean = df_clean[df_clean['Name'].notna()].copy()\n",
        "print(f\"After removing null names: {df_clean.shape}\")\n",
        "\n",
        "# Step 1C: Remove media omitted messages (no useful content)\n",
        "df_clean = df_clean[df_clean['Message'] != '<Media omitted>'].copy()\n",
        "print(f\"After removing <Media omitted>: {df_clean.shape}\")\n",
        "\n",
        "# Step 1D: Remove very short messages (likely just reactions: \"ok\", \"üëç\", \"same\")\n",
        "# Keep messages with at least 10 characters (adjustable threshold)\n",
        "df_clean = df_clean[df_clean['Message'].str.len() >= 10].copy()\n",
        "print(f\"After removing very short messages (<10 chars): {df_clean.shape}\")\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"\\nSample of cleaned data:\")\n",
        "print(df_clean[['Name', 'Message']].head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "box9epolrCiN",
        "outputId": "1e6fda49-4fb8-4c31-8f75-66ba65cb4cd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset size: (3352, 4)\n",
            "==================================================\n",
            "After removing null messages: (2947, 4)\n",
            "After removing null names: (2945, 4)\n",
            "After removing <Media omitted>: (2609, 4)\n",
            "After removing very short messages (<10 chars): (2194, 4)\n",
            "==================================================\n",
            "\n",
            "Sample of cleaned data:\n",
            "                            Name  \\\n",
            "2   Mr Obasanjo Fajemirokun UM6P   \n",
            "4                      My Number   \n",
            "6              +234 902 097 1082   \n",
            "8              +234 806 798 4051   \n",
            "9                +212 700-167603   \n",
            "10                           Joy   \n",
            "11       Samuel Kobina Gyasi SCI   \n",
            "12                  Khalifa UM6P   \n",
            "13               +212 700-167603   \n",
            "14               +212 700-167603   \n",
            "\n",
            "                                              Message  \n",
            "2   I shared 10 lessons from my first year at UM6P...  \n",
            "4                Collectiive intelligence mail landed  \n",
            "6                                  Just received mine  \n",
            "8                                   Best of luck guys  \n",
            "9   Lucky you! Very unfair for us here. How am I s...  \n",
            "10                          Oh oh you are in Morocco?  \n",
            "11  It was the same last here so you can write for...  \n",
            "12                     Have you done your interview??  \n",
            "13   Yes, I mean, Abs was so good at organizing this.  \n",
            "14                      I asked they said no we can't  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Layer 2: Clean Special Tags & Standardize"
      ],
      "metadata": {
        "id": "ET4aWqhnspQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Continue from df_clean\n",
        "df_clean = df_clean.copy()\n",
        "\n",
        "# Step 2A: Remove editing tags but keep the message\n",
        "df_clean['Message'] = df_clean['Message'].str.replace('<This message was edited>', '', regex=False)\n",
        "df_clean['Message'] = df_clean['Message'].str.replace('<This message was deleted>', '', regex=False)\n",
        "\n",
        "# Step 2B: Strip extra whitespace (from tag removal and general cleanup)\n",
        "df_clean['Message'] = df_clean['Message'].str.strip()\n",
        "\n",
        "# Step 2C: Remove any remaining empty messages after tag removal\n",
        "df_clean = df_clean[df_clean['Message'].str.len() > 0].copy()\n",
        "\n",
        "print(f\"After tag removal and whitespace cleanup: {df_clean.shape}\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Step 2D: Basic statistics to understand our data\n",
        "print(\"\\nMessage Length Statistics:\")\n",
        "df_clean['Message_Length'] = df_clean['Message'].str.len()\n",
        "print(df_clean['Message_Length'].describe())\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"\\nSample of longest messages (likely most informative):\")\n",
        "print(df_clean.nlargest(5, 'Message_Length')[['Name', 'Message']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VzhVesRcrcAK",
        "outputId": "b35e14ac-7c5f-442e-9cc9-b712c1fbec2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After tag removal and whitespace cleanup: (2194, 4)\n",
            "==================================================\n",
            "\n",
            "Message Length Statistics:\n",
            "count    2194.000000\n",
            "mean      102.536463\n",
            "std       341.971513\n",
            "min         8.000000\n",
            "25%        21.000000\n",
            "50%        40.500000\n",
            "75%        88.000000\n",
            "max      9200.000000\n",
            "Name: Message_Length, dtype: float64\n",
            "\n",
            "==================================================\n",
            "\n",
            "Sample of longest messages (likely most informative):\n",
            "                    Name                                            Message\n",
            "904         Khalifa UM6P  ### Supporting Documents to be Provided for th...\n",
            "2349  Acquah Nana Yeboah  Here are some notes I would like to share with...\n",
            "1063   +234 814 470 7909  5 Career Hacks Every Student Needs to Know  \\n...\n",
            "2294  Acquah Nana Yeboah  Hello Everyone, \\n If you‚Äôre new here and wond...\n",
            "2364  Acquah Nana Yeboah  Hello Everyone, \\n If you‚Äôre new here and wond...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract Questions & Create Q&A Dataset"
      ],
      "metadata": {
        "id": "9B8uUlfhvbng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Drop the Name column (privacy + not needed)\n",
        "df_clean = df_clean.drop('Name', axis=1)\n",
        "\n",
        "print(f\"Dataset after dropping Name column: {df_clean.shape}\")\n",
        "print(\"Columns:\", df_clean.columns.tolist())\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Step 3A: Detect Questions\n",
        "# Multiple signals for question detection\n",
        "\n",
        "def is_question(message):\n",
        "    \"\"\"\n",
        "    Identify if a message is a question using multiple signals\n",
        "    \"\"\"\n",
        "    message_lower = message.lower()\n",
        "\n",
        "    # Signal 1: Contains question mark\n",
        "    if '?' in message:\n",
        "        return True\n",
        "\n",
        "    # Signal 2: Starts with question words\n",
        "    question_starters = ['what', 'how', 'when', 'where', 'why', 'which',\n",
        "                         'who', 'can', 'could', 'would', 'should', 'is',\n",
        "                         'are', 'do', 'does', 'did', 'will']\n",
        "\n",
        "    first_word = message_lower.split()[0] if message_lower.split() else ''\n",
        "    if first_word in question_starters:\n",
        "        return True\n",
        "\n",
        "    # Signal 3: Contains help-seeking phrases\n",
        "    help_phrases = ['please help', 'anyone know', 'need help', 'can someone',\n",
        "                    'does anyone', 'how do i', 'where can i', 'advice on',\n",
        "                    'suggestions', 'recommend', 'pls', 'plz']\n",
        "\n",
        "    if any(phrase in message_lower for phrase in help_phrases):\n",
        "        return True\n",
        "\n",
        "    return False\n",
        "\n",
        "# Apply question detection\n",
        "df_clean['Is_Question'] = df_clean['Message'].apply(is_question)\n",
        "\n",
        "# Statistics\n",
        "num_questions = df_clean['Is_Question'].sum()\n",
        "num_statements = (~df_clean['Is_Question']).sum()\n",
        "\n",
        "print(f\"\\nQuestion Detection Results:\")\n",
        "print(f\"Questions: {num_questions} ({num_questions/len(df_clean)*100:.1f}%)\")\n",
        "print(f\"Statements/Answers: {num_statements} ({num_statements/len(df_clean)*100:.1f}%)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Show sample of detected questions\n",
        "print(\"\\nSample of detected QUESTIONS:\")\n",
        "print(df_clean[df_clean['Is_Question']][['Date', 'Message']].head(10))\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"\\nSample of detected STATEMENTS/ANSWERS:\")\n",
        "print(df_clean[~df_clean['Is_Question']][['Date', 'Message']].head(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "txcS-3lSs5AU",
        "outputId": "2274378f-a6c4-4d10-fbbf-e1afa4a09ea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset after dropping Name column: (2194, 4)\n",
            "Columns: ['Date', 'Time', 'Message', 'Message_Length']\n",
            "==================================================\n",
            "\n",
            "Question Detection Results:\n",
            "Questions: 519 (23.7%)\n",
            "Statements/Answers: 1675 (76.3%)\n",
            "==================================================\n",
            "\n",
            "Sample of detected QUESTIONS:\n",
            "          Date                                            Message\n",
            "9   03/06/2024  Lucky you! Very unfair for us here. How am I s...\n",
            "10  03/06/2024                          Oh oh you are in Morocco?\n",
            "12  03/06/2024                     Have you done your interview??\n",
            "18  03/06/2024                      When did you write the mail ?\n",
            "22  03/06/2024                                       You did MIM?\n",
            "23  03/06/2024  You are BG campus ?.. \\n It happened to us but...\n",
            "28  03/06/2024  https://www.linkedin.com/posts/kofi-osei-frimp...\n",
            "36  04/06/2024  @‚Å®~Africanlady‚Å©   Good morning Ma! I didn't re...\n",
            "37  04/06/2024  This is a YouTube channel that provides tips f...\n",
            "39  04/06/2024  Good morning! Can someone help us about this?üëÜüëÜ üëÜ\n",
            "\n",
            "==================================================\n",
            "\n",
            "Sample of detected STATEMENTS/ANSWERS:\n",
            "          Date                                            Message\n",
            "2   03/06/2024    I shared 10 lessons from my first year at UM6P.\n",
            "4   03/06/2024               Collectiive intelligence mail landed\n",
            "6   03/06/2024                                 Just received mine\n",
            "8   03/06/2024                                  Best of luck guys\n",
            "11  03/06/2024  It was the same last here so you can write for...\n",
            "13  03/06/2024   Yes, I mean, Abs was so good at organizing this.\n",
            "14  03/06/2024                      I asked they said no we can't\n",
            "15  03/06/2024  Being a UM6P student, I was told, ‚ÄúSorry, we c...\n",
            "16  03/06/2024  Thanks ma. \\n Is there any clue about the writ...\n",
            "17  03/06/2024                                It's in the mail na\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Let's read those gold nuggets in full\n",
        "print(\"=\"*70)\n",
        "print(\"COMPREHENSIVE GUIDES (Longest Messages):\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for idx, row in df_clean.nlargest(3, 'Message_Length').iterrows():\n",
        "    print(f\"\\nDate: {row['Date']}\")\n",
        "    print(f\"Length: {row['Message_Length']} characters\")\n",
        "    print(f\"Message:\\n{row['Message'][:500]}...\")  # First 500 chars\n",
        "    print(\"-\"*70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "yZpuksL6wWU2",
        "outputId": "006f47d0-ffb3-4193-bd8c-9187189177aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "COMPREHENSIVE GUIDES (Longest Messages):\n",
            "======================================================================\n",
            "\n",
            "Date: 10/07/2024\n",
            "Length: 9200 characters\n",
            "Message:\n",
            "### Supporting Documents to be Provided for the FIRSI Scholarship Application 2024-2025 #### For Moroccan Applicants\n",
            " **Note**: Any false, falsified, or incomplete declaration will nullify the scholarship application file.\n",
            " \n",
            " **Note**: Any false, falsified, or incomplete declaration will nullify the scholarship application file. FIRSI and UM6P reserve the right to control, examine, and verify, by their own means or by any person or provider mandated by the Foundation for this purpose, any inform...\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Date: 02/04/2025\n",
            "Length: 6170 characters\n",
            "Message:\n",
            "Here are some notes I would like to share with all of you about writing an impressive motivation letter and other parts of your application. \n",
            " This post is gleaned from some of the motivation letters I have reviewed and the most common mistakes I see people make. This is in no way an indictment of anyone's abilities, but I believe we need to do better. I am sharing the feedback below because I don't have the bandwidth to review essays individually, and this is a culmination of most of the issues...\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Date: 29/07/2024\n",
            "Length: 4677 characters\n",
            "Message:\n",
            "5 Career Hacks Every Student Needs to Know  \n",
            " A fortnight ago, I had the pleasure of addressing a group of university students in Kenya, hosted by Microsoft‚Äôs East Africa Garage. These promising students participated in a hackathon organized by Green Labs and were invited to visit our Garage to gain firsthand information on innovation and growth frameworks. As members of the Garage committee, we ensured that their visit went beyond sightseeing, incorporating career guidance and a Q&A session abo...\n",
            "----------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's See the Full Guides & Categorize Data"
      ],
      "metadata": {
        "id": "-h3E6iWK8bXn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First, let's extract those comprehensive guides in full\n",
        "print(\"=\"*70)\n",
        "print(\"EXTRACTING COMPREHENSIVE GUIDES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Get the 5 longest messages (likely all guides)\n",
        "comprehensive_guides = df_clean.nlargest(5, 'Message_Length').copy()\n",
        "\n",
        "print(f\"\\nFound {len(comprehensive_guides)} comprehensive guides\")\n",
        "print(\"\\nGuide Topics:\")\n",
        "for idx, row in comprehensive_guides.iterrows():\n",
        "    print(f\"- Date: {row['Date']} | Length: {row['Message_Length']} chars\")\n",
        "    # Show first 150 chars to identify topic\n",
        "    print(f\"  Preview: {row['Message'][:150]}...\")\n",
        "    print()\n",
        "\n",
        "# Save these guides separately (they're too valuable to mix with chat)\n",
        "comprehensive_guides[['Date', 'Message']].to_csv('comprehensive_guides.csv', index=False)\n",
        "print(\"‚úÖ Saved to 'comprehensive_guides.csv'\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Remove guides from main chat (we'll process them separately)\n",
        "df_chat = df_clean[df_clean['Message_Length'] < 1000].copy()  # Threshold: 1000 chars\n",
        "\n",
        "print(f\"\\nMain chat dataset (without guides): {df_chat.shape}\")\n",
        "print(f\"Questions in chat: {df_chat['Is_Question'].sum()}\")\n",
        "print(f\"Answers in chat: {(~df_chat['Is_Question']).sum()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xlXLpFBcxW9h",
        "outputId": "5ed523f0-1b03-47cf-f4bf-81c0e135b344"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "EXTRACTING COMPREHENSIVE GUIDES\n",
            "======================================================================\n",
            "\n",
            "Found 5 comprehensive guides\n",
            "\n",
            "Guide Topics:\n",
            "- Date: 10/07/2024 | Length: 9200 chars\n",
            "  Preview: ### Supporting Documents to be Provided for the FIRSI Scholarship Application 2024-2025 #### For Moroccan Applicants\n",
            " **Note**: Any false, falsified, ...\n",
            "\n",
            "- Date: 02/04/2025 | Length: 6170 chars\n",
            "  Preview: Here are some notes I would like to share with all of you about writing an impressive motivation letter and other parts of your application. \n",
            " This po...\n",
            "\n",
            "- Date: 29/07/2024 | Length: 4677 chars\n",
            "  Preview: 5 Career Hacks Every Student Needs to Know  \n",
            " A fortnight ago, I had the pleasure of addressing a group of university students in Kenya, hosted by Mic...\n",
            "\n",
            "- Date: 24/03/2025 | Length: 3904 chars\n",
            "  Preview: Hello Everyone, \n",
            " If you‚Äôre new here and wondering what this group is about, here's a brief explainer.\n",
            " \n",
            " This group is for guiding Nigerian applicant...\n",
            "\n",
            "- Date: 03/04/2025 | Length: 3884 chars\n",
            "  Preview: Hello Everyone, \n",
            " If you‚Äôre new here and wondering what this group is about, here's a brief explainer.\n",
            " \n",
            " This group is for guiding Nigerian applicant...\n",
            "\n",
            "‚úÖ Saved to 'comprehensive_guides.csv'\n",
            "======================================================================\n",
            "\n",
            "Main chat dataset (without guides): (2174, 5)\n",
            "Questions in chat: 506\n",
            "Answers in chat: 1668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Process Survey Data (The Gold!)"
      ],
      "metadata": {
        "id": "hpYMADWr--xY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load survey data, specifying 'latin1' encoding to handle potential character decoding issues\n",
        "survey_df = pd.read_csv('help_um6p_student.csv', encoding='latin1')\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"SURVEY DATA - INITIAL EXPLORATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(f\"\\nDataset shape: {survey_df.shape}\")\n",
        "print(f\"\\nColumns: {survey_df.columns.tolist()}\")\n",
        "print(f\"\\nData types:\\n{survey_df.dtypes}\")\n",
        "print(f\"\\nMissing values:\\n{survey_df.isnull().sum()}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SAMPLE OF RESPONSES (First 2 rows)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Show first 2 responses (to understand structure)\n",
        "for idx in range(min(2, len(survey_df))):\n",
        "    print(f\"\\n--- Response {idx+1} ---\")\n",
        "    print(f\"Consent: {survey_df.loc[idx, 'consent']}\")\n",
        "    print(f\"UM6P Student: {survey_df.loc[idx, 'um6p_student']}\")\n",
        "    print(f\"Program: {survey_df.loc[idx, 'program']}\")\n",
        "    print(f\"\\nProblem Description (first 200 chars):\\n{str(survey_df.loc[idx, 'problem_description'])[:200]}...\")\n",
        "    print(f\"\\nProblem Solution (first 200 chars):\\n{str(survey_df.loc[idx, 'problem_solution'])[:200]}...\")\n",
        "    print(f\"\\nAdvice (first 200 chars):\\n{str(survey_df.loc[idx, 'advice'])[:200]}...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xOW3AyOf9fKg",
        "outputId": "c7967c90-758a-4a21-8303-1b474dc8c5eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "SURVEY DATA - INITIAL EXPLORATION\n",
            "======================================================================\n",
            "\n",
            "Dataset shape: (10, 6)\n",
            "\n",
            "Columns: ['consent', 'um6p_student', 'program', 'problem_description', 'problem_solution', 'advice']\n",
            "\n",
            "Data types:\n",
            "consent                object\n",
            "um6p_student           object\n",
            "program                object\n",
            "problem_description    object\n",
            "problem_solution       object\n",
            "advice                 object\n",
            "dtype: object\n",
            "\n",
            "Missing values:\n",
            "consent                0\n",
            "um6p_student           0\n",
            "program                0\n",
            "problem_description    0\n",
            "problem_solution       0\n",
            "advice                 0\n",
            "dtype: int64\n",
            "\n",
            "======================================================================\n",
            "SAMPLE OF RESPONSES (First 2 rows)\n",
            "======================================================================\n",
            "\n",
            "--- Response 1 ---\n",
            "Consent: Yes\n",
            "UM6P Student: Yes\n",
            "Program: Collective Intelligence \n",
            "\n",
            "Problem Description (first 200 chars):\n",
            "I had difficulty in the comprehension of application process down to me arrival at the airport because of language differences. Coming from an Anglophone country where English is the way of communicat...\n",
            "\n",
            "Problem Solution (first 200 chars):\n",
            "I was able to overcome this language barrier thanks to the help of using Google chrome that made it easy to translate the website as well as highlighting texts and translating with Google Translate.\n",
            "\n",
            "...\n",
            "\n",
            "Advice (first 200 chars):\n",
            "Download the 3 apps (Google Translate, Google Chrome, Google Maps) as I mentioned as the solution to communication and transportation issues and learn how to use Google Translate and Maps offline. You...\n",
            "\n",
            "--- Response 2 ---\n",
            "Consent: Yes\n",
            "UM6P Student: Yes\n",
            "Program: Architecture \n",
            "\n",
            "Problem Description (first 200 chars):\n",
            "Language social live ...\n",
            "\n",
            "Problem Solution (first 200 chars):\n",
            "Interaction why everyone ...\n",
            "\n",
            "Advice (first 200 chars):\n",
            "Cherche √† s¬íint√©grer toi m√™me ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clean and Structure Survey Data"
      ],
      "metadata": {
        "id": "TFF8wicvJLOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load survey data\n",
        "survey_df = pd.read_csv('help_um6p_student.csv', encoding='latin1')\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"SURVEY DATA CLEANING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Step 1: Basic cleaning\n",
        "survey_clean = survey_df.copy()\n",
        "\n",
        "# Remove leading/trailing whitespace from all text columns\n",
        "text_columns = ['program', 'problem_description', 'problem_solution', 'advice']\n",
        "for col in text_columns:\n",
        "    survey_clean[col] = survey_clean[col].str.strip()\n",
        "\n",
        "# Step 2: Calculate response quality (length as proxy)\n",
        "survey_clean['description_length'] = survey_clean['problem_description'].str.len()\n",
        "survey_clean['solution_length'] = survey_clean['problem_solution'].str.len()\n",
        "survey_clean['advice_length'] = survey_clean['advice'].str.len()\n",
        "survey_clean['total_length'] = (survey_clean['description_length'] +\n",
        "                                 survey_clean['solution_length'] +\n",
        "                                 survey_clean['advice_length'])\n",
        "\n",
        "# Step 3: Analyze response quality\n",
        "print(f\"\\nTotal responses: {len(survey_clean)}\")\n",
        "print(f\"\\nResponse length statistics:\")\n",
        "print(survey_clean[['description_length', 'solution_length', 'advice_length', 'total_length']].describe())\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"QUALITY ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Flag very short responses (likely incomplete or low-quality)\n",
        "short_threshold = 100  # Less than 100 chars total is probably not useful\n",
        "\n",
        "survey_clean['is_detailed'] = survey_clean['total_length'] > short_threshold\n",
        "\n",
        "print(f\"\\nDetailed responses (>{short_threshold} chars total): {survey_clean['is_detailed'].sum()}\")\n",
        "print(f\"Brief responses (<={short_threshold} chars total): {(~survey_clean['is_detailed']).sum()}\")\n",
        "\n",
        "# Show the brief ones (to decide if we keep them)\n",
        "if (~survey_clean['is_detailed']).any():\n",
        "    print(\"\\n--- Brief Responses ---\")\n",
        "    brief_responses = survey_clean[~survey_clean['is_detailed']][['program', 'total_length']]\n",
        "    print(brief_responses)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"PROGRAM DISTRIBUTION\")\n",
        "print(\"=\"*70)\n",
        "print(survey_clean['program'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ofjGU7B1Ciul",
        "outputId": "7011df5b-f205-4e1e-9393-c6e5d4c3c38b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "SURVEY DATA CLEANING\n",
            "======================================================================\n",
            "\n",
            "Total responses: 10\n",
            "\n",
            "Response length statistics:\n",
            "       description_length  solution_length  advice_length  total_length\n",
            "count            10.00000        10.000000      10.000000     10.000000\n",
            "mean            243.30000       218.000000     197.100000    658.400000\n",
            "std             271.05557       312.798124     228.159033    765.792429\n",
            "min               9.00000        24.000000      29.000000     73.000000\n",
            "25%              51.50000        71.500000      53.500000    214.500000\n",
            "50%             161.50000       103.000000      89.500000    387.500000\n",
            "75%             390.25000       210.250000     298.250000    709.250000\n",
            "max             845.00000      1082.000000     723.000000   2650.000000\n",
            "\n",
            "======================================================================\n",
            "QUALITY ANALYSIS\n",
            "======================================================================\n",
            "\n",
            "Detailed responses (>100 chars total): 9\n",
            "Brief responses (<=100 chars total): 1\n",
            "\n",
            "--- Brief Responses ---\n",
            "        program  total_length\n",
            "1  Architecture            73\n",
            "\n",
            "======================================================================\n",
            "PROGRAM DISTRIBUTION\n",
            "======================================================================\n",
            "program\n",
            "Collective Intelligence                                                2\n",
            "PhD                                                                    2\n",
            "Emines                                                                 1\n",
            "Architecture                                                           1\n",
            "PhD student at the college of Agriculture and Environmental Science    1\n",
            "SCI                                                                    1\n",
            "MIM                                                                    1\n",
            "School of Applied science and engineering                              1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Structure Survey Data for RAG"
      ],
      "metadata": {
        "id": "mCL0gYHkbiyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Continue from survey_clean\n",
        "# Keep only detailed responses\n",
        "survey_detailed = survey_clean[survey_clean['is_detailed']].copy()\n",
        "\n",
        "print(f\"Working with {len(survey_detailed)} detailed survey responses\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Step 1: Create structured entries for RAG\n",
        "structured_entries = []\n",
        "\n",
        "for idx, row in survey_detailed.iterrows():\n",
        "    # Create a structured knowledge entry\n",
        "    entry = {\n",
        "        'source_type': 'student_experience',\n",
        "        'program': row['program'],\n",
        "        'content': f\"\"\"Student Experience - {row['program']}\n",
        "\n",
        "CHALLENGES FACED:\n",
        "{row['problem_description']}\n",
        "\n",
        "HOW THEY SOLVED IT:\n",
        "{row['problem_solution']}\n",
        "\n",
        "ADVICE FOR FUTURE STUDENTS:\n",
        "{row['advice']}\n",
        "\"\"\",\n",
        "        'metadata': {\n",
        "            'total_length': row['total_length'],\n",
        "            'response_quality': 'detailed'\n",
        "        }\n",
        "    }\n",
        "\n",
        "    structured_entries.append(entry)\n",
        "\n",
        "# Convert to DataFrame\n",
        "survey_structured = pd.DataFrame(structured_entries)\n",
        "\n",
        "print(f\"\\nCreated {len(survey_structured)} structured survey entries\")\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SAMPLE STRUCTURED ENTRY (First one):\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nSource Type: {survey_structured.loc[0, 'source_type']}\")\n",
        "print(f\"Program: {survey_structured.loc[0, 'program']}\")\n",
        "print(f\"\\nContent:\\n{survey_structured.loc[0, 'content'][:500]}...\")\n",
        "print(f\"\\nMetadata: {survey_structured.loc[0, 'metadata']}\")\n",
        "\n",
        "# Save structured survey data\n",
        "survey_structured.to_json('survey_structured.json', orient='records', indent=2)\n",
        "print(\"\\n‚úÖ Saved to 'survey_structured.json'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gz-ZzAUEKbz0",
        "outputId": "3f192296-7627-4cd2-882f-c2123b649027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working with 9 detailed survey responses\n",
            "======================================================================\n",
            "\n",
            "Created 9 structured survey entries\n",
            "\n",
            "======================================================================\n",
            "SAMPLE STRUCTURED ENTRY (First one):\n",
            "======================================================================\n",
            "\n",
            "Source Type: student_experience\n",
            "Program: Collective Intelligence\n",
            "\n",
            "Content:\n",
            "Student Experience - Collective Intelligence\n",
            "\n",
            "CHALLENGES FACED:\n",
            "I had difficulty in the comprehension of application process down to me arrival at the airport because of language differences. Coming from an Anglophone country where English is the way of communication. The school's application portal was difficult for me to navigate as I couldn't understand the french language that was majorly used and translating it was also difficult due to the website interface. Also when I eventually arrived ...\n",
            "\n",
            "Metadata: {'total_length': 2650, 'response_quality': 'detailed'}\n",
            "\n",
            "‚úÖ Saved to 'survey_structured.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Auto-Extract Topics from Survey Data"
      ],
      "metadata": {
        "id": "x5ZOUMbKcdhz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Define topic keywords (based on common UM6P admission challenges)\n",
        "topic_keywords = {\n",
        "    'visa': ['visa', 'embassy', 'passport', 'travel document', 'consulate'],\n",
        "    'documentation': ['document', 'transcript', 'certificate', 'legalization',\n",
        "                      'translation', 'attestation', 'notarization'],\n",
        "    'language_barrier': ['language', 'french', 'english', 'translate', 'communication'],\n",
        "    'accommodation': ['housing', 'accommodation', 'residence', 'apartment', 'room'],\n",
        "    'financial': ['scholarship', 'funding', 'money', 'payment', 'tuition', 'fee', 'bank'],\n",
        "    'interview': ['interview', 'assessment', 'evaluation', 'test'],\n",
        "    'arrival': ['arrival', 'airport', 'travel', 'flight', 'journey', 'transportation'],\n",
        "    'application_process': ['application', 'admission', 'apply', 'submit', 'deadline'],\n",
        "    'cultural_adaptation': ['culture', 'adapt', 'integrate', 'social', 'community'],\n",
        "    'academic_preparation': ['academic', 'study', 'research', 'preparation', 'course']\n",
        "}\n",
        "\n",
        "def extract_topics(text):\n",
        "    \"\"\"\n",
        "    Extract relevant topics from text based on keyword matching\n",
        "    \"\"\"\n",
        "    text_lower = text.lower()\n",
        "    found_topics = []\n",
        "\n",
        "    for topic, keywords in topic_keywords.items():\n",
        "        if any(keyword in text_lower for keyword in keywords):\n",
        "            found_topics.append(topic)\n",
        "\n",
        "    return found_topics if found_topics else ['general']\n",
        "\n",
        "# Apply topic extraction to each survey entry\n",
        "survey_structured['topics'] = survey_structured['content'].apply(extract_topics)\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"TOPIC EXTRACTION RESULTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Count topic frequency\n",
        "from collections import Counter\n",
        "all_topics = [topic for topics_list in survey_structured['topics'] for topic in topics_list]\n",
        "topic_counts = Counter(all_topics)\n",
        "\n",
        "print(\"\\nTopic Distribution:\")\n",
        "for topic, count in sorted(topic_counts.items(), key=lambda x: x[1], reverse=True):\n",
        "    print(f\"  {topic}: {count} responses\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SAMPLE WITH TOPICS:\")\n",
        "print(\"=\"*70)\n",
        "for idx in range(min(3, len(survey_structured))):\n",
        "    print(f\"\\nResponse {idx+1}:\")\n",
        "    print(f\"Program: {survey_structured.loc[idx, 'program']}\")\n",
        "    print(f\"Topics: {', '.join(survey_structured.loc[idx, 'topics'])}\")\n",
        "    print(f\"Preview: {survey_structured.loc[idx, 'content'][:150]}...\")\n",
        "    print(\"-\"*70)\n",
        "\n",
        "# Save with topics\n",
        "survey_structured.to_json('survey_structured_with_topics.json', orient='records', indent=2)\n",
        "print(\"\\n‚úÖ Saved to 'survey_structured_with_topics.json'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sMwrNEdvcep7",
        "outputId": "0ad426fe-1af4-478a-f66b-a2c5975fcf12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "TOPIC EXTRACTION RESULTS\n",
            "======================================================================\n",
            "\n",
            "Topic Distribution:\n",
            "  documentation: 4 responses\n",
            "  arrival: 4 responses\n",
            "  application_process: 4 responses\n",
            "  academic_preparation: 4 responses\n",
            "  financial: 3 responses\n",
            "  language_barrier: 2 responses\n",
            "  cultural_adaptation: 2 responses\n",
            "  visa: 1 responses\n",
            "  accommodation: 1 responses\n",
            "  interview: 1 responses\n",
            "  general: 1 responses\n",
            "\n",
            "======================================================================\n",
            "SAMPLE WITH TOPICS:\n",
            "======================================================================\n",
            "\n",
            "Response 1:\n",
            "Program: Collective Intelligence\n",
            "Topics: documentation, language_barrier, arrival, application_process, academic_preparation\n",
            "Preview: Student Experience - Collective Intelligence\n",
            "\n",
            "CHALLENGES FACED:\n",
            "I had difficulty in the comprehension of application process down to me arrival at the...\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Response 2:\n",
            "Program: Emines\n",
            "Topics: financial\n",
            "Preview: Student Experience - Emines\n",
            "\n",
            "CHALLENGES FACED:\n",
            "The Firsi's answer about the scholarship came late, so I when I arrived class had already started. Beca...\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Response 3:\n",
            "Program: PhD student at the college of Agriculture and Environmental Science\n",
            "Topics: visa, financial, cultural_adaptation, academic_preparation\n",
            "Preview: Student Experience - PhD student at the college of Agriculture and Environmental Science\n",
            "\n",
            "CHALLENGES FACED:\n",
            "Visa process, renewal of ID, restriction n...\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "‚úÖ Saved to 'survey_structured_with_topics.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save a clean survey summary"
      ],
      "metadata": {
        "id": "4Z3e4PfndjQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a final summary for documentation\n",
        "print(\"=\"*70)\n",
        "print(\"SURVEY DATA PROCESSING - FINAL SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "summary = {\n",
        "    'total_responses': len(survey_structured),\n",
        "    'programs_covered': survey_structured['program'].nunique(),\n",
        "    'avg_response_length': survey_structured['metadata'].apply(lambda x: x['total_length']).mean(),\n",
        "    'total_topics_identified': len(all_topics),\n",
        "    'unique_topics': len(set(all_topics))\n",
        "}\n",
        "\n",
        "print(\"\\nüìä Statistics:\")\n",
        "for key, value in summary.items():\n",
        "    print(f\"  {key}: {value:.0f}\" if isinstance(value, float) else f\"  {key}: {value}\")\n",
        "\n",
        "print(\"\\nüéØ Most Common Pain Points:\")\n",
        "print(\"  1. Documentation\")\n",
        "print(\"  2. Arrival & Logistics\")\n",
        "print(\"  3. Application Process\")\n",
        "print(\"  4. Academic Preparation\")\n",
        "\n",
        "print(\"\\n‚úÖ Survey data is ready for RAG!\")\n",
        "print(\"\\nFiles created:\")\n",
        "print(\"  - survey_structured.json\")\n",
        "print(\"  - survey_structured_with_topics.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "olOJ4GbIc_Pn",
        "outputId": "4ff04066-da29-478e-a3c4-aa4a2cac298b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "SURVEY DATA PROCESSING - FINAL SUMMARY\n",
            "======================================================================\n",
            "\n",
            "üìä Statistics:\n",
            "  total_responses: 9\n",
            "  programs_covered: 7\n",
            "  avg_response_length: 723\n",
            "  total_topics_identified: 27\n",
            "  unique_topics: 11\n",
            "\n",
            "üéØ Most Common Pain Points:\n",
            "  1. Documentation\n",
            "  2. Arrival & Logistics\n",
            "  3. Application Process\n",
            "  4. Academic Preparation\n",
            "\n",
            "‚úÖ Survey data is ready for RAG!\n",
            "\n",
            "Files created:\n",
            "  - survey_structured.json\n",
            "  - survey_structured_with_topics.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload PDFs to Colab"
      ],
      "metadata": {
        "id": "_abu4Myzd72y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"UPLOAD YOUR PDF FILES\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\nClick 'Choose Files' and select all 6 PDFs at once\")\n",
        "print(\"(You can select multiple files by holding Ctrl/Cmd)\")\n",
        "\n",
        "# Upload files\n",
        "uploaded = files.upload()\n",
        "\n",
        "print(\"\\n‚úÖ Upload complete!\")\n",
        "print(f\"Files uploaded: {len(uploaded)}\")\n",
        "print(\"\\nUploaded files:\")\n",
        "for filename in uploaded.keys():\n",
        "    print(f\"  - {filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "collapsed": true,
        "id": "bjkAwm1Ed9Ho",
        "outputId": "1def8ec9-ef86-49a9-fc8d-46920e15dec8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "UPLOAD YOUR PDF FILES\n",
            "======================================================================\n",
            "\n",
            "Click 'Choose Files' and select all 6 PDFs at once\n",
            "(You can select multiple files by holding Ctrl/Cmd)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-994e0711-e5c4-43ce-9338-5e38391fb33c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-994e0711-e5c4-43ce-9338-5e38391fb33c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ABS handbook for the Master of Agribusiness Innovation.pdf to ABS handbook for the Master of Agribusiness Innovation.pdf\n",
            "Saving Brochure Master in International Management.pdf to Brochure Master in International Management.pdf\n",
            "Saving FGSES Master programs Brochure EN.pdf to FGSES Master programs Brochure EN.pdf\n",
            "Saving Master's Degree in Collective Intelligence-2023.pdf to Master's Degree in Collective Intelligence-2023.pdf\n",
            "Saving UM6P APPLICANTS GUIDE.pdf to UM6P APPLICANTS GUIDE.pdf\n",
            "Saving UM6P_Brochure_Globale_Eng.pdf to UM6P_Brochure_Globale_Eng.pdf\n",
            "\n",
            "‚úÖ Upload complete!\n",
            "Files uploaded: 6\n",
            "\n",
            "Uploaded files:\n",
            "  - ABS handbook for the Master of Agribusiness Innovation.pdf\n",
            "  - Brochure Master in International Management.pdf\n",
            "  - FGSES Master programs Brochure EN.pdf\n",
            "  - Master's Degree in Collective Intelligence-2023.pdf\n",
            "  - UM6P APPLICANTS GUIDE.pdf\n",
            "  - UM6P_Brochure_Globale_Eng.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract Content from All PDFs"
      ],
      "metadata": {
        "id": "p_FPRpUBgKjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install PyMuPDF (run once)\n",
        "!pip install pymupdf -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tnCshN3lgRiN",
        "outputId": "53cbb73a-62e9-4778-8b0f-ec674d40d3a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m113.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz  # PyMuPDF\n",
        "import os\n",
        "import json\n",
        "\n",
        "def extract_pdf_content(pdf_path):\n",
        "    \"\"\"\n",
        "    Extract text from PDF with structure preservation\n",
        "    \"\"\"\n",
        "    try:\n",
        "        doc = fitz.open(pdf_path)\n",
        "\n",
        "        pdf_data = {\n",
        "            'source_type': 'official_document',\n",
        "            'filename': os.path.basename(pdf_path),\n",
        "            'num_pages': len(doc),\n",
        "            'full_content': '',\n",
        "            'pages': []\n",
        "        }\n",
        "\n",
        "        full_text = []\n",
        "\n",
        "        for page_num in range(len(doc)):\n",
        "            page = doc[page_num]\n",
        "            text = page.get_text()\n",
        "\n",
        "            # Only keep pages with substantial content\n",
        "            if len(text.strip()) > 50:\n",
        "                page_content = text.strip()\n",
        "                full_text.append(page_content)\n",
        "\n",
        "                pdf_data['pages'].append({\n",
        "                    'page_number': page_num + 1,\n",
        "                    'content': page_content,\n",
        "                    'char_count': len(page_content)\n",
        "                })\n",
        "\n",
        "        # Combine all pages into full content\n",
        "        pdf_data['full_content'] = '\\n\\n'.join(full_text)\n",
        "        pdf_data['total_chars'] = len(pdf_data['full_content'])\n",
        "\n",
        "        doc.close()\n",
        "        return pdf_data\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error processing {pdf_path}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"PDF EXTRACTION IN PROGRESS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Get all PDF files in current directory\n",
        "pdf_files = [f for f in os.listdir('.') if f.endswith('.pdf')]\n",
        "\n",
        "print(f\"\\nFound {len(pdf_files)} PDF files:\")\n",
        "for pdf in pdf_files:\n",
        "    print(f\"  - {pdf}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "\n",
        "# Extract content from all PDFs\n",
        "extracted_pdfs = []\n",
        "\n",
        "for pdf_file in pdf_files:\n",
        "    print(f\"\\nProcessing: {pdf_file}\")\n",
        "    result = extract_pdf_content(pdf_file)\n",
        "\n",
        "    if result:\n",
        "        extracted_pdfs.append(result)\n",
        "        print(f\"  ‚úÖ Success: {result['num_pages']} pages, {result['total_chars']:,} characters\")\n",
        "    else:\n",
        "        print(f\"  ‚ùå Failed\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"EXTRACTION COMPLETE: {len(extracted_pdfs)}/{len(pdf_files)} PDFs processed successfully\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Show summary\n",
        "if extracted_pdfs:\n",
        "    print(\"\\nüìä Summary:\")\n",
        "    for pdf in extracted_pdfs:\n",
        "        print(f\"\\n{pdf['filename']}:\")\n",
        "        print(f\"  Pages: {pdf['num_pages']}\")\n",
        "        print(f\"  Content pages: {len(pdf['pages'])}\")\n",
        "        print(f\"  Total characters: {pdf['total_chars']:,}\")\n",
        "        print(f\"  Preview (first 150 chars):\\n  {pdf['full_content'][:150]}...\")\n",
        "\n",
        "    # Save extracted PDFs\n",
        "    with open('pdfs_extracted.json', 'w', encoding='utf-8') as f:\n",
        "        json.dump(extracted_pdfs, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(\"\\n‚úÖ Saved to 'pdfs_extracted.json'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "jjvE010PgNE8",
        "outputId": "43e577de-5e3f-448a-93c3-04332696cdc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "PDF EXTRACTION IN PROGRESS\n",
            "======================================================================\n",
            "\n",
            "Found 6 PDF files:\n",
            "  - ABS handbook for the Master of Agribusiness Innovation.pdf\n",
            "  - UM6P APPLICANTS GUIDE.pdf\n",
            "  - UM6P_Brochure_Globale_Eng.pdf\n",
            "  - Brochure Master in International Management.pdf\n",
            "  - FGSES Master programs Brochure EN.pdf\n",
            "  - Master's Degree in Collective Intelligence-2023.pdf\n",
            "\n",
            "======================================================================\n",
            "\n",
            "Processing: ABS handbook for the Master of Agribusiness Innovation.pdf\n",
            "  ‚úÖ Success: 14 pages, 26,592 characters\n",
            "\n",
            "Processing: UM6P APPLICANTS GUIDE.pdf\n",
            "  ‚úÖ Success: 8 pages, 23,498 characters\n",
            "\n",
            "Processing: UM6P_Brochure_Globale_Eng.pdf\n",
            "  ‚úÖ Success: 16 pages, 16,973 characters\n",
            "\n",
            "Processing: Brochure Master in International Management.pdf\n",
            "  ‚úÖ Success: 8 pages, 6,235 characters\n",
            "\n",
            "Processing: FGSES Master programs Brochure EN.pdf\n",
            "  ‚úÖ Success: 6 pages, 11,233 characters\n",
            "\n",
            "Processing: Master's Degree in Collective Intelligence-2023.pdf\n",
            "  ‚úÖ Success: 8 pages, 12,012 characters\n",
            "\n",
            "======================================================================\n",
            "EXTRACTION COMPLETE: 6/6 PDFs processed successfully\n",
            "======================================================================\n",
            "\n",
            "üìä Summary:\n",
            "\n",
            "ABS handbook for the Master of Agribusiness Innovation.pdf:\n",
            "  Pages: 14\n",
            "  Content pages: 12\n",
            "  Total characters: 26,592\n",
            "  Preview (first 150 chars):\n",
            "  2 \n",
            "AFRICA BUSINESS SCHOOL \n",
            "ABS handbook for the Master  \n",
            "of Agribusiness Innovation \n",
            " \n",
            "TABLE OF CONTENTS \n",
            "I. \n",
            "Mission ...................................\n",
            "\n",
            "UM6P APPLICANTS GUIDE.pdf:\n",
            "  Pages: 8\n",
            "  Content pages: 8\n",
            "  Total characters: 23,498\n",
            "  Preview (first 150 chars):\n",
            "  1. How many faces are involved during the application stage? \n",
            "‚Ä¢ There are basically 3 stages involved to get into UM6P, which are.  \n",
            "1. Submission of ...\n",
            "\n",
            "UM6P_Brochure_Globale_Eng.pdf:\n",
            "  Pages: 16\n",
            "  Content pages: 16\n",
            "  Total characters: 16,973\n",
            "  Preview (first 150 chars):\n",
            "  1\n",
            "Our Global \n",
            "Academic Offer\n",
            "Empowering Minds.\n",
            "Academic Year 2024-2025\n",
            "\n",
            "2\n",
            "BE PART OF A YOUNG UNIVERSITY\n",
            "DRIVEN BY EXCELLENCE\n",
            "Young and ambitious unive...\n",
            "\n",
            "Brochure Master in International Management.pdf:\n",
            "  Pages: 8\n",
            "  Content pages: 7\n",
            "  Total characters: 6,235\n",
            "  Preview (first 150 chars):\n",
            "  LEARNING OUTCOMES\n",
            "The Master in International Management prepares our graduates to:\n",
            "   Identify and critically analyse international business and mana...\n",
            "\n",
            "FGSES Master programs Brochure EN.pdf:\n",
            "  Pages: 6\n",
            "  Content pages: 5\n",
            "  Total characters: 11,233\n",
            "  Preview (first 150 chars):\n",
            "  WWW.FGSES-UM6P.MA\n",
            "MASTER\n",
            "PROGRAMS\n",
            "‚Ä¢\t\n",
            "ECONOMIC ANALYSIS AND PUBLIC POLICIES \n",
            "‚Ä¢\t\n",
            "QUANTITATIVE ECONOMICS \n",
            "‚Ä¢\t\n",
            "GLOBAL AFFAIRS\n",
            "‚Ä¢\t\n",
            "BEHAVIORAL AND SOCIAL SCIE...\n",
            "\n",
            "Master's Degree in Collective Intelligence-2023.pdf:\n",
            "  Pages: 8\n",
            "  Content pages: 7\n",
            "  Total characters: 12,012\n",
            "  Preview (first 150 chars):\n",
            "  ABOUT \n",
            "MOHAMMED VI POLYTECHNIC \n",
            "UNIVERSITY\n",
            "Mohammed VI Polytechnic University is \n",
            "an institution oriented towards applied \n",
            "research and innovation, wh...\n",
            "\n",
            "‚úÖ Saved to 'pdfs_extracted.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analyze PDF Content Quality"
      ],
      "metadata": {
        "id": "_JF2JUjwg4SO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*70)\n",
        "print(\"PDF CONTENT QUALITY ANALYSIS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for idx, pdf in enumerate(extracted_pdfs):\n",
        "    print(f\"\\n--- PDF {idx+1}: {pdf['filename']} ---\")\n",
        "\n",
        "    # Check for common extraction issues\n",
        "    content = pdf['full_content']\n",
        "\n",
        "    # Issue 1: Too much whitespace/newlines\n",
        "    newline_ratio = content.count('\\n') / len(content) if len(content) > 0 else 0\n",
        "\n",
        "    # Issue 2: Broken words (common in scanned PDFs)\n",
        "    broken_words = len([w for w in content.split() if len(w) == 1 and w.isalpha()])\n",
        "\n",
        "    # Issue 3: Special characters (encoding issues)\n",
        "    special_char_count = sum(1 for c in content if ord(c) > 127)\n",
        "\n",
        "    print(f\"  Newline ratio: {newline_ratio:.2%}\")\n",
        "    print(f\"  Single-letter words: {broken_words}\")\n",
        "    print(f\"  Special characters: {special_char_count}\")\n",
        "\n",
        "    # Show a sample\n",
        "    print(f\"\\n  Sample content (chars 500-700):\")\n",
        "    print(f\"  {content[500:700]}\")\n",
        "\n",
        "    # Quality assessment\n",
        "    if newline_ratio > 0.05 or broken_words > 50:\n",
        "        print(f\"  ‚ö†Ô∏è  Warning: May need additional cleaning\")\n",
        "    else:\n",
        "        print(f\"  ‚úÖ Quality looks good\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sZQslwkzgw8M",
        "outputId": "ac8c69c0-2be0-40c2-8fd0-8939df6ae370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "PDF CONTENT QUALITY ANALYSIS\n",
            "======================================================================\n",
            "\n",
            "--- PDF 1: ABS handbook for the Master of Agribusiness Innovation.pdf ---\n",
            "  Newline ratio: 1.77%\n",
            "  Single-letter words: 38\n",
            "  Special characters: 100\n",
            "\n",
            "  Sample content (chars 500-700):\n",
            "  ..................................................................................................................................... 4 \n",
            "IV. \n",
            "Program Objectives .......................................\n",
            "  ‚úÖ Quality looks good\n",
            "\n",
            "--- PDF 2: UM6P APPLICANTS GUIDE.pdf ---\n",
            "  Newline ratio: 1.34%\n",
            "  Single-letter words: 86\n",
            "  Special characters: 22\n",
            "\n",
            "  Sample content (chars 500-700):\n",
            "  o pass through this first stage to the second stage. You must upload your \n",
            "documents completely and you must ensure that you have a strong profile. Having \n",
            "a very solid statement of purpose is very im\n",
            "  ‚ö†Ô∏è  Warning: May need additional cleaning\n",
            "\n",
            "--- PDF 3: UM6P_Brochure_Globale_Eng.pdf ---\n",
            "  Newline ratio: 3.23%\n",
            "  Single-letter words: 44\n",
            "  Special characters: 105\n",
            "\n",
            "  Sample content (chars 500-700):\n",
            "  ing and aim to position ourselves \n",
            "among the major global institutions in the medium \n",
            "term by expanding the impact of our research and \n",
            "education.\n",
            "Wherever you are from, whatever you study and \n",
            "whatev\n",
            "  ‚úÖ Quality looks good\n",
            "\n",
            "--- PDF 4: Brochure Master in International Management.pdf ---\n",
            "  Newline ratio: 2.63%\n",
            "  Single-letter words: 16\n",
            "  Special characters: 17\n",
            "\n",
            "  Sample content (chars 500-700):\n",
            "  to build and grow \n",
            "businesses across borders.\n",
            "  Lead teams, collaborate ethically as a team member and communicate eÔ¨Äectively \n",
            "(orally and in writing) in cross-cultural environments.\n",
            "01 | MIM\n",
            "PROGRAM \n",
            "  ‚úÖ Quality looks good\n",
            "\n",
            "--- PDF 5: FGSES Master programs Brochure EN.pdf ---\n",
            "  Newline ratio: 1.33%\n",
            "  Single-letter words: 30\n",
            "  Special characters: 26\n",
            "\n",
            "  Sample content (chars 500-700):\n",
            "  rgraduate, Master‚Äôs as well \n",
            "as Ph.D. programs, \n",
            "‚Ä¢ The Africa Institute for Research in Economics and Social Sciences (AIRESS); geared towards research, \n",
            "‚Ä¢ The Public Policy School (PPS); offering exe\n",
            "  ‚úÖ Quality looks good\n",
            "\n",
            "--- PDF 6: Master's Degree in Collective Intelligence-2023.pdf ---\n",
            "  Newline ratio: 3.80%\n",
            "  Single-letter words: 20\n",
            "  Special characters: 57\n",
            "\n",
            "  Sample content (chars 500-700):\n",
            "   allows Mohammed VI Polytechnic \n",
            "University to consolidate Morocco‚Äôs avant-\n",
            "garde position in these fields through the \n",
            "implementation of a unique partnership \n",
            "approach and the strengthening of its \n",
            "a\n",
            "  ‚úÖ Quality looks good\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Structure PDFs for RAG"
      ],
      "metadata": {
        "id": "alkmxBNPiCEs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_pdf_text(text):\n",
        "    \"\"\"\n",
        "    Clean extracted PDF text for RAG\n",
        "    \"\"\"\n",
        "    # Remove excessive newlines (replace 3+ newlines with 2)\n",
        "    text = re.sub(r'\\n{3,}', '\\n\\n', text)\n",
        "\n",
        "    # Remove page numbers and headers/footers (common patterns)\n",
        "    text = re.sub(r'\\n\\d+\\s*\\n', '\\n', text)  # Standalone page numbers\n",
        "    text = re.sub(r'\\n\\d+\\s*\\|\\s*', '\\n', text)  # \"5 | Page\" format\n",
        "\n",
        "    # Fix broken hyphenation (word- \\n word becomes word)\n",
        "    text = re.sub(r'(\\w)-\\s*\\n\\s*(\\w)', r'\\1\\2', text)\n",
        "\n",
        "    # Remove multiple spaces\n",
        "    text = re.sub(r' {2,}', ' ', text)\n",
        "\n",
        "    # Remove dots used for table of contents alignment\n",
        "    text = re.sub(r'\\.{4,}', ' ', text)\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"STRUCTURING PDFs FOR RAG\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Structure each PDF\n",
        "pdfs_structured = []\n",
        "\n",
        "for pdf in extracted_pdfs:\n",
        "    # Clean the content\n",
        "    cleaned_content = clean_pdf_text(pdf['full_content'])\n",
        "\n",
        "    # Infer document type from filename\n",
        "    filename_lower = pdf['filename'].lower()\n",
        "\n",
        "    if 'handbook' in filename_lower or 'brochure' in filename_lower:\n",
        "        doc_type = 'program_guide'\n",
        "    elif 'admission' in filename_lower or 'requirement' in filename_lower:\n",
        "        doc_type = 'admission_requirements'\n",
        "    elif 'visa' in filename_lower:\n",
        "        doc_type = 'visa_information'\n",
        "    else:\n",
        "        doc_type = 'general_information'\n",
        "\n",
        "    # Create structured entry\n",
        "    structured_entry = {\n",
        "        'source_type': 'official_document',\n",
        "        'document_type': doc_type,\n",
        "        'filename': pdf['filename'],\n",
        "        'content': cleaned_content,\n",
        "        'metadata': {\n",
        "            'num_pages': pdf['num_pages'],\n",
        "            'total_chars': len(cleaned_content),\n",
        "            'original_chars': pdf['total_chars']\n",
        "        }\n",
        "    }\n",
        "\n",
        "    pdfs_structured.append(structured_entry)\n",
        "\n",
        "    print(f\"\\n‚úÖ {pdf['filename']}\")\n",
        "    print(f\"   Type: {doc_type}\")\n",
        "    print(f\"   Cleaned: {pdf['total_chars']:,} ‚Üí {len(cleaned_content):,} chars\")\n",
        "    print(f\"   Preview: {cleaned_content[:150]}...\")\n",
        "\n",
        "# Save structured PDFs\n",
        "import json\n",
        "with open('pdfs_structured.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(pdfs_structured, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"‚úÖ Saved {len(pdfs_structured)} structured PDFs to 'pdfs_structured.json'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CxpD3_chhRcb",
        "outputId": "62ac6491-38cd-42b4-9e93-1a3cb1d02b89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "STRUCTURING PDFs FOR RAG\n",
            "======================================================================\n",
            "\n",
            "‚úÖ ABS handbook for the Master of Agribusiness Innovation.pdf\n",
            "   Type: program_guide\n",
            "   Cleaned: 26,592 ‚Üí 23,575 chars\n",
            "   Preview: 2 \n",
            "AFRICA BUSINESS SCHOOL \n",
            "ABS handbook for the Master \n",
            "of Agribusiness Innovation \n",
            " \n",
            "TABLE OF CONTENTS \n",
            "I. \n",
            "Mission   4 \n",
            "II. \n",
            "Vision   4 \n",
            "III. \n",
            "Our P...\n",
            "\n",
            "‚úÖ UM6P APPLICANTS GUIDE.pdf\n",
            "   Type: general_information\n",
            "   Cleaned: 23,498 ‚Üí 23,477 chars\n",
            "   Preview: 1. How many faces are involved during the application stage? \n",
            "‚Ä¢ There are basically 3 stages involved to get into UM6P, which are. \n",
            "1. Submission of d...\n",
            "\n",
            "‚úÖ UM6P_Brochure_Globale_Eng.pdf\n",
            "   Type: program_guide\n",
            "   Cleaned: 16,973 ‚Üí 16,903 chars\n",
            "   Preview: 1\n",
            "Our Global \n",
            "Academic Offer\n",
            "Empowering Minds.\n",
            "Academic Year 2024-2025\n",
            "\n",
            "BE PART OF A YOUNG UNIVERSITY\n",
            "DRIVEN BY EXCELLENCE\n",
            "Young and ambitious univers...\n",
            "\n",
            "‚úÖ Brochure Master in International Management.pdf\n",
            "   Type: program_guide\n",
            "   Cleaned: 6,235 ‚Üí 6,137 chars\n",
            "   Preview: LEARNING OUTCOMES\n",
            "The Master in International Management prepares our graduates to:\n",
            " Identify and critically analyse international business and manage...\n",
            "\n",
            "‚úÖ FGSES Master programs Brochure EN.pdf\n",
            "   Type: program_guide\n",
            "   Cleaned: 11,233 ‚Üí 11,227 chars\n",
            "   Preview: WWW.FGSES-UM6P.MA\n",
            "MASTER\n",
            "PROGRAMS\n",
            "‚Ä¢\t\n",
            "ECONOMIC ANALYSIS AND PUBLIC POLICIES \n",
            "‚Ä¢\t\n",
            "QUANTITATIVE ECONOMICS \n",
            "‚Ä¢\t\n",
            "GLOBAL AFFAIRS\n",
            "‚Ä¢\t\n",
            "BEHAVIORAL AND SOCIAL SCIE...\n",
            "\n",
            "‚úÖ Master's Degree in Collective Intelligence-2023.pdf\n",
            "   Type: general_information\n",
            "   Cleaned: 12,012 ‚Üí 11,996 chars\n",
            "   Preview: ABOUT \n",
            "MOHAMMED VI POLYTECHNIC \n",
            "UNIVERSITY\n",
            "Mohammed VI Polytechnic University is \n",
            "an institution oriented towards applied \n",
            "research and innovation, wh...\n",
            "\n",
            "======================================================================\n",
            "‚úÖ Saved 6 structured PDFs to 'pdfs_structured.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combine ALL Data Sources"
      ],
      "metadata": {
        "id": "86JPQ71SiTsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"COMBINING ALL DATA SOURCES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load all processed data\n",
        "with open('survey_structured_with_topics.json', 'r') as f:\n",
        "    survey_data = json.load(f)\n",
        "\n",
        "with open('pdfs_structured.json', 'r') as f:\n",
        "    pdf_data = json.load(f)\n",
        "\n",
        "# Load WhatsApp guides\n",
        "whatsapp_guides = pd.read_csv('comprehensive_guides.csv')\n",
        "\n",
        "# Structure WhatsApp guides\n",
        "guides_structured = []\n",
        "for idx, row in whatsapp_guides.iterrows():\n",
        "    guides_structured.append({\n",
        "        'source_type': 'community_guide',\n",
        "        'content': row['Message'],\n",
        "        'metadata': {\n",
        "            'date': row['Date'],\n",
        "            'char_count': len(row['Message'])\n",
        "        }\n",
        "    })\n",
        "\n",
        "print(\"\\nüìä Data Sources Summary:\")\n",
        "print(f\"  Survey responses: {len(survey_data)}\")\n",
        "print(f\"  Official PDFs: {len(pdf_data)}\")\n",
        "print(f\"  WhatsApp guides: {len(guides_structured)}\")\n",
        "print(f\"  TOTAL knowledge entries: {len(survey_data) + len(pdf_data) + len(guides_structured)}\")\n",
        "\n",
        "# Combine all sources\n",
        "all_knowledge = {\n",
        "    'survey_experiences': survey_data,\n",
        "    'official_documents': pdf_data,\n",
        "    'community_guides': guides_structured\n",
        "}\n",
        "\n",
        "# Save master knowledge base\n",
        "with open('knowledge_base_complete.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(all_knowledge, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(\"\\n‚úÖ Complete knowledge base saved to 'knowledge_base_complete.json'\")\n",
        "\n",
        "# Statistics\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"KNOWLEDGE BASE STATISTICS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "total_chars = 0\n",
        "for survey in survey_data:\n",
        "    total_chars += len(survey['content'])\n",
        "for pdf in pdf_data:\n",
        "    total_chars += len(pdf['content'])\n",
        "for guide in guides_structured:\n",
        "    total_chars += len(guide['content'])\n",
        "\n",
        "print(f\"\\nTotal characters: {total_chars:,}\")\n",
        "print(f\"Estimated tokens (√∑4): {total_chars//4:,}\")\n",
        "print(f\"\\nBreakdown by source:\")\n",
        "\n",
        "survey_chars = sum(len(s['content']) for s in survey_data)\n",
        "pdf_chars = sum(len(p['content']) for p in pdf_data)\n",
        "guide_chars = sum(len(g['content']) for g in guides_structured)\n",
        "\n",
        "print(f\"  Survey experiences: {survey_chars:,} chars ({survey_chars/total_chars*100:.1f}%)\")\n",
        "print(f\"  Official documents: {pdf_chars:,} chars ({pdf_chars/total_chars*100:.1f}%)\")\n",
        "print(f\"  Community guides: {guide_chars:,} chars ({guide_chars/total_chars*100:.1f}%)lie√üt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujDb4k_KiVEQ",
        "outputId": "42e1b6d7-b126-4377-8deb-3aad3869e3de",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "COMBINING ALL DATA SOURCES\n",
            "======================================================================\n",
            "\n",
            "üìä Data Sources Summary:\n",
            "  Survey responses: 9\n",
            "  Official PDFs: 6\n",
            "  WhatsApp guides: 5\n",
            "  TOTAL knowledge entries: 20\n",
            "\n",
            "‚úÖ Complete knowledge base saved to 'knowledge_base_complete.json'\n",
            "\n",
            "======================================================================\n",
            "KNOWLEDGE BASE STATISTICS\n",
            "======================================================================\n",
            "\n",
            "Total characters: 128,679\n",
            "Estimated tokens (√∑4): 32,169\n",
            "\n",
            "Breakdown by source:\n",
            "  Survey experiences: 7,529 chars (5.9%)\n",
            "  Official documents: 93,315 chars (72.5%)\n",
            "  Community guides: 27,835 chars (21.6%)lie√üt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Preprocessing"
      ],
      "metadata": {
        "id": "7JsUGIuyrFH1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Our Lean Preprocessing Pipeline\n",
        "\n",
        "For RAG-optimized preprocessing:\n",
        "\n",
        "1. Text Normalization ‚úÖ\n",
        "   ```\n",
        "   ‚îú‚îÄ‚îÄ Fix encoding (UTF-8)\n",
        "   ‚îú‚îÄ‚îÄ Standardize entities (UM6P, email, phone)\n",
        "   ‚îú‚îÄ‚îÄ Normalize whitespace\n",
        "   ‚îî‚îÄ‚îÄ Handle special characters\n",
        "\n",
        "2. Minimal Regex Cleaning ‚úÖ\n",
        "   ```\n",
        "   ‚îú‚îÄ‚îÄ Remove PDF artifacts\n",
        "   ‚îú‚îÄ‚îÄ Fix broken hyphenation\n",
        "   ‚îî‚îÄ‚îÄ Clean excess newlines\n",
        "\n",
        "3. Sentence Segmentation ‚úÖ\n",
        "   ```\n",
        "   ‚îú‚îÄ‚îÄ Split into retrievable chunks\n",
        "   ‚îú‚îÄ‚îÄ Preserve context (don't split mid-thought)\n",
        "   ‚îî‚îÄ‚îÄ Maintain natural boundaries\n",
        "\n",
        "4. Quality Checks ‚úÖ\n",
        "   ```\n",
        "   ‚îú‚îÄ‚îÄ Detect language (confirm English)\n",
        "   ‚îú‚îÄ‚îÄ Filter empty/garbage chunks\n",
        "   ‚îî‚îÄ‚îÄ Validate structure\n",
        "\n",
        "‚ùå NO: Lemmatization, Stemming, Stopword removal, Tokenization, POS tagging"
      ],
      "metadata": {
        "id": "wY14I07ntyHJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Normalization"
      ],
      "metadata": {
        "id": "cuwY1cgsxQD_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "\n",
        "def normalize_text(text):\n",
        "    \"\"\"\n",
        "    Normalize text for RAG while preserving natural language\n",
        "    \"\"\"\n",
        "    if not isinstance(text, str) or not text.strip():\n",
        "        return \"\"\n",
        "\n",
        "    # 1. Fix encoding issues (common in PDFs)\n",
        "    text = text.encode('utf-8', errors='ignore').decode('utf-8')\n",
        "\n",
        "    # 2. Standardize UM6P entity variations\n",
        "    text = re.sub(r'\\bum6p\\b', 'UM6P', text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r'\\bUm6p\\b', 'UM6P', text)\n",
        "\n",
        "    # 3. Standardize program names (based on your mapping)\n",
        "    program_mappings = {\n",
        "        r'\\bSCI\\b': 'School of Collective Intelligence',\n",
        "        r'\\bMIM\\b': 'Master in International Management',\n",
        "        r'\\bABI\\b': 'Agri-Business Innovation',\n",
        "        r'\\bABS\\b': 'African Business School',\n",
        "        r'\\bMFE\\b': 'Master in Financial Engineering'\n",
        "    }\n",
        "\n",
        "    for pattern, replacement in program_mappings.items():\n",
        "        # Only replace if it appears as standalone acronym\n",
        "        if re.search(pattern, text):\n",
        "            # Keep both acronym and full name for better retrieval\n",
        "            text = re.sub(pattern, f'{replacement} ({pattern.strip(r\"\\\\b\")})', text)\n",
        "\n",
        "    # 4. Normalize number formats\n",
        "    # \"10 000\" or \"10,000\" ‚Üí \"10,000\"\n",
        "    text = re.sub(r'(\\d+)\\s+(\\d{3})', r'\\1,\\2', text)\n",
        "\n",
        "    # 5. Standardize common abbreviations\n",
        "    text = re.sub(r'\\be-mail\\b', 'email', text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r'\\bvs\\.\\b', 'versus', text, flags=re.IGNORECASE)\n",
        "\n",
        "    # 6. Fix broken hyphenation from PDF extraction\n",
        "    text = re.sub(r'(\\w)-\\s*\\n\\s*(\\w)', r'\\1\\2', text)\n",
        "\n",
        "    # 7. Normalize whitespace (but preserve paragraph breaks)\n",
        "    text = re.sub(r'\\n{3,}', '\\n\\n', text)  # Max 2 newlines\n",
        "    text = re.sub(r'[ \\t]+', ' ', text)     # Single spaces\n",
        "    text = re.sub(r'\\n ', '\\n', text)        # Remove leading space after newline\n",
        "\n",
        "    # 8. Remove PDF artifacts\n",
        "    text = re.sub(r'\\n\\d+\\s*\\n', '\\n', text)           # Standalone page numbers\n",
        "    text = re.sub(r'\\n\\d+\\s*\\|\\s*Page\\s*\\n', '\\n', text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r'\\.{4,}', ' ', text)                 # Table of contents dots\n",
        "\n",
        "    # 9. Standardize punctuation spacing\n",
        "    text = re.sub(r'\\s+([.,!?;:])', r'\\1', text)  # Remove space before punctuation\n",
        "    text = re.sub(r'([.,!?;:])\\s*', r'\\1 ', text)  # Add space after punctuation\n",
        "\n",
        "    # 10. Final cleanup\n",
        "    text = text.strip()\n",
        "\n",
        "    return text\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"TEXT NORMALIZATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load your complete knowledge base\n",
        "with open('knowledge_base_complete.json', 'r', encoding='utf-8') as f:\n",
        "    knowledge_base = json.load(f)\n",
        "\n",
        "# Normalize all content\n",
        "normalized_count = 0\n",
        "\n",
        "# Normalize survey experiences\n",
        "for item in knowledge_base['survey_experiences']:\n",
        "    original = item['content']\n",
        "    item['content'] = normalize_text(original)\n",
        "    if original != item['content']:\n",
        "        normalized_count += 1\n",
        "\n",
        "# Normalize official documents\n",
        "for item in knowledge_base['official_documents']:\n",
        "    original = item['content']\n",
        "    item['content'] = normalize_text(original)\n",
        "    if original != item['content']:\n",
        "        normalized_count += 1\n",
        "\n",
        "# Normalize community guides\n",
        "for item in knowledge_base['community_guides']:\n",
        "    original = item['content']\n",
        "    item['content'] = normalize_text(original)\n",
        "    if original != item['content']:\n",
        "        normalized_count += 1\n",
        "\n",
        "print(f\"\\n‚úÖ Normalized {normalized_count} entries\")\n",
        "\n",
        "# Show example of normalization\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"NORMALIZATION EXAMPLES\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Pick one from each source type\n",
        "print(\"\\n--- Survey Experience Sample ---\")\n",
        "sample = knowledge_base['survey_experiences'][0]['content'][:300]\n",
        "print(f\"First 300 chars:\\n{sample}...\")\n",
        "\n",
        "print(\"\\n--- Official Document Sample ---\")\n",
        "sample = knowledge_base['official_documents'][0]['content'][:300]\n",
        "print(f\"First 300 chars:\\n{sample}...\")\n",
        "\n",
        "print(\"\\n--- Community Guide Sample ---\")\n",
        "sample = knowledge_base['community_guides'][0]['content'][:300]\n",
        "print(f\"First 300 chars:\\n{sample}...\")\n",
        "\n",
        "# Save normalized knowledge base\n",
        "with open('knowledge_base_normalized.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(knowledge_base, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(\"\\n‚úÖ Saved to 'knowledge_base_normalized.json'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZKmPjEOcs-BS",
        "outputId": "32d2b923-c342-441b-db28-63923cbf8091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "TEXT NORMALIZATION\n",
            "======================================================================\n",
            "\n",
            "‚úÖ Normalized 20 entries\n",
            "\n",
            "======================================================================\n",
            "NORMALIZATION EXAMPLES\n",
            "======================================================================\n",
            "\n",
            "--- Survey Experience Sample ---\n",
            "First 300 chars:\n",
            "Student Experience - Collective Intelligence\n",
            "\n",
            "CHALLENGES FACED: I had difficulty in the comprehension of application process down to me arrival at the airport because of language differences. Coming from an Anglophone country where English is the way of communication. The school's application portal...\n",
            "\n",
            "--- Official Document Sample ---\n",
            "First 300 chars:\n",
            "2 \n",
            "AFRICA BUSINESS SCHOOL \n",
            "African Business School (ABS) handbook for the Master \n",
            "of Agribusiness Innovation \n",
            "\n",
            "TABLE OF CONTENTS \n",
            "I. Mission 4 \n",
            "II. Vision 4 \n",
            "III. Our Pedagogy 4 \n",
            "IV. Program Objectives 5 \n",
            "V. Learning Outcomes 5 \n",
            "VI. About the Program 6 \n",
            "VII. Admissions 6 \n",
            "VIII. Overview and Planning...\n",
            "\n",
            "--- Community Guide Sample ---\n",
            "First 300 chars:\n",
            "### Supporting Documents to be Provided for the FIRSI Scholarship Application 2024-2025 #### For Moroccan Applicants\n",
            "**Note**: Any false, falsified, or incomplete declaration will nullify the scholarship application file. **Note**: Any false, falsified, or incomplete declaration will nullify the sch...\n",
            "\n",
            "‚úÖ Saved to 'knowledge_base_normalized.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentence Segmentation (Critical for RAG)"
      ],
      "metadata": {
        "id": "gxeQqWNgxlit"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "\n",
        "def segment_into_sentences(text):\n",
        "    \"\"\"\n",
        "    Segment text into sentences for RAG chunking\n",
        "    Handles common edge cases (abbreviations, decimals, etc.)\n",
        "    \"\"\"\n",
        "    if not text or len(text.strip()) == 0:\n",
        "        return []\n",
        "\n",
        "    # Handle common abbreviations that shouldn't trigger sentence breaks\n",
        "    # Replace temporarily with placeholders\n",
        "    text = re.sub(r'\\bDr\\.', 'Dr<DOT>', text)\n",
        "    text = re.sub(r'\\bMr\\.', 'Mr<DOT>', text)\n",
        "    text = re.sub(r'\\bMs\\.', 'Ms<DOT>', text)\n",
        "    text = re.sub(r'\\bProf\\.', 'Prof<DOT>', text)\n",
        "    text = re.sub(r'\\be\\.g\\.', 'e<DOT>g<DOT>', text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r'\\bi\\.e\\.', 'i<DOT>e<DOT>', text, flags=re.IGNORECASE)\n",
        "    text = re.sub(r'\\betc\\.', 'etc<DOT>', text, flags=re.IGNORECASE)\n",
        "\n",
        "    # Split on sentence boundaries\n",
        "    # Pattern: Period/Question/Exclamation + Space + Capital letter or newline\n",
        "    sentences = re.split(r'(?<=[.!?])\\s+(?=[A-Z])|(?<=[.!?])\\n+', text)\n",
        "\n",
        "    # Restore abbreviations\n",
        "    sentences = [s.replace('<DOT>', '.') for s in sentences]\n",
        "\n",
        "    # Clean and filter\n",
        "    cleaned_sentences = []\n",
        "    for sent in sentences:\n",
        "        sent = sent.strip()\n",
        "        # Keep sentences with at least 20 characters (filters noise)\n",
        "        if len(sent) >= 20:\n",
        "            cleaned_sentences.append(sent)\n",
        "\n",
        "    return cleaned_sentences\n",
        "\n",
        "def create_chunks(sentences, max_chunk_size=3, overlap=1):\n",
        "    \"\"\"\n",
        "    Create overlapping chunks from sentences for better context retrieval\n",
        "\n",
        "    Args:\n",
        "        sentences: List of sentences\n",
        "        max_chunk_size: Maximum sentences per chunk\n",
        "        overlap: Number of sentences to overlap between chunks\n",
        "    \"\"\"\n",
        "    if not sentences:\n",
        "        return []\n",
        "\n",
        "    chunks = []\n",
        "\n",
        "    for i in range(0, len(sentences), max_chunk_size - overlap):\n",
        "        # Get chunk (up to max_chunk_size sentences)\n",
        "        chunk_sentences = sentences[i:i + max_chunk_size]\n",
        "\n",
        "        if chunk_sentences:\n",
        "            chunk_text = ' '.join(chunk_sentences)\n",
        "            chunks.append({\n",
        "                'text': chunk_text,\n",
        "                'sentence_count': len(chunk_sentences),\n",
        "                'char_count': len(chunk_text),\n",
        "                'start_sentence': i\n",
        "            })\n",
        "\n",
        "    return chunks\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"SENTENCE SEGMENTATION & CHUNKING\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load normalized knowledge base\n",
        "with open('knowledge_base_normalized.json', 'r', encoding='utf-8') as f:\n",
        "    knowledge_base = json.load(f)\n",
        "\n",
        "# Process each source type\n",
        "processed_knowledge = {\n",
        "    'survey_experiences': [],\n",
        "    'official_documents': [],\n",
        "    'community_guides': []\n",
        "}\n",
        "\n",
        "total_chunks = 0\n",
        "\n",
        "# Process survey experiences\n",
        "print(\"\\nProcessing Survey Experiences...\")\n",
        "for item in knowledge_base['survey_experiences']:\n",
        "    sentences = segment_into_sentences(item['content'])\n",
        "    chunks = create_chunks(sentences, max_chunk_size=3, overlap=1)\n",
        "\n",
        "    for chunk in chunks:\n",
        "        processed_knowledge['survey_experiences'].append({\n",
        "            'source_type': item['source_type'],\n",
        "            'program': item['program'],\n",
        "            'topics': item['topics'],\n",
        "            'content': chunk['text'],\n",
        "            'metadata': {\n",
        "                **item['metadata'],\n",
        "                'sentence_count': chunk['sentence_count'],\n",
        "                'char_count': chunk['char_count']\n",
        "            }\n",
        "        })\n",
        "\n",
        "    total_chunks += len(chunks)\n",
        "\n",
        "print(f\"  Created {len(processed_knowledge['survey_experiences'])} chunks\")\n",
        "\n",
        "# Process official documents (larger chunks since they're more structured)\n",
        "print(\"\\nProcessing Official Documents...\")\n",
        "for item in knowledge_base['official_documents']:\n",
        "    sentences = segment_into_sentences(item['content'])\n",
        "    chunks = create_chunks(sentences, max_chunk_size=5, overlap=2)  # Larger chunks for PDFs\n",
        "\n",
        "    for chunk in chunks:\n",
        "        processed_knowledge['official_documents'].append({\n",
        "            'source_type': item['source_type'],\n",
        "            'document_type': item['document_type'],\n",
        "            'filename': item['filename'],\n",
        "            'content': chunk['text'],\n",
        "            'metadata': {\n",
        "                **item['metadata'],\n",
        "                'sentence_count': chunk['sentence_count'],\n",
        "                'char_count': chunk['char_count']\n",
        "            }\n",
        "        })\n",
        "\n",
        "    total_chunks += len(chunks)\n",
        "\n",
        "print(f\"  Created {len(processed_knowledge['official_documents'])} chunks\")\n",
        "\n",
        "# Process community guides\n",
        "print(\"\\nProcessing Community Guides...\")\n",
        "for item in knowledge_base['community_guides']:\n",
        "    sentences = segment_into_sentences(item['content'])\n",
        "    chunks = create_chunks(sentences, max_chunk_size=4, overlap=1)\n",
        "\n",
        "    for chunk in chunks:\n",
        "        processed_knowledge['community_guides'].append({\n",
        "            'source_type': item['source_type'],\n",
        "            'content': chunk['text'],\n",
        "            'metadata': {\n",
        "                **item['metadata'],\n",
        "                'sentence_count': chunk['sentence_count'],\n",
        "                'char_count': chunk['char_count']\n",
        "            }\n",
        "        })\n",
        "\n",
        "    total_chunks += len(chunks)\n",
        "\n",
        "print(f\"  Created {len(processed_knowledge['community_guides'])} chunks\")\n",
        "\n",
        "# Statistics\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CHUNKING STATISTICS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"\\nTotal chunks created: {total_chunks}\")\n",
        "print(f\"  Survey chunks: {len(processed_knowledge['survey_experiences'])}\")\n",
        "print(f\"  Document chunks: {len(processed_knowledge['official_documents'])}\")\n",
        "print(f\"  Guide chunks: {len(processed_knowledge['community_guides'])}\")\n",
        "\n",
        "# Show sample chunks\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SAMPLE CHUNKS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\n--- Survey Chunk ---\")\n",
        "print(processed_knowledge['survey_experiences'][0]['content'][:200] + \"...\")\n",
        "\n",
        "print(\"\\n--- Document Chunk ---\")\n",
        "print(processed_knowledge['official_documents'][0]['content'][:200] + \"...\")\n",
        "\n",
        "print(\"\\n--- Guide Chunk ---\")\n",
        "print(processed_knowledge['community_guides'][0]['content'][:200] + \"...\")\n",
        "\n",
        "# Save chunked knowledge base\n",
        "with open('knowledge_base_chunked.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(processed_knowledge, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(\"\\n‚úÖ Saved to 'knowledge_base_chunked.json'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5trjzpckxnRt",
        "outputId": "8df08c6c-d974-45b3-d406-3297f2fec7a0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "SENTENCE SEGMENTATION & CHUNKING\n",
            "======================================================================\n",
            "\n",
            "Processing Survey Experiences...\n",
            "  Created 30 chunks\n",
            "\n",
            "Processing Official Documents...\n",
            "  Created 192 chunks\n",
            "\n",
            "Processing Community Guides...\n",
            "  Created 53 chunks\n",
            "\n",
            "======================================================================\n",
            "CHUNKING STATISTICS\n",
            "======================================================================\n",
            "\n",
            "Total chunks created: 275\n",
            "  Survey chunks: 30\n",
            "  Document chunks: 192\n",
            "  Guide chunks: 53\n",
            "\n",
            "======================================================================\n",
            "SAMPLE CHUNKS\n",
            "======================================================================\n",
            "\n",
            "--- Survey Chunk ---\n",
            "Student Experience - Collective Intelligence\n",
            "\n",
            "CHALLENGES FACED: I had difficulty in the comprehension of application process down to me arrival at the airport because of language differences. Coming f...\n",
            "\n",
            "--- Document Chunk ---\n",
            "2 \n",
            "AFRICA BUSINESS SCHOOL \n",
            "African Business School (ABS) handbook for the Master \n",
            "of Agribusiness Innovation \n",
            "\n",
            "TABLE OF CONTENTS \n",
            "I. Program Objectives 5 \n",
            "V. Learning Outcomes 5 \n",
            "VI. About the Program...\n",
            "\n",
            "--- Guide Chunk ---\n",
            "### Supporting Documents to be Provided for the FIRSI Scholarship Application 2024-2025 #### For Moroccan Applicants\n",
            "**Note**: Any false, falsified, or incomplete declaration will nullify the scholars...\n",
            "\n",
            "‚úÖ Saved to 'knowledge_base_chunked.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quality Validation"
      ],
      "metadata": {
        "id": "ngOSEKITygjQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from collections import Counter\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"QUALITY VALIDATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load chunked knowledge base\n",
        "with open('knowledge_base_chunked.json', 'r', encoding='utf-8') as f:\n",
        "    chunked_kb = json.load(f)\n",
        "\n",
        "# Flatten all chunks for analysis\n",
        "all_chunks = (chunked_kb['survey_experiences'] +\n",
        "              chunked_kb['official_documents'] +\n",
        "              chunked_kb['community_guides'])\n",
        "\n",
        "print(f\"\\nTotal chunks to validate: {len(all_chunks)}\")\n",
        "\n",
        "# Validation checks\n",
        "validation_results = {\n",
        "    'empty_chunks': 0,\n",
        "    'too_short': 0,\n",
        "    'too_long': 0,\n",
        "    'valid_chunks': 0,\n",
        "    'non_english': 0\n",
        "}\n",
        "\n",
        "valid_chunks = []\n",
        "flagged_chunks = []\n",
        "\n",
        "for idx, chunk in enumerate(all_chunks):\n",
        "    content = chunk['content']\n",
        "    char_count = len(content)\n",
        "\n",
        "    # Check 1: Empty or whitespace-only\n",
        "    if not content.strip():\n",
        "        validation_results['empty_chunks'] += 1\n",
        "        flagged_chunks.append({'index': idx, 'issue': 'empty', 'content': content[:100]})\n",
        "        continue\n",
        "\n",
        "    # Check 2: Too short (less than 50 chars is probably not useful)\n",
        "    if char_count < 50:\n",
        "        validation_results['too_short'] += 1\n",
        "        flagged_chunks.append({'index': idx, 'issue': 'too_short', 'content': content})\n",
        "        continue\n",
        "\n",
        "    # Check 3: Too long (over 2000 chars might need further chunking)\n",
        "    if char_count > 2000:\n",
        "        validation_results['too_long'] += 1\n",
        "        flagged_chunks.append({'index': idx, 'issue': 'too_long', 'content': content[:100]})\n",
        "        # Don't skip, just flag\n",
        "\n",
        "    # Check 4: Simple language detection (check for common French words)\n",
        "    # Since you said English only, let's flag potential French\n",
        "    french_indicators = ['de la', 'le ', 'les ', 'et le', 'pour ', 'avec ', 'dans ']\n",
        "    french_count = sum(1 for indicator in french_indicators if indicator in content.lower())\n",
        "\n",
        "    if french_count >= 3:  # If 3+ French indicators, probably French\n",
        "        validation_results['non_english'] += 1\n",
        "        flagged_chunks.append({'index': idx, 'issue': 'possibly_french', 'content': content[:100]})\n",
        "        continue\n",
        "\n",
        "    # Passed all checks\n",
        "    validation_results['valid_chunks'] += 1\n",
        "    valid_chunks.append(chunk)\n",
        "\n",
        "# Results\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"VALIDATION RESULTS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for check, count in validation_results.items():\n",
        "    percentage = (count / len(all_chunks)) * 100\n",
        "    print(f\"  {check}: {count} ({percentage:.1f}%)\")\n",
        "\n",
        "# Show flagged chunks if any\n",
        "if flagged_chunks:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(f\"FLAGGED CHUNKS: {len(flagged_chunks)}\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    for i, flagged in enumerate(flagged_chunks[:5]):  # Show first 5\n",
        "        print(f\"\\nFlagged {i+1}: {flagged['issue']}\")\n",
        "        print(f\"  Content: {flagged['content']}...\")\n",
        "\n",
        "# Final statistics\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"FINAL PREPROCESSING STATISTICS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "chunk_lengths = [len(chunk['content']) for chunk in valid_chunks]\n",
        "print(f\"\\nValid chunks: {len(valid_chunks)}\")\n",
        "print(f\"Average chunk length: {sum(chunk_lengths)/len(chunk_lengths):.0f} chars\")\n",
        "print(f\"Min chunk length: {min(chunk_lengths)} chars\")\n",
        "print(f\"Max chunk length: {max(chunk_lengths)} chars\")\n",
        "\n",
        "# Estimate tokens for RAG (rough: 1 token ‚âà 4 chars)\n",
        "total_chars = sum(chunk_lengths)\n",
        "estimated_tokens = total_chars / 4\n",
        "\n",
        "print(f\"\\nTotal characters: {total_chars:,}\")\n",
        "print(f\"Estimated tokens: {estimated_tokens:,.0f}\")\n",
        "print(f\"Estimated cost for embeddings (assuming OpenAI): ~${estimated_tokens/1000*0.0001:.2f}\")\n",
        "\n",
        "# Save only valid chunks\n",
        "final_knowledge_base = {\n",
        "    'survey_experiences': [c for c in chunked_kb['survey_experiences'] if c in valid_chunks],\n",
        "    'official_documents': [c for c in chunked_kb['official_documents'] if c in valid_chunks],\n",
        "    'community_guides': [c for c in chunked_kb['community_guides'] if c in valid_chunks],\n",
        "    'metadata': {\n",
        "        'total_chunks': len(valid_chunks),\n",
        "        'preprocessing_complete': True,\n",
        "        'validation_passed': True\n",
        "    }\n",
        "}\n",
        "\n",
        "with open('knowledge_base_preprocessed.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(final_knowledge_base, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(\"\\n‚úÖ Final preprocessed knowledge base saved to 'knowledge_base_preprocessed.json'\")\n",
        "print(\"\\nüéâ TEXT PREPROCESSING COMPLETE!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "0CGhNlMmyhwr",
        "outputId": "8ffe184e-4a09-4eab-e92b-76f6e0d905e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "QUALITY VALIDATION\n",
            "======================================================================\n",
            "\n",
            "Total chunks to validate: 275\n",
            "\n",
            "======================================================================\n",
            "VALIDATION RESULTS\n",
            "======================================================================\n",
            "  empty_chunks: 0 (0.0%)\n",
            "  too_short: 2 (0.7%)\n",
            "  too_long: 11 (4.0%)\n",
            "  valid_chunks: 273 (99.3%)\n",
            "  non_english: 0 (0.0%)\n",
            "\n",
            "======================================================================\n",
            "FLAGGED CHUNKS: 13\n",
            "======================================================================\n",
            "\n",
            "Flagged 1: too_short\n",
            "  Content: Older students will help best much....\n",
            "\n",
            "Flagged 2: too_long\n",
            "  Content: Vision \n",
            "African Business School (ABS) addresses the most pressing challenges facing Africa and the w...\n",
            "\n",
            "Flagged 3: too_long\n",
            "  Content: Gamifica¬≠\n",
            "tion and Peer Learning are being introduced, as a new \n",
            "pedagogical method for example 1337...\n",
            "\n",
            "Flagged 4: too_long\n",
            "  Content: Join one of the nume¬≠\n",
            "rous student clubs (UM6P Band, Alchimia, Cyborg, Enac¬≠\n",
            "tus, Rotaract, ‚Ä¶), play...\n",
            "\n",
            "Flagged 5: too_long\n",
            "  Content: The cluster Is home to a large variety \n",
            "of schools and offers a wide range of innovative and \n",
            "interd...\n",
            "\n",
            "======================================================================\n",
            "FINAL PREPROCESSING STATISTICS\n",
            "======================================================================\n",
            "\n",
            "Valid chunks: 273\n",
            "Average chunk length: 730 chars\n",
            "Min chunk length: 53 chars\n",
            "Max chunk length: 7289 chars\n",
            "\n",
            "Total characters: 199,415\n",
            "Estimated tokens: 49,854\n",
            "Estimated cost for embeddings (assuming OpenAI): ~$0.00\n",
            "\n",
            "‚úÖ Final preprocessed knowledge base saved to 'knowledge_base_preprocessed.json'\n",
            "\n",
            "üéâ TEXT PREPROCESSING COMPLETE!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Handling Those Long Chunks"
      ],
      "metadata": {
        "id": "-tkHB50B0FK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"HANDLING LONG CHUNKS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load preprocessed knowledge base\n",
        "with open('knowledge_base_preprocessed.json', 'r', encoding='utf-8') as f:\n",
        "    kb = json.load(f)\n",
        "\n",
        "def split_long_chunk(chunk, max_length=1500):\n",
        "    \"\"\"\n",
        "    Split overly long chunks into smaller pieces\n",
        "    \"\"\"\n",
        "    content = chunk['content']\n",
        "\n",
        "    if len(content) <= max_length:\n",
        "        return [chunk]\n",
        "\n",
        "    # Split by sentences first (if available)\n",
        "    sentences = content.split('. ')\n",
        "\n",
        "    sub_chunks = []\n",
        "    current_chunk = \"\"\n",
        "\n",
        "    for sentence in sentences:\n",
        "        # Add sentence to current chunk\n",
        "        test_chunk = current_chunk + sentence + \". \"\n",
        "\n",
        "        if len(test_chunk) <= max_length:\n",
        "            current_chunk = test_chunk\n",
        "        else:\n",
        "            # Save current chunk and start new one\n",
        "            if current_chunk:\n",
        "                sub_chunk = chunk.copy()\n",
        "                sub_chunk['content'] = current_chunk.strip()\n",
        "                sub_chunk['metadata']['char_count'] = len(current_chunk)\n",
        "                sub_chunk['metadata']['split_from_long'] = True\n",
        "                sub_chunks.append(sub_chunk)\n",
        "\n",
        "            current_chunk = sentence + \". \"\n",
        "\n",
        "    # Add final chunk\n",
        "    if current_chunk:\n",
        "        sub_chunk = chunk.copy()\n",
        "        sub_chunk['content'] = current_chunk.strip()\n",
        "        sub_chunk['metadata']['char_count'] = len(current_chunk)\n",
        "        sub_chunk['metadata']['split_from_long'] = True\n",
        "        sub_chunks.append(sub_chunk)\n",
        "\n",
        "    return sub_chunks if sub_chunks else [chunk]\n",
        "\n",
        "# Process all sources\n",
        "final_kb = {\n",
        "    'survey_experiences': [],\n",
        "    'official_documents': [],\n",
        "    'community_guides': []\n",
        "}\n",
        "\n",
        "splits_made = 0\n",
        "\n",
        "for source_type in ['survey_experiences', 'official_documents', 'community_guides']:\n",
        "    for chunk in kb[source_type]:\n",
        "        if len(chunk['content']) > 1500:\n",
        "            splits = split_long_chunk(chunk, max_length=1500)\n",
        "            final_kb[source_type].extend(splits)\n",
        "            splits_made += len(splits) - 1\n",
        "        else:\n",
        "            final_kb[source_type].append(chunk)\n",
        "\n",
        "# Calculate final stats\n",
        "total_chunks = (len(final_kb['survey_experiences']) +\n",
        "                len(final_kb['official_documents']) +\n",
        "                len(final_kb['community_guides']))\n",
        "\n",
        "print(f\"\\n‚úÖ Split {splits_made} long chunks\")\n",
        "print(f\"Total chunks: 201 ‚Üí {total_chunks}\")\n",
        "\n",
        "# New statistics\n",
        "all_chunks = (final_kb['survey_experiences'] +\n",
        "              final_kb['official_documents'] +\n",
        "              final_kb['community_guides'])\n",
        "\n",
        "chunk_lengths = [len(chunk['content']) for chunk in all_chunks]\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"UPDATED STATISTICS\")\n",
        "print(\"=\"*70)\n",
        "print(f\"Total chunks: {total_chunks}\")\n",
        "print(f\"Average chunk length: {sum(chunk_lengths)/len(chunk_lengths):.0f} chars\")\n",
        "print(f\"Min chunk length: {min(chunk_lengths)} chars\")\n",
        "print(f\"Max chunk length: {max(chunk_lengths)} chars\")\n",
        "\n",
        "# Check distribution\n",
        "print(\"\\nChunk size distribution:\")\n",
        "size_ranges = {\n",
        "    '0-500': 0,\n",
        "    '501-1000': 0,\n",
        "    '1001-1500': 0,\n",
        "    '1501+': 0\n",
        "}\n",
        "\n",
        "for length in chunk_lengths:\n",
        "    if length <= 500:\n",
        "        size_ranges['0-500'] += 1\n",
        "    elif length <= 1000:\n",
        "        size_ranges['501-1000'] += 1\n",
        "    elif length <= 1500:\n",
        "        size_ranges['1001-1500'] += 1\n",
        "    else:\n",
        "        size_ranges['1501+'] += 1\n",
        "\n",
        "for range_name, count in size_ranges.items():\n",
        "    percentage = (count / total_chunks) * 100\n",
        "    print(f\"  {range_name} chars: {count} ({percentage:.1f}%)\")\n",
        "\n",
        "# Save final version\n",
        "final_kb['metadata'] = {\n",
        "    'total_chunks': total_chunks,\n",
        "    'preprocessing_complete': True,\n",
        "    'validation_passed': True,\n",
        "    'long_chunks_split': True\n",
        "}\n",
        "\n",
        "with open('knowledge_base_final.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(final_kb, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(\"\\n‚úÖ Saved to 'knowledge_base_final.json'\")\n",
        "print(\"\\nüéâ PREPROCESSING FULLY COMPLETE - READY FOR FEATURE ENGINEERING!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "we88iiZXyrtZ",
        "outputId": "423aecc8-d457-421a-9650-c5109700b67b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "HANDLING LONG CHUNKS\n",
            "======================================================================\n",
            "\n",
            "‚úÖ Split 25 long chunks\n",
            "Total chunks: 201 ‚Üí 298\n",
            "\n",
            "======================================================================\n",
            "UPDATED STATISTICS\n",
            "======================================================================\n",
            "Total chunks: 298\n",
            "Average chunk length: 669 chars\n",
            "Min chunk length: 53 chars\n",
            "Max chunk length: 1617 chars\n",
            "\n",
            "Chunk size distribution:\n",
            "  0-500 chars: 112 (37.6%)\n",
            "  501-1000 chars: 128 (43.0%)\n",
            "  1001-1500 chars: 55 (18.5%)\n",
            "  1501+ chars: 3 (1.0%)\n",
            "\n",
            "‚úÖ Saved to 'knowledge_base_final.json'\n",
            "\n",
            "üéâ PREPROCESSING FULLY COMPLETE - READY FOR FEATURE ENGINEERING!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering (Balanced Approach)"
      ],
      "metadata": {
        "id": "32njO65N4HSW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"FEATURE ENGINEERING - ENHANCED TOPIC CLASSIFICATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load final preprocessed knowledge base\n",
        "with open('knowledge_base_final.json', 'r', encoding='utf-8') as f:\n",
        "    kb = json.load(f)\n",
        "\n",
        "# Enhanced topic taxonomy with hierarchical structure\n",
        "topic_taxonomy = {\n",
        "    'visa_process': {\n",
        "        'keywords': ['visa', 'embassy', 'consulate', 'passport', 'travel document',\n",
        "                     'visa application', 'visa appointment', 'visa fee'],\n",
        "        'subtopics': {\n",
        "            'visa_requirements': ['visa requirement', 'visa document', 'what documents for visa'],\n",
        "            'visa_timeline': ['how long', 'visa processing time', 'visa wait', 'visa duration'],\n",
        "            'visa_interview': ['visa interview', 'embassy interview', 'consulate meeting']\n",
        "        }\n",
        "    },\n",
        "    'documentation': {\n",
        "        'keywords': ['document', 'certificate', 'transcript', 'diploma', 'attestation'],\n",
        "        'subtopics': {\n",
        "            'translation': ['translation', 'translate', 'translated copy', 'certified translation'],\n",
        "            'legalization': ['legalization', 'legalize', 'apostille', 'notarization', 'notarize'],\n",
        "            'authentication': ['authentication', 'authenticate', 'certified copy', 'official copy']\n",
        "        }\n",
        "    },\n",
        "    'application_process': {\n",
        "        'keywords': ['application', 'apply', 'admission', 'submit', 'deadline', 'portal'],\n",
        "        'subtopics': {\n",
        "            'requirements': ['requirement', 'required', 'need', 'must have', 'prerequisite'],\n",
        "            'timeline': ['deadline', 'due date', 'submission date', 'when to apply'],\n",
        "            'portal_issues': ['portal', 'website', 'online application', 'login', 'technical issue']\n",
        "        }\n",
        "    },\n",
        "    'financial': {\n",
        "        'keywords': ['scholarship', 'tuition', 'fee', 'payment', 'funding', 'financial',\n",
        "                     'FIRSI', 'cost', 'money', 'bank'],\n",
        "        'subtopics': {\n",
        "            'scholarship': ['scholarship', 'FIRSI', 'funding opportunity', 'financial aid'],\n",
        "            'payment': ['payment', 'pay', 'transfer', 'bank', 'transaction'],\n",
        "            'costs': ['cost', 'fee', 'tuition', 'expense', 'price']\n",
        "        }\n",
        "    },\n",
        "    'arrival_preparation': {\n",
        "        'keywords': ['arrival', 'airport', 'travel', 'flight', 'transportation', 'journey'],\n",
        "        'subtopics': {\n",
        "            'travel': ['flight', 'booking', 'ticket', 'airport', 'arrival time'],\n",
        "            'transportation': ['transport', 'taxi', 'bus', 'from airport', 'getting to'],\n",
        "            'first_days': ['first day', 'arrival day', 'check-in', 'registration']\n",
        "        }\n",
        "    },\n",
        "    'accommodation': {\n",
        "        'keywords': ['housing', 'accommodation', 'residence', 'apartment', 'room',\n",
        "                     'dormitory', 'living'],\n",
        "        'subtopics': {\n",
        "            'campus_housing': ['campus', 'dormitory', 'residence hall', 'on-campus'],\n",
        "            'off_campus': ['off-campus', 'apartment', 'rent', 'private housing']\n",
        "        }\n",
        "    },\n",
        "    'language_support': {\n",
        "        'keywords': ['language', 'french', 'english', 'translate', 'communication',\n",
        "                     'speak', 'understand'],\n",
        "        'subtopics': {\n",
        "            'language_barrier': ['language barrier', 'communication problem', 'understand french'],\n",
        "            'language_tools': ['google translate', 'translation app', 'language help']\n",
        "        }\n",
        "    },\n",
        "    'academic_preparation': {\n",
        "        'keywords': ['academic', 'study', 'course', 'research', 'preparation', 'program'],\n",
        "        'subtopics': {\n",
        "            'program_info': ['program', 'curriculum', 'courses', 'modules'],\n",
        "            'prerequisites': ['prerequisite', 'background', 'required knowledge', 'preparation']\n",
        "        }\n",
        "    },\n",
        "    'interview': {\n",
        "        'keywords': ['interview', 'assessment', 'evaluation', 'test', 'oral exam'],\n",
        "        'subtopics': {\n",
        "            'interview_prep': ['prepare for interview', 'interview preparation', 'what to expect'],\n",
        "            'interview_questions': ['interview question', 'what they ask', 'common questions']\n",
        "        }\n",
        "    },\n",
        "    'cultural_adaptation': {\n",
        "        'keywords': ['culture', 'adapt', 'integrate', 'social', 'community', 'moroccan'],\n",
        "        'subtopics': {\n",
        "            'social_integration': ['social', 'friends', 'community', 'integrate'],\n",
        "            'cultural_differences': ['culture', 'cultural difference', 'customs', 'traditions']\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "def classify_topics(text):\n",
        "    \"\"\"\n",
        "    Classify text into topics and subtopics\n",
        "    Returns: {main_topic: [subtopics]}\n",
        "    \"\"\"\n",
        "    text_lower = text.lower()\n",
        "    found_topics = {}\n",
        "\n",
        "    for main_topic, config in topic_taxonomy.items():\n",
        "        # Check main topic keywords\n",
        "        main_matches = sum(1 for kw in config['keywords'] if kw in text_lower)\n",
        "\n",
        "        if main_matches > 0:\n",
        "            found_subtopics = []\n",
        "\n",
        "            # Check subtopics\n",
        "            if 'subtopics' in config:\n",
        "                for subtopic, keywords in config['subtopics'].items():\n",
        "                    if any(kw in text_lower for kw in keywords):\n",
        "                        found_subtopics.append(subtopic)\n",
        "\n",
        "            found_topics[main_topic] = found_subtopics if found_subtopics else ['general']\n",
        "\n",
        "    return found_topics if found_topics else {'general': ['uncategorized']}\n",
        "\n",
        "# Apply enhanced topic classification\n",
        "all_chunks = []\n",
        "topic_stats = Counter()\n",
        "\n",
        "for source_type in ['survey_experiences', 'official_documents', 'community_guides']:\n",
        "    for chunk in kb[source_type]:\n",
        "        # Classify topics\n",
        "        topics = classify_topics(chunk['content'])\n",
        "\n",
        "        # Add to chunk metadata\n",
        "        chunk['topics_enhanced'] = topics\n",
        "        chunk['main_topics'] = list(topics.keys())\n",
        "\n",
        "        # Update statistics\n",
        "        for main_topic in topics.keys():\n",
        "            topic_stats[main_topic] += 1\n",
        "\n",
        "        all_chunks.append(chunk)\n",
        "\n",
        "# Statistics\n",
        "print(f\"\\nProcessed {len(all_chunks)} chunks\")\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"TOPIC DISTRIBUTION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for topic, count in topic_stats.most_common():\n",
        "    percentage = (count / len(all_chunks)) * 100\n",
        "    print(f\"  {topic}: {count} chunks ({percentage:.1f}%)\")\n",
        "\n",
        "# Show example\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EXAMPLE: Enhanced Topic Classification\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Find a chunk with multiple topics\n",
        "for chunk in all_chunks:\n",
        "    if len(chunk['topics_enhanced']) >= 2:\n",
        "        print(f\"\\nContent preview: {chunk['content'][:200]}...\")\n",
        "        print(f\"\\nTopics detected:\")\n",
        "        for main_topic, subtopics in chunk['topics_enhanced'].items():\n",
        "            print(f\"  {main_topic}:\")\n",
        "            for subtopic in subtopics:\n",
        "                print(f\"    - {subtopic}\")\n",
        "        break\n",
        "\n",
        "# Update knowledge base with enhanced topics\n",
        "kb_enhanced = {\n",
        "    'survey_experiences': [c for c in all_chunks if c.get('source_type') == 'student_experience'],\n",
        "    'official_documents': [c for c in all_chunks if c.get('source_type') == 'official_document'],\n",
        "    'community_guides': [c for c in all_chunks if c.get('source_type') == 'community_guide'],\n",
        "    'metadata': kb['metadata']\n",
        "}\n",
        "\n",
        "with open('knowledge_base_with_topics.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(kb_enhanced, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(\"\\n‚úÖ Saved to 'knowledge_base_with_topics.json'\")"
      ],
      "metadata": {
        "id": "Cso-Oxqq4Nlf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "5b2a5788-eec1-424a-df06-ddd62b478c5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "FEATURE ENGINEERING - ENHANCED TOPIC CLASSIFICATION\n",
            "======================================================================\n",
            "\n",
            "Processed 298 chunks\n",
            "\n",
            "======================================================================\n",
            "TOPIC DISTRIBUTION\n",
            "======================================================================\n",
            "  academic_preparation: 161 chunks (54.0%)\n",
            "  application_process: 106 chunks (35.6%)\n",
            "  cultural_adaptation: 97 chunks (32.6%)\n",
            "  financial: 85 chunks (28.5%)\n",
            "  documentation: 61 chunks (20.5%)\n",
            "  language_support: 54 chunks (18.1%)\n",
            "  interview: 47 chunks (15.8%)\n",
            "  arrival_preparation: 35 chunks (11.7%)\n",
            "  visa_process: 27 chunks (9.1%)\n",
            "  accommodation: 25 chunks (8.4%)\n",
            "  general: 19 chunks (6.4%)\n",
            "\n",
            "======================================================================\n",
            "EXAMPLE: Enhanced Topic Classification\n",
            "======================================================================\n",
            "\n",
            "Content preview: Student Experience - Collective Intelligence\n",
            "\n",
            "CHALLENGES FACED: I had difficulty in the comprehension of application process down to me arrival at the airport because of language differences. Coming f...\n",
            "\n",
            "Topics detected:\n",
            "  application_process:\n",
            "    - portal_issues\n",
            "  arrival_preparation:\n",
            "    - travel\n",
            "  language_support:\n",
            "    - general\n",
            "\n",
            "‚úÖ Saved to 'knowledge_base_with_topics.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Entity Extraction"
      ],
      "metadata": {
        "id": "75qYpDZZTrnS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"FEATURE ENGINEERING - ENTITY EXTRACTION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load knowledge base with topics\n",
        "with open('knowledge_base_with_topics.json', 'r', encoding='utf-8') as f:\n",
        "    kb = json.load(f)\n",
        "\n",
        "# Define entity patterns\n",
        "entity_patterns = {\n",
        "    'programs': [\n",
        "        r'\\b(School of Collective Intelligence|Collective Intelligence|SCI)\\b',\n",
        "        r'\\b(Master in International Management|MIM)\\b',\n",
        "        r'\\b(Agri-Business Innovation|ABI)\\b',\n",
        "        r'\\b(African Business School|ABS)\\b',\n",
        "        r'\\b(Master in Financial Engineering|MFE)\\b',\n",
        "        r'\\b(EMINES|Emines)\\b',\n",
        "        r'\\b(PhD|Ph\\.?D\\.?)\\b',\n",
        "        r'\\b(Master\\'?s?|Masters?)\\b',\n",
        "    ],\n",
        "    'countries': [\n",
        "        r'\\bNigeria[n]?\\b',\n",
        "        r'\\bMorocco\\b|\\bMoroccan\\b',\n",
        "        r'\\bKenya[n]?\\b',\n",
        "        r'\\bGhana\\b|\\bGhanaian\\b',\n",
        "        r'\\bSenegal\\b|\\bSenegalese\\b',\n",
        "        r'\\bCameroon\\b|\\bCameroonian\\b',\n",
        "        r'\\bEthiopia[n]?\\b',\n",
        "        r'\\bSouth Africa[n]?\\b',\n",
        "    ],\n",
        "    'documents': [\n",
        "        r'\\btranscript[s]?\\b',\n",
        "        r'\\bcertificate[s]?\\b',\n",
        "        r'\\bdiploma[s]?\\b',\n",
        "        r'\\bpassport[s]?\\b',\n",
        "        r'\\bvisa[s]?\\b',\n",
        "        r'\\bCV\\b|\\bresume\\b',\n",
        "        r'\\bmotivation letter[s]?\\b',\n",
        "        r'\\brecommendation letter[s]?\\b',\n",
        "        r'\\bID\\b|\\bidentification\\b',\n",
        "        r'\\battestation[s]?\\b',\n",
        "    ],\n",
        "    'locations': [\n",
        "        r'\\bUM6P\\b',\n",
        "        r'\\bBenguerir\\b',\n",
        "        r'\\bRabat\\b',\n",
        "        r'\\bCasablanca\\b',\n",
        "        r'\\bairport\\b',\n",
        "        r'\\bembassy\\b',\n",
        "        r'\\bconsulate\\b',\n",
        "        r'\\bcampus\\b',\n",
        "    ],\n",
        "    'timeframes': [\n",
        "        r'\\b\\d{1,2}\\s*weeks?\\b',\n",
        "        r'\\b\\d{1,2}\\s*months?\\b',\n",
        "        r'\\b\\d{1,2}\\s*days?\\b',\n",
        "        r'\\bdeadline[s]?\\b',\n",
        "        r'\\bJanuary|February|March|April|May|June|July|August|September|October|November|December\\b',\n",
        "        r'\\b202\\d\\b',\n",
        "    ]\n",
        "}\n",
        "\n",
        "def extract_entities(text):\n",
        "    \"\"\"\n",
        "    Extract named entities from text\n",
        "    \"\"\"\n",
        "    entities = {}\n",
        "\n",
        "    for entity_type, patterns in entity_patterns.items():\n",
        "        found = set()\n",
        "        for pattern in patterns:\n",
        "            matches = re.findall(pattern, text, re.IGNORECASE)\n",
        "            found.update(matches)\n",
        "\n",
        "        entities[entity_type] = list(found) if found else []\n",
        "\n",
        "    return entities\n",
        "\n",
        "# Apply entity extraction\n",
        "all_chunks = []\n",
        "entity_stats = {entity_type: Counter() for entity_type in entity_patterns.keys()}\n",
        "\n",
        "for source_type in ['survey_experiences', 'official_documents', 'community_guides']:\n",
        "    for chunk in kb[source_type]:\n",
        "        # Extract entities\n",
        "        entities = extract_entities(chunk['content'])\n",
        "\n",
        "        # Add to chunk\n",
        "        chunk['entities'] = entities\n",
        "\n",
        "        # Update statistics\n",
        "        for entity_type, entity_list in entities.items():\n",
        "            for entity in entity_list:\n",
        "                entity_stats[entity_type][entity.lower()] += 1\n",
        "\n",
        "        all_chunks.append(chunk)\n",
        "\n",
        "# Statistics\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"ENTITY EXTRACTION STATISTICS\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for entity_type, counter in entity_stats.items():\n",
        "    if counter:\n",
        "        print(f\"\\n{entity_type.upper()} (Top 5):\")\n",
        "        for entity, count in counter.most_common(5):\n",
        "            print(f\"  {entity}: {count} mentions\")\n",
        "\n",
        "# Show example\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EXAMPLE: Entity Extraction\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Find a chunk with rich entities\n",
        "for chunk in all_chunks:\n",
        "    total_entities = sum(len(v) for v in chunk['entities'].values())\n",
        "    if total_entities >= 5:\n",
        "        print(f\"\\nContent preview: {chunk['content'][:200]}...\")\n",
        "        print(f\"\\nExtracted entities:\")\n",
        "        for entity_type, entity_list in chunk['entities'].items():\n",
        "            if entity_list:\n",
        "                print(f\"  {entity_type}: {', '.join(entity_list)}\")\n",
        "        break\n",
        "\n",
        "# Update knowledge base\n",
        "kb_with_entities = {\n",
        "    'survey_experiences': [c for c in all_chunks if c.get('source_type') == 'student_experience'],\n",
        "    'official_documents': [c for c in all_chunks if c.get('source_type') == 'official_document'],\n",
        "    'community_guides': [c for c in all_chunks if c.get('source_type') == 'community_guide'],\n",
        "    'metadata': kb['metadata']\n",
        "}\n",
        "\n",
        "with open('knowledge_base_with_entities.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(kb_with_entities, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(\"\\n‚úÖ Saved to 'knowledge_base_with_entities.json'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "PrwwjIJ2TvMC",
        "outputId": "c19e17db-828a-43ad-d8e4-586c5f4f3055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "FEATURE ENGINEERING - ENTITY EXTRACTION\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "ENTITY EXTRACTION STATISTICS\n",
            "======================================================================\n",
            "\n",
            "PROGRAMS (Top 5):\n",
            "  master: 59 mentions\n",
            "  collective intelligence: 27 mentions\n",
            "  abs: 23 mentions\n",
            "  african business school: 20 mentions\n",
            "  phd: 11 mentions\n",
            "\n",
            "COUNTRIES (Top 5):\n",
            "  morocco: 38 mentions\n",
            "  moroccan: 17 mentions\n",
            "  nigerian: 11 mentions\n",
            "  nigeria: 3 mentions\n",
            "  kenya: 2 mentions\n",
            "\n",
            "DOCUMENTS (Top 5):\n",
            "  certificate: 18 mentions\n",
            "  visa: 16 mentions\n",
            "  motivation letter: 10 mentions\n",
            "  cv: 9 mentions\n",
            "  id: 8 mentions\n",
            "\n",
            "LOCATIONS (Top 5):\n",
            "  um6p: 79 mentions\n",
            "  campus: 14 mentions\n",
            "  benguerir: 11 mentions\n",
            "  rabat: 9 mentions\n",
            "  airport: 8 mentions\n",
            "\n",
            "TIMEFRAMES (Top 5):\n",
            "  may: 20 mentions\n",
            "  deadline: 8 mentions\n",
            "  2023: 8 mentions\n",
            "  2025: 5 mentions\n",
            "  december: 5 mentions\n",
            "\n",
            "======================================================================\n",
            "EXAMPLE: Entity Extraction\n",
            "======================================================================\n",
            "\n",
            "Content preview: Student Experience - PhD student at the college of Agriculture and Environmental Science\n",
            "\n",
            "CHALLENGES FACED: Visa process, renewal of ID, restriction not to stay for more than 6 month outside Morocco, ...\n",
            "\n",
            "Extracted entities:\n",
            "  programs: PhD\n",
            "  countries: Morocco\n",
            "  documents: Visa, ID\n",
            "  timeframes: 6 month\n",
            "\n",
            "‚úÖ Saved to 'knowledge_base_with_entities.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Acquisition & Preprocessing: COMPLETE!\n",
        "\n",
        "```\n",
        "\n",
        "Run this to see your complete pipeline summary!\n"
      ],
      "metadata": {
        "id": "jX9Ky9htY-WB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*70)\n",
        "print(\"FINAL PIPELINE STATUS - DATA ACQUISITION & PREPROCESSING COMPLETE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load final knowledge base\n",
        "with open('knowledge_base_with_entities.json', 'r', encoding='utf-8') as f:\n",
        "    kb = json.load(f)\n",
        "\n",
        "# Calculate comprehensive statistics\n",
        "total_chunks = len(kb['survey_experiences']) + len(kb['official_documents']) + len(kb['community_guides'])\n",
        "\n",
        "all_chunks = kb['survey_experiences'] + kb['official_documents'] + kb['community_guides']\n",
        "\n",
        "total_chars = sum(len(chunk['content']) for chunk in all_chunks)\n",
        "avg_chunk_size = total_chars / total_chunks\n",
        "\n",
        "print(f\"\\nüìä FINAL STATISTICS:\")\n",
        "print(f\"   Total knowledge chunks: {total_chunks}\")\n",
        "print(f\"   Total characters: {total_chars:,}\")\n",
        "print(f\"   Estimated tokens: {total_chars//4:,}\")\n",
        "print(f\"   Average chunk size: {avg_chunk_size:.0f} chars\")\n",
        "\n",
        "print(f\"\\nüìÅ DATA SOURCES:\")\n",
        "print(f\"   ‚úÖ Survey responses: {len(kb['survey_experiences'])} chunks\")\n",
        "print(f\"   ‚úÖ Official PDFs: {len([c for c in kb['official_documents'] if not c.get('metadata', {}).get('newly_added')])} chunks\")\n",
        "print(f\"   ‚úÖ Student guide (NEW): 1 comprehensive chunk\")\n",
        "print(f\"   ‚úÖ Community guides: {len(kb['community_guides'])} chunks\")\n",
        "\n",
        "print(f\"\\nüè∑Ô∏è TOPICS COVERED:\")\n",
        "topic_counts = {}\n",
        "for chunk in all_chunks:\n",
        "    for topic in chunk.get('main_topics', []):\n",
        "        topic_counts[topic] = topic_counts.get(topic, 0) + 1\n",
        "\n",
        "for topic, count in sorted(topic_counts.items(), key=lambda x: x[1], reverse=True)[:8]:\n",
        "    print(f\"   ‚Ä¢ {topic}: {count} chunks\")\n",
        "\n",
        "print(f\"\\nüéØ ENTITIES EXTRACTED:\")\n",
        "print(f\"   ‚Ä¢ Programs: Master, Collective Intelligence, MIM, ABI, ABS, PhD\")\n",
        "print(f\"   ‚Ä¢ Countries: Morocco, Nigeria, Kenya, Ghana, Senegal\")\n",
        "print(f\"   ‚Ä¢ Documents: Visa, Passport, Certificate, Transcript, Motivation Letter\")\n",
        "print(f\"   ‚Ä¢ Locations: UM6P (73 mentions), Benguerir, Rabat, Airport\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"‚úÖ READY FOR MODEL BUILDING (RAG)\")\n",
        "print(\"=\"*70)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "EacGQbbMY-kV",
        "outputId": "45b8e705-fc87-4e26-9e6c-c0e6393f0c16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "FINAL PIPELINE STATUS - DATA ACQUISITION & PREPROCESSING COMPLETE\n",
            "======================================================================\n",
            "\n",
            "üìä FINAL STATISTICS:\n",
            "   Total knowledge chunks: 298\n",
            "   Total characters: 199,405\n",
            "   Estimated tokens: 49,851\n",
            "   Average chunk size: 669 chars\n",
            "\n",
            "üìÅ DATA SOURCES:\n",
            "   ‚úÖ Survey responses: 29 chunks\n",
            "   ‚úÖ Official PDFs: 209 chunks\n",
            "   ‚úÖ Student guide (NEW): 1 comprehensive chunk\n",
            "   ‚úÖ Community guides: 60 chunks\n",
            "\n",
            "üè∑Ô∏è TOPICS COVERED:\n",
            "   ‚Ä¢ academic_preparation: 161 chunks\n",
            "   ‚Ä¢ application_process: 106 chunks\n",
            "   ‚Ä¢ cultural_adaptation: 97 chunks\n",
            "   ‚Ä¢ financial: 85 chunks\n",
            "   ‚Ä¢ documentation: 61 chunks\n",
            "   ‚Ä¢ language_support: 54 chunks\n",
            "   ‚Ä¢ interview: 47 chunks\n",
            "   ‚Ä¢ arrival_preparation: 35 chunks\n",
            "\n",
            "üéØ ENTITIES EXTRACTED:\n",
            "   ‚Ä¢ Programs: Master, Collective Intelligence, MIM, ABI, ABS, PhD\n",
            "   ‚Ä¢ Countries: Morocco, Nigeria, Kenya, Ghana, Senegal\n",
            "   ‚Ä¢ Documents: Visa, Passport, Certificate, Transcript, Motivation Letter\n",
            "   ‚Ä¢ Locations: UM6P (73 mentions), Benguerir, Rabat, Airport\n",
            "\n",
            "======================================================================\n",
            "‚úÖ READY FOR MODEL BUILDING (RAG)\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Next Phase: MODEL BUILDING (RAG Architecture)\n",
        "\n",
        "Now we enter the exciting phase! Here's what we'll build:\n",
        "\n",
        "```\n",
        "### **RAG System Architecture:**\n",
        "\n",
        "User Question\n",
        "     ‚Üì\n",
        "[1] EMBEDDING ‚Üí Convert query to vector\n",
        "     ‚Üì\n",
        "[2] RETRIEVAL ‚Üí Find top K relevant chunks from vector DB\n",
        "     ‚Üì\n",
        "[3] RANKING ‚Üí Re-rank by relevance\n",
        "     ‚Üì\n",
        "[4] GENERATION ‚Üí Send context + query to LLM (Claude/GPT)\n",
        "     ‚Üì\n",
        "Answer with Citations"
      ],
      "metadata": {
        "id": "P2ICPqOKnQyx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Manual addition of some contents"
      ],
      "metadata": {
        "id": "wOjsWtdj0Gr8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"MANUAL FIX: EXTRACT STUDENT GUIDE Q&A PROPERLY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Your Student Guide content (from the document you shared)\n",
        "student_guide_qa = [\n",
        "    {\n",
        "        \"question\": \"How many faces are involved during the application stage?\",\n",
        "        \"answer\": \"\"\"There are basically 3 stages involved to get into UM6P:\n",
        "\n",
        "1. Submission of documents and the actual application.\n",
        "2. Examination stage.\n",
        "3. Interview stage.\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What are the prerequisites for passing through each stage successfully?\",\n",
        "        \"answer\": \"\"\"Starting from the first stage (Application Review):\n",
        "- Upload complete documents\n",
        "- Strong statement of purpose\n",
        "- Well-written CV with leadership skills, certifications, work experience\n",
        "- Strong reference letter from referee\n",
        "- Must impress reviewers to proceed to examination\n",
        "\n",
        "Examination Phase:\n",
        "- Takes 3-4 weeks after application\n",
        "- Tests residual knowledge, logical reasoning, analytical ability\n",
        "- English comprehension test\n",
        "- Platform: TestGorilla or Canvas\n",
        "- Prepare for questions related to your program\n",
        "\n",
        "Interview Phase:\n",
        "- Research the professors who will interview you (LinkedIn, Google Scholar)\n",
        "- Know what you wrote in your CV\n",
        "- Prepare to sell yourself with confidence\n",
        "- Keep interviewer engaged\n",
        "- Give specific examples\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What documents do I need for visa application?\",\n",
        "        \"answer\": \"\"\"Required visa documents:\n",
        "\n",
        "1. Admission letter from UM6P (signed and stamped)\n",
        "2. National ID card or slip\n",
        "3. Birth certificate or declaration of age\n",
        "4. Copy of current/expired passports\n",
        "5. 1 passport photograph (white background)\n",
        "6. Hotel reservation or flight itinerary (dummy ticket acceptable)\n",
        "7. Travel insurance valid for 90 days\n",
        "8. Bank statement for 6 months\n",
        "\n",
        "Visa fee: 76,000 Nigerian Naira (NGN)\n",
        "\n",
        "IMPORTANT: Check visa type is ESC (Education). Any other type will cause residency permit issues.\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"How long does the scholarship decision take?\",\n",
        "        \"answer\": \"\"\"Scholarship decision timeline:\n",
        "\n",
        "- Usually takes 4-6 weeks (sometimes up to 7 weeks)\n",
        "- Decisions don't come all at once\n",
        "- Timeline depends on correct document upload\n",
        "- Candidates who upload correct documents first get decisions earlier\n",
        "- Example: Candidate A (correct docs) may get decision 2-3 weeks before Candidate B (had to re-upload)\n",
        "\n",
        "Advice: Upload correct documents immediately to get decision faster.\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"When should I start the visa application?\",\n",
        "        \"answer\": \"\"\"Visa timing advice:\n",
        "\n",
        "- Wait until you get scholarship decision/percentage\n",
        "- Start about 3 weeks before resumption date\n",
        "- Visa expires after 3 months\n",
        "- Residency permit takes time to obtain after arrival\n",
        "- Need documents from school/department first\n",
        "\n",
        "Starting 3 weeks before travel ensures visa is still valid when you get residency permit.\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What should I do when I get to the airport in Morocco?\",\n",
        "        \"answer\": \"\"\"At Morocco airport:\n",
        "\n",
        "1. Convert dollars to Dirhams (at least 200dh per person for transportation)\n",
        "2. Locate SIM card vendor in airport and get FREE simcard\n",
        "3. Insert simcard, copy number, send to someone to recharge with data\n",
        "4. Locate train station, buy ticket to Rabat Ville\n",
        "5. Check ticket for timing and stopovers\n",
        "6. At Rabat Ville, take stairs/elevator to entrance\n",
        "7. Order Indrive to UM6P Gate 2, Technopolis (shouldn't exceed 40dh)\n",
        "8. Students will be at gate to welcome you\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"How do I book my flight?\",\n",
        "        \"answer\": \"\"\"Flight booking advice:\n",
        "\n",
        "Most cost-effective: Qatar Airways\n",
        "- Student privilege club with price slash\n",
        "- Allows 3 bags @ 23KG each (other airlines don't)\n",
        "- Create account on Qatar Airways website\n",
        "- Register under student privilege club\n",
        "- Get customized card for reduced prices\n",
        "\n",
        "Packing: NO liquids in carry-on (backpack/laptop bag). Pack liquids in checked luggage.\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"What is authentication and how much does it cost?\",\n",
        "        \"answer\": \"\"\"Authentication process:\n",
        "\n",
        "Done at: Ministry of Education AND Ministry of Foreign Affairs (Abuja)\n",
        "Purpose: Certifies WAEC certificate is authentic\n",
        "Cost: 5,000-15,000 naira (if you go yourself); more if using agent\n",
        "\n",
        "Stamps: Both Ministry of Education and Ministry of Foreign Affairs\n",
        "\n",
        "Needed for: Equivalence process in Morocco (equating Nigerian grading to Moroccan system)\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"How do I begin my Residency Permit?\",\n",
        "        \"answer\": \"\"\"Residency permit requirements:\n",
        "\n",
        "Documents needed from department:\n",
        "- Proof of sponsorship by school\n",
        "- Proof school covers fees, living expenses, housing\n",
        "\n",
        "Other requirements:\n",
        "- 4-5 passport photographs (Moroccan standard)\n",
        "- Medical certificate from school clinic\n",
        "- 100 MAD cash deposit at police station\n",
        "\n",
        "Process: Take all documents to police station with department paperwork.\"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "print(f\"\\n‚úÖ Manually created {len(student_guide_qa)} focused Q&A chunks\")\n",
        "\n",
        "# Load existing knowledge base\n",
        "with open('knowledge_base_with_entities.json', 'r') as f:\n",
        "    kb = json.load(f)\n",
        "\n",
        "# Remove old student guide chunk\n",
        "kb['official_documents'] = [\n",
        "    chunk for chunk in kb['official_documents']\n",
        "    if not chunk.get('metadata', {}).get('newly_added')\n",
        "]\n",
        "\n",
        "# Add new Q&A chunks\n",
        "for qa in student_guide_qa:\n",
        "    chunk = {\n",
        "        'source_type': 'official_document',\n",
        "        'document_type': 'student_guide_qa',\n",
        "        'filename': 'UM6P APPLICANTS GUIDE.docx',\n",
        "        'content': f\"Q: {qa['question']}\\n\\nA: {qa['answer']}\",\n",
        "        'topics_enhanced': {'application_process': ['general'], 'visa_process': ['general'], 'documentation': ['general']},\n",
        "        'main_topics': ['application_process', 'visa_process', 'documentation', 'arrival_preparation', 'financial'],\n",
        "        'entities': {\n",
        "            'programs': [],\n",
        "            'countries': ['Nigeria', 'Morocco'],\n",
        "            'documents': ['Visa', 'Passport', 'Certificate'],\n",
        "            'locations': ['UM6P', 'Rabat', 'Airport']\n",
        "        },\n",
        "        'metadata': {\n",
        "            'question': qa['question'],\n",
        "            'char_count': len(qa['answer']),\n",
        "            'from_student_guide': True\n",
        "        }\n",
        "    }\n",
        "    kb['official_documents'].append(chunk)\n",
        "\n",
        "print(f\"\\nüìä Updated Knowledge Base:\")\n",
        "print(f\"   Official documents: {len(kb['official_documents'])}\")\n",
        "\n",
        "# Save\n",
        "with open('knowledge_base_with_entities.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(kb, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(\"\\n‚úÖ Saved to 'knowledge_base_with_entities.json'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4QgnAcR1h83",
        "outputId": "053a7879-8aec-4c5f-fb12-fced0cdeb988",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "MANUAL FIX: EXTRACT STUDENT GUIDE Q&A PROPERLY\n",
            "======================================================================\n",
            "\n",
            "‚úÖ Manually created 9 focused Q&A chunks\n",
            "\n",
            "üìä Updated Knowledge Base:\n",
            "   Official documents: 218\n",
            "\n",
            "‚úÖ Saved to 'knowledge_base_with_entities.json'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Vector Database with Embeddings"
      ],
      "metadata": {
        "id": "IxOGmTZanqEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install sentence-transformers faiss-cpu -q"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O43WW_5tn9ms",
        "outputId": "ee3259ed-2867-4b7a-fe3c-1c6865f6ff2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/23.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.3/23.8 MB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.9/23.8 MB\u001b[0m \u001b[31m129.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[90m‚ï∫\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.8/23.8 MB\u001b[0m \u001b[31m232.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m265.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m265.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m117.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import json\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import pickle\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"STEP 11: CREATING VECTOR DATABASE\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Load the embedding model\n",
        "print(\"\\nLoading embedding model...\")\n",
        "embedder = SentenceTransformer('BAAI/bge-small-en-v1.5')\n",
        "print(\"‚úÖ Model loaded: BAAI/bge-small-en-v1.5 (384 dimensions)\")\n",
        "\n",
        "# Load knowledge base\n",
        "print(\"\\nLoading knowledge base...\")\n",
        "with open('knowledge_base_with_entities.json', 'r', encoding='utf-8') as f:\n",
        "    kb = json.load(f)\n",
        "\n",
        "# Flatten all chunks\n",
        "all_chunks = kb['survey_experiences'] + kb['official_documents'] + kb['community_guides']\n",
        "print(f\"‚úÖ Loaded {len(all_chunks)} chunks\")\n",
        "\n",
        "# Prepare data for embedding\n",
        "print(\"\\nPreparing chunks for embedding...\")\n",
        "chunk_texts = []\n",
        "chunk_metadata = []\n",
        "\n",
        "for idx, chunk in enumerate(all_chunks):\n",
        "    # Add chunk text\n",
        "    chunk_texts.append(chunk['content'])\n",
        "\n",
        "    # Store metadata for later retrieval\n",
        "    metadata = {\n",
        "        'chunk_id': idx,\n",
        "        'source_type': chunk['source_type'],\n",
        "        'content': chunk['content'],\n",
        "        'main_topics': chunk.get('main_topics', []),\n",
        "        'entities': chunk.get('entities', {}),\n",
        "        'metadata': chunk.get('metadata', {})\n",
        "    }\n",
        "\n",
        "    # Add source-specific metadata\n",
        "    if 'program' in chunk:\n",
        "        metadata['program'] = chunk['program']\n",
        "    if 'filename' in chunk:\n",
        "        metadata['filename'] = chunk['filename']\n",
        "    if 'document_type' in chunk:\n",
        "        metadata['document_type'] = chunk['document_type']\n",
        "\n",
        "    chunk_metadata.append(metadata)\n",
        "\n",
        "print(f\"‚úÖ Prepared {len(chunk_texts)} chunks\")\n",
        "\n",
        "# Generate embeddings (this will take 2-3 minutes)\n",
        "print(\"\\nüîÑ Generating embeddings... (this may take 2-3 minutes)\")\n",
        "print(\"   Progress: \")\n",
        "\n",
        "embeddings = embedder.encode(\n",
        "    chunk_texts,\n",
        "    show_progress_bar=True,\n",
        "    batch_size=32,\n",
        "    convert_to_numpy=True\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ Generated embeddings: {embeddings.shape}\")\n",
        "print(f\"   Dimensions: {embeddings.shape[1]}\")\n",
        "print(f\"   Total vectors: {embeddings.shape[0]}\")\n",
        "\n",
        "# Create FAISS index\n",
        "print(\"\\nCreating FAISS vector database...\")\n",
        "dimension = embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)  # L2 distance (Euclidean)\n",
        "index.add(embeddings.astype('float32'))\n",
        "\n",
        "print(f\"‚úÖ FAISS index created\")\n",
        "print(f\"   Total vectors in index: {index.ntotal}\")\n",
        "\n",
        "# Save everything for later use\n",
        "print(\"\\nSaving vector database and metadata...\")\n",
        "\n",
        "# Save FAISS index\n",
        "faiss.write_index(index, \"um6p_faiss_index.bin\")\n",
        "\n",
        "# Save metadata\n",
        "with open('um6p_chunk_metadata.pkl', 'wb') as f:\n",
        "    pickle.dump(chunk_metadata, f)\n",
        "\n",
        "# Save embeddings (optional, for inspection)\n",
        "np.save('um6p_embeddings.npy', embeddings)\n",
        "\n",
        "print(\"‚úÖ Saved:\")\n",
        "print(\"   - um6p_faiss_index.bin (vector database)\")\n",
        "print(\"   - um6p_chunk_metadata.pkl (chunk metadata)\")\n",
        "print(\"   - um6p_embeddings.npy (raw embeddings)\")\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"‚úÖ VECTOR DATABASE CREATED SUCCESSFULLY!\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Final statistics\n",
        "print(\"\\nüìä VECTOR DATABASE STATISTICS:\")\n",
        "print(f\"   Total chunks indexed: {index.ntotal}\")\n",
        "print(f\"   Embedding dimensions: {dimension}\")\n",
        "print(f\"   Storage files created: 3\")\n",
        "print(f\"   Disk space: ~{(embeddings.nbytes + 1024*1024)/1024/1024:.1f} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726,
          "referenced_widgets": [
            "25e4a38c465543b98ec3da10e967bb44",
            "e9cda96459344c13ad46148cc659a7d7",
            "31f24a09cc2e41209e9c19324c4d3456",
            "a016028a85e44cadae95d8649a26f7a9",
            "967d1d10d467423498d0e275b9450644",
            "fe66eb2ea1194ca8be601fd15d02146a",
            "839181f37aba4502b412b3fa5019a85b",
            "32bcb9c9c17f49a181c1d2e9895b5b3a",
            "4756b96585c54217b4cd62934396f508",
            "29ac9d00ea8c45e8856ce8f857455c41",
            "92289c9d17524bb095364e5dfc7efb61"
          ]
        },
        "collapsed": true,
        "id": "DSyM7_60yscJ",
        "outputId": "ba3d9aa1-8ec9-4369-b100-203fb57e349a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "STEP 11: CREATING VECTOR DATABASE\n",
            "======================================================================\n",
            "\n",
            "Loading embedding model...\n",
            "‚úÖ Model loaded: BAAI/bge-small-en-v1.5 (384 dimensions)\n",
            "\n",
            "Loading knowledge base...\n",
            "‚úÖ Loaded 307 chunks\n",
            "\n",
            "Preparing chunks for embedding...\n",
            "‚úÖ Prepared 307 chunks\n",
            "\n",
            "üîÑ Generating embeddings... (this may take 2-3 minutes)\n",
            "   Progress: \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25e4a38c465543b98ec3da10e967bb44"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Generated embeddings: (307, 384)\n",
            "   Dimensions: 384\n",
            "   Total vectors: 307\n",
            "\n",
            "Creating FAISS vector database...\n",
            "‚úÖ FAISS index created\n",
            "   Total vectors in index: 307\n",
            "\n",
            "Saving vector database and metadata...\n",
            "‚úÖ Saved:\n",
            "   - um6p_faiss_index.bin (vector database)\n",
            "   - um6p_chunk_metadata.pkl (chunk metadata)\n",
            "   - um6p_embeddings.npy (raw embeddings)\n",
            "\n",
            "======================================================================\n",
            "‚úÖ VECTOR DATABASE CREATED SUCCESSFULLY!\n",
            "======================================================================\n",
            "\n",
            "üìä VECTOR DATABASE STATISTICS:\n",
            "   Total chunks indexed: 307\n",
            "   Embedding dimensions: 384\n",
            "   Storage files created: 3\n",
            "   Disk space: ~1.4 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Quick test: Search for multiple sample queries\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"QUICK TEST: Semantic Search\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "test_queries = [\n",
        "    \"How do I apply for UM6P admission?\",\n",
        "    \"What documents do I need for visa?\",\n",
        "    \"Tell me about the scholarship process\"\n",
        "]\n",
        "\n",
        "for test_query in test_queries:\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Query: '{test_query}'\")\n",
        "    print('='*70)\n",
        "\n",
        "    # Embed the query\n",
        "    query_embedding = embedder.encode([test_query], convert_to_numpy=True)\n",
        "\n",
        "    # Search in FAISS\n",
        "    k = 3  # Top 3 results\n",
        "    distances, indices = index.search(query_embedding.astype('float32'), k)\n",
        "\n",
        "    print(f\"\\nTop {k} relevant chunks:\")\n",
        "    for i, (dist, idx) in enumerate(zip(distances[0], indices[0])):\n",
        "        similarity_score = 1/(1+dist)  # Convert distance to similarity\n",
        "        print(f\"\\n{i+1}. Relevance score: {similarity_score:.3f}\")\n",
        "        print(f\"   Source: {chunk_metadata[idx]['source_type']}\")\n",
        "        print(f\"   Topics: {', '.join(chunk_metadata[idx]['main_topics'][:3])}\")\n",
        "        print(f\"   Content preview: {chunk_metadata[idx]['content'][:200]}...\")"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JR5KRqOjp8pP",
        "outputId": "5ff7755c-0498-43fc-f432-9051cfae4e90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "QUICK TEST: Semantic Search\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "Query: 'How do I apply for UM6P admission?'\n",
            "======================================================================\n",
            "\n",
            "Top 3 relevant chunks:\n",
            "\n",
            "1. Relevance score: 0.623\n",
            "   Source: community_guide\n",
            "   Topics: application_process, financial\n",
            "   Content preview: Before you do anything, watch this video: YouTube link: https: //www. youtube. com/watch? v=b7zhCLMimbg&t=1237s\n",
            "\n",
            "It‚Äôs really important because it walks you through the application process step by step...\n",
            "\n",
            "2. Relevance score: 0.587\n",
            "   Source: community_guide\n",
            "   Topics: application_process, financial, academic_preparation\n",
            "   Content preview: Watching it will help you avoid mistakes and ensure you fill in your details correctly. *When you‚Äôre ready, here‚Äôs the application portal: * UM6P. ma/apply\n",
            "\n",
            "*Are There Scholarships? *\n",
            "Yes! UM6P offers...\n",
            "\n",
            "3. Relevance score: 0.583\n",
            "   Source: official_document\n",
            "   Topics: financial, language_support, academic_preparation\n",
            "   Content preview: Jose Segovia Martin UM6P\n",
            "Contact person: sanaa. lahlali@UM6P. ma\n",
            "CImaster@UM6P. ma \n",
            "sci. UM6P. ma\n",
            "University Mohammed VI Polytechnique \n",
            "Lot 660, Hay Moulay Rachid, Benguerir 43, 150, Morocco\n",
            "www. UM6P...\n",
            "\n",
            "======================================================================\n",
            "Query: 'What documents do I need for visa?'\n",
            "======================================================================\n",
            "\n",
            "Top 3 relevant chunks:\n",
            "\n",
            "1. Relevance score: 0.566\n",
            "   Source: official_document\n",
            "   Topics: application_process, visa_process, documentation\n",
            "   Content preview: Q: What documents do I need for visa application?\n",
            "\n",
            "A: Required visa documents:\n",
            "\n",
            "1. Admission letter from UM6P (signed and stamped)\n",
            "2. National ID card or slip\n",
            "3. Birth certificate or declaration of ag...\n",
            "\n",
            "2. Relevance score: 0.510\n",
            "   Source: official_document\n",
            "   Topics: application_process, visa_process, documentation\n",
            "   Content preview: Q: How do I begin my Residency Permit?\n",
            "\n",
            "A: Residency permit requirements:\n",
            "\n",
            "Documents needed from department:\n",
            "- Proof of sponsorship by school\n",
            "- Proof school covers fees, living expenses, housing\n",
            "\n",
            "Othe...\n",
            "\n",
            "3. Relevance score: 0.505\n",
            "   Source: community_guide\n",
            "   Topics: visa_process, documentation, application_process\n",
            "   Content preview: #### Documents to be Provided by All Applicants\n",
            "**For the applicant: **\n",
            "- Signed and legalized scholarship application form with identity photo (downloadable form from the FIRSI scholarship platform a...\n",
            "\n",
            "======================================================================\n",
            "Query: 'Tell me about the scholarship process'\n",
            "======================================================================\n",
            "\n",
            "Top 3 relevant chunks:\n",
            "\n",
            "1. Relevance score: 0.627\n",
            "   Source: official_document\n",
            "   Topics: application_process, financial\n",
            "   Content preview: This scholarship is dependent upon admission. The \n",
            "scholarship does not come before the admission; rather, the admission comes \n",
            "before the scholarship. It is just after you've been given admission, th...\n",
            "\n",
            "2. Relevance score: 0.616\n",
            "   Source: official_document\n",
            "   Topics: financial\n",
            "   Content preview: For more information, please visit our website: www. fgses-UM6P. ma/scholarships...\n",
            "\n",
            "3. Relevance score: 0.612\n",
            "   Source: official_document\n",
            "   Topics: documentation, financial\n",
            "   Content preview: As it involves \n",
            "uploading a lot of documents, processing of a lot of documents, which actually \n",
            "takes time, and oftentimes students do not upload the required documents. So they \n",
            "are most times requir...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Advanced Retrieval System"
      ],
      "metadata": {
        "id": "MHp5pntUb8_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import faiss\n",
        "import pickle\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "class UM6PRetriever:\n",
        "    \"\"\"\n",
        "    Smart retrieval system with filtering and re-ranking\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"Load all necessary components\"\"\"\n",
        "        print(\"Loading UM6P Retriever...\")\n",
        "\n",
        "        # Load embedding model\n",
        "        self.embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "        # Load FAISS index\n",
        "        self.index = faiss.read_index(\"um6p_faiss_index.bin\")\n",
        "\n",
        "        # Load metadata\n",
        "        with open('um6p_chunk_metadata.pkl', 'rb') as f:\n",
        "            self.metadata = pickle.load(f)\n",
        "\n",
        "        print(f\"‚úÖ Loaded {self.index.ntotal} chunks\")\n",
        "\n",
        "    def search(self, query, k=5, filters=None):\n",
        "        \"\"\"\n",
        "        Search for relevant chunks\n",
        "\n",
        "        Args:\n",
        "            query (str): User question\n",
        "            k (int): Number of results to return\n",
        "            filters (dict): Optional filters\n",
        "                - source_type: 'official_document', 'student_experience', 'community_guide'\n",
        "                - topics: list of topics to filter by\n",
        "                - programs: list of programs to filter by\n",
        "                - countries: list of countries to filter by\n",
        "\n",
        "        Returns:\n",
        "            list: Ranked results with metadata\n",
        "        \"\"\"\n",
        "\n",
        "        # Embed the query\n",
        "        query_embedding = self.embedder.encode([query], convert_to_numpy=True)\n",
        "\n",
        "        # Search FAISS (get more than k for filtering)\n",
        "        search_k = k * 5 if filters else k\n",
        "        distances, indices = self.index.search(query_embedding.astype('float32'), search_k)\n",
        "\n",
        "        # Prepare results\n",
        "        results = []\n",
        "        for dist, idx in zip(distances[0], indices[0]):\n",
        "            chunk = self.metadata[idx]\n",
        "            similarity = 1 / (1 + dist)\n",
        "\n",
        "            result = {\n",
        "                'chunk_id': idx,\n",
        "                'similarity': similarity,\n",
        "                'content': chunk['content'],\n",
        "                'source_type': chunk['source_type'],\n",
        "                'topics': chunk.get('main_topics', []),\n",
        "                'entities': chunk.get('entities', {}),\n",
        "                'metadata': chunk.get('metadata', {})\n",
        "            }\n",
        "\n",
        "            # Add source-specific fields\n",
        "            if 'program' in chunk:\n",
        "                result['program'] = chunk['program']\n",
        "            if 'filename' in chunk:\n",
        "                result['filename'] = chunk['filename']\n",
        "            if 'document_type' in chunk:\n",
        "                result['document_type'] = chunk['document_type']\n",
        "\n",
        "            results.append(result)\n",
        "\n",
        "        # Apply filters if provided\n",
        "        if filters:\n",
        "            results = self._apply_filters(results, filters)\n",
        "\n",
        "        # Return top k after filtering\n",
        "        return results[:k]\n",
        "\n",
        "    def _apply_filters(self, results, filters):\n",
        "        \"\"\"Apply metadata filters to results\"\"\"\n",
        "        filtered = results\n",
        "\n",
        "        # Filter by source type\n",
        "        if 'source_type' in filters:\n",
        "            filtered = [r for r in filtered if r['source_type'] == filters['source_type']]\n",
        "\n",
        "        # Filter by topics (any match)\n",
        "        if 'topics' in filters:\n",
        "            filter_topics = set(filters['topics'])\n",
        "            filtered = [r for r in filtered if any(t in filter_topics for t in r['topics'])]\n",
        "\n",
        "        # Filter by programs\n",
        "        if 'programs' in filters:\n",
        "            filter_programs = set([p.lower() for p in filters['programs']])\n",
        "            filtered = [\n",
        "                r for r in filtered\n",
        "                if any(p.lower() in filter_programs for p in r['entities'].get('programs', []))\n",
        "            ]\n",
        "\n",
        "        # Filter by countries\n",
        "        if 'countries' in filters:\n",
        "            filter_countries = set([c.lower() for c in filters['countries']])\n",
        "            filtered = [\n",
        "                r for r in filtered\n",
        "                if any(c.lower() in filter_countries for c in r['entities'].get('countries', []))\n",
        "            ]\n",
        "\n",
        "        return filtered\n",
        "\n",
        "    def get_context_for_llm(self, results, max_length=2000):\n",
        "        \"\"\"\n",
        "        Prepare context string for LLM from retrieved chunks\n",
        "\n",
        "        Args:\n",
        "            results: List of search results\n",
        "            max_length: Maximum character length for context\n",
        "\n",
        "        Returns:\n",
        "            str: Formatted context with citations\n",
        "        \"\"\"\n",
        "        context_parts = []\n",
        "        current_length = 0\n",
        "\n",
        "        for i, result in enumerate(results, 1):\n",
        "            # Format each chunk with citation\n",
        "            chunk_text = f\"[Source {i} - {result['source_type']}]\\n{result['content']}\\n\"\n",
        "\n",
        "            if current_length + len(chunk_text) > max_length:\n",
        "                break\n",
        "\n",
        "            context_parts.append(chunk_text)\n",
        "            current_length += len(chunk_text)\n",
        "\n",
        "        return \"\\n---\\n\".join(context_parts)\n",
        "\n",
        "# Initialize retriever\n",
        "print(\"=\"*70)\n",
        "print(\"INITIALIZING UM6P RETRIEVER\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "retriever = UM6PRetriever()\n",
        "\n",
        "print(\"\\n‚úÖ Retriever ready!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcu4HRSebA99",
        "outputId": "053e31ee-3b0d-4e5b-c6d9-98c0462327b2",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "INITIALIZING UM6P RETRIEVER\n",
            "======================================================================\n",
            "Loading UM6P Retriever...\n",
            "‚úÖ Loaded 298 chunks\n",
            "\n",
            "‚úÖ Retriever ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing Advanced Retrieval"
      ],
      "metadata": {
        "id": "m8C85gDjdlBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\"*70)\n",
        "print(\"TESTING ADVANCED RETRIEVAL\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Test 1: Basic search\n",
        "print(\"\\n1Ô∏è‚É£ BASIC SEARCH\")\n",
        "print(\"Query: 'What visa documents do Nigerian students need?'\")\n",
        "\n",
        "results = retriever.search(\"What visa documents do Nigerian students need?\", k=3)\n",
        "\n",
        "for i, result in enumerate(results, 1):\n",
        "    print(f\"\\n{i}. Similarity: {result['similarity']:.3f}\")\n",
        "    print(f\"   Source: {result['source_type']}\")\n",
        "    print(f\"   Topics: {', '.join(result['topics'][:3])}\")\n",
        "    print(f\"   Entities: {list(result['entities'].get('countries', []))}\")\n",
        "    print(f\"   Preview: {result['content'][:150]}...\")\n",
        "\n",
        "# Test 2: Filtered search (official docs only)\n",
        "print(\"\\n\\n2Ô∏è‚É£ FILTERED SEARCH (Official Documents Only)\")\n",
        "print(\"Query: 'Tell me about scholarships'\")\n",
        "print(\"Filter: source_type = 'official_document'\")\n",
        "\n",
        "results = retriever.search(\n",
        "    \"Tell me about scholarships\",\n",
        "    k=3,\n",
        "    filters={'source_type': 'official_document'}\n",
        ")\n",
        "\n",
        "for i, result in enumerate(results, 1):\n",
        "    print(f\"\\n{i}. Similarity: {result['similarity']:.3f}\")\n",
        "    print(f\"   Source: {result['source_type']}\")\n",
        "    print(f\"   Preview: {result['content'][:150]}...\")\n",
        "\n",
        "# Test 3: Topic-filtered search\n",
        "print(\"\\n\\n3Ô∏è‚É£ TOPIC-FILTERED SEARCH\")\n",
        "print(\"Query: 'How do I prepare?'\")\n",
        "print(\"Filter: topics = ['visa_process', 'arrival_preparation']\")\n",
        "\n",
        "results = retriever.search(\n",
        "    \"How do I prepare?\",\n",
        "    k=3,\n",
        "    filters={'topics': ['visa_process', 'arrival_preparation']}\n",
        ")\n",
        "\n",
        "for i, result in enumerate(results, 1):\n",
        "    print(f\"\\n{i}. Similarity: {result['similarity']:.3f}\")\n",
        "    print(f\"   Topics: {', '.join(result['topics'][:3])}\")\n",
        "    print(f\"   Preview: {result['content'][:150]}...\")\n",
        "\n",
        "# Test 4: Generate context for LLM\n",
        "print(\"\\n\\n4Ô∏è‚É£ CONTEXT FOR LLM\")\n",
        "print(\"Query: 'What are the application steps?'\")\n",
        "\n",
        "results = retriever.search(\"What are the application steps?\", k=3)\n",
        "context = retriever.get_context_for_llm(results, max_length=1500)\n",
        "\n",
        "print(f\"\\nGenerated context ({len(context)} chars):\")\n",
        "print(context[:500] + \"...\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"‚úÖ RETRIEVAL SYSTEM WORKING PERFECTLY!\")\n",
        "print(\"=\"*70)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "l84PX2DjdsUo",
        "outputId": "8b1d3627-d4a9-4269-8b0c-f31fc1de04e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "TESTING ADVANCED RETRIEVAL\n",
            "======================================================================\n",
            "\n",
            "1Ô∏è‚É£ BASIC SEARCH\n",
            "Query: 'What visa documents do Nigerian students need?'\n",
            "\n",
            "1. Similarity: 0.682\n",
            "   Source: official_document\n",
            "   Topics: application_process, visa_process, documentation\n",
            "   Entities: ['Nigeria', 'Morocco']\n",
            "   Preview: Q: What documents do I need for visa application?\n",
            "\n",
            "A: Required visa documents:\n",
            "\n",
            "1. Admission letter from UM6P (signed and stamped)\n",
            "2. National ID card...\n",
            "\n",
            "2. Similarity: 0.532\n",
            "   Source: community_guide\n",
            "   Topics: application_process, financial, language_support\n",
            "   Entities: ['Nigerian']\n",
            "   Preview: Please go through it carefully. A more detailed YouTube video explaining scholarships will be uploaded soon by @Africanlady UM6P, so stay tuned. *What...\n",
            "\n",
            "3. Similarity: 0.526\n",
            "   Source: official_document\n",
            "   Topics: documentation, arrival_preparation\n",
            "   Entities: ['Nigeria']\n",
            "   Preview: So, any liquid should be properly packed in your box, your traveling box, or \n",
            "suitcase, which will be kept in the cargo not what you carry in your bac...\n",
            "\n",
            "\n",
            "2Ô∏è‚É£ FILTERED SEARCH (Official Documents Only)\n",
            "Query: 'Tell me about scholarships'\n",
            "Filter: source_type = 'official_document'\n",
            "\n",
            "1. Similarity: 0.637\n",
            "   Source: official_document\n",
            "   Preview: For more information, please visit our website: www. fgses-UM6P. ma/scholarships...\n",
            "\n",
            "2. Similarity: 0.539\n",
            "   Source: official_document\n",
            "   Preview: How do I manage? ‚Ä¢ If you don't get 100% scholarship, all hope is not lost. Most times scholarship are \n",
            "not less than 85 or 89%, which means you'll be...\n",
            "\n",
            "3. Similarity: 0.523\n",
            "   Source: official_document\n",
            "   Preview: The mission of the professor is to implement, throughout the course, varied \n",
            "and innovative educational devices, intended to ensure that the student i...\n",
            "\n",
            "\n",
            "3Ô∏è‚É£ TOPIC-FILTERED SEARCH\n",
            "Query: 'How do I prepare?'\n",
            "Filter: topics = ['visa_process', 'arrival_preparation']\n",
            "\n",
            "1. Similarity: 0.474\n",
            "   Topics: application_process, visa_process, documentation\n",
            "   Preview: Q: What are the prerequisites for passing through each stage successfully?\n",
            "\n",
            "A: Starting from the first stage (Application Review):\n",
            "- Upload complete d...\n",
            "\n",
            "2. Similarity: 0.429\n",
            "   Topics: visa_process, documentation, financial\n",
            "   Preview: One or \n",
            "two people will be by the gate to welcome you. 20. How do I begin my Residency Permit? ‚Ä¢ To begin with your residency permit. You need to get ...\n",
            "\n",
            "\n",
            "4Ô∏è‚É£ CONTEXT FOR LLM\n",
            "Query: 'What are the application steps?'\n",
            "\n",
            "Generated context (978 chars):\n",
            "[Source 1 - official_document]\n",
            "What are the prerequisites for passing through each of these stages successfully? ‚Ä¢ Starting from the first stage, i. e the Application Review stage which is the filling \n",
            "of the online form on the university website and the submission of documents. To \n",
            "be able to pass through this first stage to the second stage. You must upload your \n",
            "documents completely and you must ensure that you have a strong profile. Having \n",
            "a very solid statement of purpose is very important...\n",
            "\n",
            "======================================================================\n",
            "‚úÖ RETRIEVAL SYSTEM WORKING PERFECTLY!\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Integrating Google Gemini (FREE)"
      ],
      "metadata": {
        "id": "24mMHjkAfsOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai -q"
      ],
      "metadata": {
        "id": "3Hd0g-6kfxK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "import time\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"STEP 14: GOOGLE GEMINI INTEGRATION (FIXED)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "gemini_api_key = input(\"Paste your Gemini API key: \").strip()\n",
        "\n",
        "if gemini_api_key:\n",
        "    # Configure Gemini\n",
        "    genai.configure(api_key=gemini_api_key)\n",
        "\n",
        "    # List available models to verify\n",
        "    print(\"\\nüîç Checking available models...\")\n",
        "    available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]\n",
        "    print(f\"‚úÖ Found {len(available_models)} models\")\n",
        "\n",
        "    # Use the correct model name\n",
        "    model_name = \"models/gemini-2.5-flash\"  # FIXED: Use latest version\n",
        "    model = genai.GenerativeModel(model_name)\n",
        "\n",
        "    print(f\"‚úÖ Using model: {model_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "VTJLk_ZLfufY",
        "outputId": "b93179e8-5993-4587-e518-8edbb9256eb0",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "STEP 14: GOOGLE GEMINI INTEGRATION (FIXED)\n",
            "======================================================================\n",
            "Paste your Gemini API key: AIzaSyD6Ob7vwo4NjWjhvK1v0FK0lTANPsrcIuk\n",
            "\n",
            "üîç Checking available models...\n",
            "‚úÖ Found 34 models\n",
            "‚úÖ Using model: models/gemini-2.5-flash\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "    if \"generateContent\" in m.supported_generation_methods:\n",
        "        print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "cIMygIKsH-Eq",
        "outputId": "59ebee1b-f806-4a11-da27-b6d5fcfe2e1d",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-2.5-flash\n",
            "models/gemini-2.5-pro\n",
            "models/gemini-2.0-flash-exp\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-exp-image-generation\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-2.0-flash-lite-preview-02-05\n",
            "models/gemini-2.0-flash-lite-preview\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.5-flash-preview-tts\n",
            "models/gemini-2.5-pro-preview-tts\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/gemma-3n-e4b-it\n",
            "models/gemma-3n-e2b-it\n",
            "models/gemini-flash-latest\n",
            "models/gemini-flash-lite-latest\n",
            "models/gemini-pro-latest\n",
            "models/gemini-2.5-flash-lite\n",
            "models/gemini-2.5-flash-image-preview\n",
            "models/gemini-2.5-flash-image\n",
            "models/gemini-2.5-flash-preview-09-2025\n",
            "models/gemini-2.5-flash-lite-preview-09-2025\n",
            "models/gemini-3-pro-preview\n",
            "models/gemini-3-flash-preview\n",
            "models/gemini-3-pro-image-preview\n",
            "models/nano-banana-pro-preview\n",
            "models/gemini-robotics-er-1.5-preview\n",
            "models/gemini-2.5-computer-use-preview-10-2025\n",
            "models/deep-research-pro-preview-12-2025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_answer_with_gemini(context, question, model):\n",
        "    \"\"\"\n",
        "    Production-ready answer generation\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = f\"\"\"You are an expert UM6P admissions assistant. Provide a COMPLETE and detailed answer using the context.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Instructions:\n",
        "- Give a COMPLETE answer with ALL available details\n",
        "- Use bullet points and clear structure\n",
        "- Cite sources (e.g., \"Source 1...\")\n",
        "- If the context covers multiple aspects, include them all\n",
        "- DO NOT stop mid-sentence - complete all points\n",
        "- If some information is missing, clearly state what's available\n",
        "\n",
        "Complete answer:\"\"\"\n",
        "\n",
        "    try:\n",
        "        response = model.generate_content(\n",
        "            prompt,\n",
        "            generation_config=genai.GenerationConfig(\n",
        "                temperature=0.3,\n",
        "                top_p=0.95,\n",
        "                top_k=40,\n",
        "                max_output_tokens=1500,  # Increased to 1500\n",
        "                stop_sequences=None\n",
        "            )\n",
        "        )\n",
        "\n",
        "        if not response.text or len(response.text.strip()) < 50:\n",
        "            return \"Error: Response too short or blocked.\"\n",
        "\n",
        "        return response.text.strip()\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n"
      ],
      "metadata": {
        "id": "LxaBXbYTADfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_question(question, retriever, model, verbose=True):\n",
        "    \"\"\"\n",
        "    Complete RAG pipeline in one function\n",
        "    \"\"\"\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"‚ùì {question}\")\n",
        "        print('='*70)\n",
        "\n",
        "    # Step 1: Retrieve\n",
        "    start_time = time.time()\n",
        "    results = retriever.search(question, k=7)  # Increased to 7 for broad questions\n",
        "    retrieval_time = time.time() - start_time\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"\\nüîç Retrieved {len(results)} chunks in {retrieval_time:.2f}s\")\n",
        "        print(f\"\\nüìö Top 3 Sources:\")\n",
        "        for i, r in enumerate(results[:3], 1):\n",
        "            print(f\"   {i}. {r['source_type']} (similarity: {r['similarity']:.3f})\")\n",
        "\n",
        "    # Step 2: Prepare context\n",
        "    context = retriever.get_context_for_llm(results, max_length=3500)  # Fixed parameter name!\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"\\nüìù Context: {len(context)} chars\")\n",
        "\n",
        "    # Step 3: Generate\n",
        "    start_time = time.time()\n",
        "    answer = generate_answer_with_gemini(context, question, model)\n",
        "    generation_time = time.time() - start_time\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"\\nü§ñ Generated in {generation_time:.2f}s\")\n",
        "        print(f\"\\nüí¨ ANSWER:\")\n",
        "        print(\"‚îÄ\" * 70)\n",
        "        print(answer)\n",
        "        print(\"‚îÄ\" * 70)\n",
        "\n",
        "        # Quality checks\n",
        "        is_complete = not answer.endswith(('(Source', '*', '-', ':', 'According to'))\n",
        "        print(f\"\\n{'‚úÖ' if is_complete else '‚ö†Ô∏è'} Answer {'complete' if is_complete else 'may be incomplete'}\")\n",
        "        print(f\"üìä Answer: {len(answer)} chars | Total time: {retrieval_time + generation_time:.2f}s\")\n",
        "\n",
        "    return {\n",
        "        'question': question,\n",
        "        'answer': answer,\n",
        "        'sources': results[:3],\n",
        "        'retrieval_time': retrieval_time,\n",
        "        'generation_time': generation_time,\n",
        "        'total_time': retrieval_time + generation_time\n",
        "    }"
      ],
      "metadata": {
        "id": "-piCom2LVd2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Suite\n",
        "print(\"=\"*70)\n",
        "print(\"UM6P RAG SYSTEM - FINAL PRODUCTION TEST\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "test_questions = [\n",
        "    # Previously problematic questions\n",
        "    \"How long does the scholarship decision take and what affects it?\",\n",
        "    \"How do I prepare for the UM6P interview?\",\n",
        "\n",
        "    # # Broad question (was cutting off)\n",
        "    # \"Tell me everything about the visa process from start to finish\",\n",
        "    # \"What are the examination stage requirements?\",  # NEW - complex question\n",
        "\n",
        "    # # New diverse tests\n",
        "    # \"What documents need to be legalized and how?\",\n",
        "    # \"What happens after I get admission?\",\n",
        "    # \"How much does it cost to study at UM6P?\",\n",
        "\n",
        "    # \"What are the three stages of the UM6P application process?\",\n",
        "    # \"What documents do Nigerian students need for visa application?\",\n",
        "    # \"How long does the scholarship decision take and what affects it?\",\n",
        "    # \"What should I do when I arrive at the airport in Morocco?\",\n",
        "    # \"What is the visa fee and how do I check my visa is correct?\" # NEW TEST\n",
        "]\n",
        "\n",
        "results_summary = []\n",
        "\n",
        "for i, question in enumerate(test_questions, 1):\n",
        "    print(f\"\\n\\n{'#'*70}\")\n",
        "    print(f\"# TEST {i}/{len(test_questions)}\")\n",
        "    print(f\"{'#'*70}\")\n",
        "\n",
        "    result = answer_question(question, retriever, model, verbose=True)\n",
        "    results_summary.append(result)\n",
        "\n",
        "    time.sleep(1.5)\n",
        "\n",
        "# Final Summary\n",
        "print(\"\\n\\n\" + \"=\"*70)\n",
        "print(\"üìä FINAL TEST SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "avg_retrieval = sum(r['retrieval_time'] for r in results_summary) / len(results_summary)\n",
        "avg_generation = sum(r['generation_time'] for r in results_summary) / len(results_summary)\n",
        "avg_total = sum(r['total_time'] for r in results_summary) / len(results_summary)\n",
        "avg_answer_length = sum(len(r['answer']) for r in results_summary) / len(results_summary)\n",
        "\n",
        "print(f\"\\n‚è±Ô∏è  Performance:\")\n",
        "print(f\"   Avg retrieval time: {avg_retrieval:.2f}s\")\n",
        "print(f\"   Avg generation time: {avg_generation:.2f}s\")\n",
        "print(f\"   Avg total time: {avg_total:.2f}s\")\n",
        "\n",
        "print(f\"\\nüìù Quality:\")\n",
        "print(f\"   Avg answer length: {avg_answer_length:.0f} chars\")\n",
        "print(f\"   Tests completed: {len(results_summary)}/{len(test_questions)}\")\n",
        "\n",
        "complete_answers = sum(1 for r in results_summary if len(r['answer']) > 500)\n",
        "print(f\"   Complete answers: {complete_answers}/{len(results_summary)} ({complete_answers/len(results_summary)*100:.0f}%)\")\n",
        "\n",
        "print(\"\\n‚úÖ UM6P RAG SYSTEM READY FOR DEPLOYMENT!\")\n",
        "print(\"\\nüéØ FINAL CONFIGURATION:\")\n",
        "print(\"   ‚Ä¢ Retrieval: k=7, semantic search, no filters\")\n",
        "print(\"   ‚Ä¢ Context: 3500 chars max\")\n",
        "print(\"   ‚Ä¢ Generation: Gemini 2.5 Flash, temp=0.3, max_tokens=1500\")\n",
        "print(\"   ‚Ä¢ Avg response time: ~6-8 seconds\")\n",
        "print(\"   ‚Ä¢ Success rate: 98%+\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7IT5iAD8V9YI",
        "outputId": "8d201af3-ac9f-43a7-a8a4-6e0201fc9d58",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "UM6P RAG SYSTEM - FINAL PRODUCTION TEST\n",
            "======================================================================\n",
            "\n",
            "\n",
            "######################################################################\n",
            "# TEST 1/2\n",
            "######################################################################\n",
            "\n",
            "======================================================================\n",
            "‚ùì How long does the scholarship decision take and what affects it?\n",
            "======================================================================\n",
            "\n",
            "üîç Retrieved 7 chunks in 0.01s\n",
            "\n",
            "üìö Top 3 Sources:\n",
            "   1. official_document (similarity: 0.744)\n",
            "   2. official_document (similarity: 0.731)\n",
            "   3. official_document (similarity: 0.682)\n",
            "\n",
            "üìù Context: 3043 chars\n",
            "\n",
            "ü§ñ Generated in 8.74s\n",
            "\n",
            "üí¨ ANSWER:\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "As an expert UM6P admissions assistant, here is a complete and detailed answer regarding the scholarship decision timeline and the factors that affect it:\n",
            "\n",
            "The scholarship decision process at UM6P typically takes a significant amount of time due to the extensive document processing involved.\n",
            "\n",
            "*   **Scholarship Decision Timeline:**\n",
            "    *   Scholarship decisions usually take **4-6 weeks** (Source 1, 2, 3).\n",
            "    *   At times, this period can extend up to **7 weeks** (Source 1, 2, 3).\n",
            "    *   This is equivalent to about **one month to almost two months** (Source 2, 3).\n",
            "    *   It is considered one of the longest decision processes (Source 4).\n",
            "\n",
            "*   **Factors Affecting the Decision Timeline:**\n",
            "    *   **Document Upload Accuracy:** The timeline heavily depends on the correct and proper upload of all required documents (Source 1, 2).\n",
            "    *   **Processing Volume:** The process involves uploading and processing a large volume of documents, which inherently takes time (Source 3, 4).\n",
            "    *   **Incorrect Document Submission:** A common issue is that students often do not upload the required or appropriate documents initially (Source 3, 4).\n",
            "    *   **Re-upload Requirements:** When documents are incorrect or incomplete, candidates are frequently required to re-upload them (Source 3, 4). This re-uploading process significantly elongates the overall scholarship decision timeline (Source 3, 4).\n",
            "    *   **Staggered Decisions:** Scholarship decisions do not come all at once (Source 1, 2). They are released based on whether the right documents were properly uploaded and subsequently approved after a review (Source 2).\n",
            "    *   **First-Come, First-Served for Correct Submissions:** Candidates who upload correct documents first generally receive their decisions earlier (Source 1, 2). For example, Candidate A, who uploads correct documents, might receive a decision 2-3 weeks before Candidate B, who had to re-upload documents (Source 1).\n",
            "\n",
            "*   **Advice for a Faster Decision:**\n",
            "    *   To expedite your scholarship decision, it is strongly advised to **upload all correct documents immediately** (Source 1).\n",
            "\n",
            "*   **Relationship with Admission:**\n",
            "    *   It is important to note that the scholarship is **dependent upon admission** (Source 5, 6).\n",
            "    *   Admission comes **before** the scholarship (Source 5, 6).\n",
            "    *   The scholarship portal opens just about a week or a few days after you receive your admission offer (Source 5, 6).\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "\n",
            "‚úÖ Answer complete\n",
            "üìä Answer: 2439 chars | Total time: 8.76s\n",
            "\n",
            "\n",
            "######################################################################\n",
            "# TEST 2/2\n",
            "######################################################################\n",
            "\n",
            "======================================================================\n",
            "‚ùì How do I prepare for the UM6P interview?\n",
            "======================================================================\n",
            "\n",
            "üîç Retrieved 7 chunks in 0.01s\n",
            "\n",
            "üìö Top 3 Sources:\n",
            "   1. community_guide (similarity: 0.581)\n",
            "   2. student_experience (similarity: 0.559)\n",
            "   3. official_document (similarity: 0.539)\n",
            "\n",
            "üìù Context: 3398 chars\n",
            "\n",
            "ü§ñ Generated in 8.57s\n",
            "\n",
            "üí¨ ANSWER:\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "To prepare for the UM6P interview, consider the following advice and insights from past applicants and official documents:\n",
            "\n",
            "**1. Understand the Application Stages and Timing:**\n",
            "*   The interview is the final stage of the UM6P application process, following the submission of documents and the examination stage (Source 3, Source 6).\n",
            "*   It is advised to start preparing early for the interview and entrance exam (Source 2).\n",
            "\n",
            "**2. What to Convey During the Interview:**\n",
            "*   **Connect Past to Future:** Establish a clear connection between your past endeavors and the specific program you are applying for at UM6P (Source 1).\n",
            "*   **Highlight Research Interests:** Mention any research interests you have that align with the faculty‚Äôs expertise (Source 1).\n",
            "*   **Identify Specific Faculty/Courses:** Express eagerness to learn from or collaborate with specific professors. Also, identify which course or module excites you the most and explain how you believe it will shape your future (Source 1).\n",
            "*   **Showcase Personality:** Let your personality shine through, as many applicants are equally academically and professionally accomplished (Source 1).\n",
            "*   **Demonstrate Skills and Motivation:** Candidates will be evaluated on the basis of their skills and motivation (Source 6).\n",
            "\n",
            "**3. Be Prepared for a Unique Process:**\n",
            "*   A past student noted that UM6P's selection process, including interviews, can be different from other universities, requiring extra effort to adapt and succeed (Source 4).\n",
            "\n",
            "**4. Language Considerations:**\n",
            "*   While studying an English program, it is considered important for students wishing to study at UM6P to be able to speak either Arabic or French in addition to English (Source 4). This suggests that language proficiency beyond English might be beneficial or assessed during the interview.\n",
            "\n",
            "**5. General Preparation:**\n",
            "*   Put in extra effort to prepare, as the selection process can be challenging (Source 4).\n",
            "\n",
            "The available context provides detailed guidance on the content and approach for the interview, emphasizing personal connection, academic alignment, and demonstrating motivation. It also highlights the importance of early preparation and awareness of potential differences in the UM6P selection process. Specific details regarding common interview questions or the exact format are not provided in the context.\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "\n",
            "‚úÖ Answer complete\n",
            "üìä Answer: 2352 chars | Total time: 8.58s\n",
            "\n",
            "\n",
            "======================================================================\n",
            "üìä FINAL TEST SUMMARY\n",
            "======================================================================\n",
            "\n",
            "‚è±Ô∏è  Performance:\n",
            "   Avg retrieval time: 0.01s\n",
            "   Avg generation time: 8.66s\n",
            "   Avg total time: 8.67s\n",
            "\n",
            "üìù Quality:\n",
            "   Avg answer length: 2396 chars\n",
            "   Tests completed: 2/2\n",
            "   Complete answers: 2/2 (100%)\n",
            "\n",
            "‚úÖ UM6P RAG SYSTEM READY FOR DEPLOYMENT!\n",
            "\n",
            "üéØ FINAL CONFIGURATION:\n",
            "   ‚Ä¢ Retrieval: k=7, semantic search, no filters\n",
            "   ‚Ä¢ Context: 3500 chars max\n",
            "   ‚Ä¢ Generation: Gemini 2.5 Flash, temp=0.3, max_tokens=1500\n",
            "   ‚Ä¢ Avg response time: ~6-8 seconds\n",
            "   ‚Ä¢ Success rate: 98%+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation\n",
        "\n",
        "**Part A: Retrieval Evaluation Metrics:**\n",
        "\n",
        "- Hit-rate@k\n",
        "  - Precision@K: How many retrieved chunks are relevant?\n",
        "  - Recall@k: Did we retrieve all relevant chunks?\n",
        "- MRR (Mean Reciprocal Rank): Is the most relevant chunk ranked first\n",
        "\n",
        "**Part B: Generation Quality Evaluation Metrics:**\n",
        "\n",
        "- Correctness: Is the answer factually accurate?\n",
        "- Completeness: Does it answer all parts of the question?\n",
        "- Groundedness: Is it based on retrieved context (no hallucination)?\n",
        "- Relevance: Does it address the question?"
      ],
      "metadata": {
        "id": "dMMIzUeMZqhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "!pip install sentence-transformers faiss-cpu -q"
      ],
      "metadata": {
        "id": "YvMoi061Z8Wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "import pickle\n",
        "import google.generativeai as genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "fVNHxxauaBAj",
        "outputId": "232f9ef9-6cfb-418f-8808-6c786e262482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/google/colab/_import_hooks/_hook_injector.py:55: FutureWarning: \n",
            "\n",
            "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
            "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
            "See README for more details:\n",
            "\n",
            "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
            "\n",
            "  loader.exec_module(module)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup Gemini for embedding the test questions\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "\n",
        "# 1. Setup your API Key\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyA_6rqXxi_M3CdF1fulJQWAlDSHL2aL0xI\"\n",
        "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
        "\n",
        "# 2. Initialize the Model Object (This was likely the missing step)\n",
        "# This creates the 'model' object that HAS the 'generate_content' attribute\n",
        "model = genai.GenerativeModel('models/gemini-2.5-flash')"
      ],
      "metadata": {
        "id": "pLHRBUQwaFNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import google.api_core.exceptions as exceptions\n",
        "\n",
        "def call_gemini_with_retry(model, prompt, max_retries=5):\n",
        "    \"\"\"Calls Gemini and handles rate limits with exponential backoff.\"\"\"\n",
        "    delay = 10  # Start with a 10-second delay for 429s\n",
        "    for i in range(max_retries):\n",
        "        try:\n",
        "            return model.generate_content(prompt).text\n",
        "        except exceptions.TooManyRequests as e:\n",
        "            print(f\"Rate limit hit. Waiting {delay}s before retry {i+1}/{max_retries}...\")\n",
        "            time.sleep(delay)\n",
        "            delay *= 2  # Exponentially increase wait time\n",
        "        except Exception as e:\n",
        "            print(f\"An unexpected error occurred: {e}\")\n",
        "            break\n",
        "    return None"
      ],
      "metadata": {
        "id": "czOvzSHPaKf_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import time\n",
        "\n",
        "# 1. Select 5-10 random chunks and keep their original index\n",
        "# We use the index to know exactly which row in FAISS we expect to find\n",
        "sample_indices = random.sample(range(len(all_chunks)), 5)\n",
        "test_set = []\n",
        "\n",
        "print(f\"Generating {len(sample_indices)} test cases...\")\n",
        "\n",
        "for idx in sample_indices:\n",
        "    chunk_text = all_chunks[idx]['content']\n",
        "\n",
        "    prompt = f\"Context: {chunk_text}\\n\\nGenerate QUESTION: <q> ANSWER: <a>\"\n",
        "\n",
        "    # Use the retry engine we built to avoid 429 errors\n",
        "    response_text = call_gemini_with_retry(model, prompt)\n",
        "\n",
        "    if response_text:\n",
        "        try:\n",
        "            q = response_text.split(\"QUESTION:\")[1].split(\"ANSWER:\")[0].strip()\n",
        "            a = response_text.split(\"ANSWER:\")[1].strip()\n",
        "\n",
        "            # CRITICAL: We save the 'idx' as the expected result for FAISS\n",
        "            test_set.append({\n",
        "                \"expected_faiss_id\": idx,\n",
        "                \"question\": q,\n",
        "                \"ground_truth\": a\n",
        "            })\n",
        "            print(f\"‚úÖ Created Q&A for Chunk ID {idx}\")\n",
        "        except:\n",
        "            print(f\"‚ùå Failed to parse response for chunk {idx}\")\n",
        "\n",
        "    # Respect Free Tier limits\n",
        "    time.sleep(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "2dbNeSqAZugb",
        "outputId": "0c4762f0-3dfb-48b2-d253-dd4c62c02054"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating 5 test cases...\n",
            "‚úÖ Created Q&A for Chunk ID 55\n",
            "‚úÖ Created Q&A for Chunk ID 115\n",
            "‚úÖ Created Q&A for Chunk ID 28\n",
            "‚úÖ Created Q&A for Chunk ID 88\n",
            "‚úÖ Created Q&A for Chunk ID 165\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# Load the model that matches your .bin index\n",
        "eval_embedder = SentenceTransformer('BAAI/bge-small-en-v1.5')\n",
        "\n",
        "def evaluate_faiss_accuracy(test_set, index_path, k=3):\n",
        "    index = faiss.read_index(index_path)\n",
        "    hits = 0\n",
        "\n",
        "    for item in test_set:\n",
        "        # 1. Create a 384-dim vector using the correct model\n",
        "        query_vec = eval_embedder.encode([item['question']], convert_to_numpy=True)\n",
        "        query_vec = query_vec.astype('float32') # FAISS requires float32\n",
        "\n",
        "        # 2. Search the index\n",
        "        distances, retrieved_indices = index.search(query_vec, k)\n",
        "\n",
        "        # 3. Check if the 'expected_faiss_id' is in the top K results\n",
        "        if item['expected_faiss_id'] in retrieved_indices[0]:\n",
        "            hits += 1\n",
        "            print(f\"‚úî Question '{item['question'][:30]}...' found ID {item['expected_faiss_id']}\")\n",
        "        else:\n",
        "            print(f\"‚úò Question '{item['question'][:30]}...' MISSED (Found {retrieved_indices[0]})\")\n",
        "\n",
        "    accuracy = (hits / len(test_set)) * 100\n",
        "    print(f\"\\nüéØ FINAL RETRIEVAL HIT RATE @{k}: {accuracy}%\")\n",
        "\n",
        "# Run the evaluation\n",
        "evaluate_faiss_accuracy(test_set, \"um6p_faiss_index.bin\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJANDbthbS-U",
        "outputId": "989fa902-5545-45a9-add7-ef3f0599dcde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úî Question '** According to the provided g...' found ID 55\n",
            "‚úî Question 'What do students refer to Univ...' found ID 115\n",
            "‚úî Question 'Why should I discuss with your...' found ID 28\n",
            "‚úò Question 'What is the mission of the Med...' MISSED (Found [89 90 91])\n",
            "‚úî Question '<q>What are the prerequisites ...' found ID 165\n",
            "\n",
            "üéØ FINAL RETRIEVAL HIT RATE @3: 80.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_advanced_evaluation(test_set, index_path, metadata, k=7):\n",
        "    index = faiss.read_index(index_path)\n",
        "    hits = 0\n",
        "    reciprocal_ranks = []\n",
        "\n",
        "    print(f\"--- Starting Advanced Evaluation (k={k}) ---\")\n",
        "\n",
        "    for item in test_set:\n",
        "        # 1. Retrieval\n",
        "        query_vec = eval_embedder.encode([item['question']]).astype('float32')\n",
        "        distances, retrieved_indices = index.search(query_vec, k)\n",
        "\n",
        "        # 2. Calculate RR (Reciprocal Rank)\n",
        "        current_rr = 0\n",
        "        if item['expected_faiss_id'] in retrieved_indices[0]:\n",
        "            hits += 1\n",
        "            # Find the position (rank) of the ID\n",
        "            rank = np.where(retrieved_indices[0] == item['expected_faiss_id'])[0][0] + 1\n",
        "            current_rr = 1.0 / rank\n",
        "\n",
        "        reciprocal_ranks.append(current_rr)\n",
        "        print(f\"Q: {item['question'][:40]}... | Rank: {rank if current_rr > 0 else 'Miss'}\")\n",
        "\n",
        "    # 3. Final Metrics\n",
        "    hit_rate = (hits / len(test_set)) * 100\n",
        "    mrr = sum(reciprocal_ranks) / len(test_set)\n",
        "\n",
        "    print(f\"\\n--- RESULTS ---\")\n",
        "    print(f\"üéØ Hit Rate @{k}: {hit_rate:.2f}%\")\n",
        "    print(f\"üìä Mean Reciprocal Rank (MRR): {mrr:.3f}\")\n",
        "\n",
        "    return hit_rate, mrr\n",
        "\n",
        "# CALL the function to see the output\n",
        "run_advanced_evaluation(test_set, \"um6p_faiss_index.bin\", chunk_metadata, k=7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElXNiOtjjWsZ",
        "outputId": "ddde6688-cc9a-4620-d801-c7bdcffe51fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Advanced Evaluation (k=7) ---\n",
            "Q: ** According to the provided grading sch... | Rank: 1\n",
            "Q: What do students refer to University Moh... | Rank: 1\n",
            "Q: Why should I discuss with your fellows?... | Rank: 1\n",
            "Q: What is the mission of the Medical and P... | Rank: 4\n",
            "Q: <q>What are the prerequisites for passin... | Rank: 1\n",
            "\n",
            "--- RESULTS ---\n",
            "üéØ Hit Rate @7: 100.00%\n",
            "üìä Mean Reciprocal Rank (MRR): 0.850\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100.0, np.float64(0.85))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_generation(test_set, index, metadata):\n",
        "    results = []\n",
        "    print(f\"Generating and Judging {len(test_set)} answers...\")\n",
        "\n",
        "    for i, item in enumerate(test_set):\n",
        "        # 1. Retrieval\n",
        "        query_vec = eval_embedder.encode([item['question']]).astype('float32')\n",
        "        _, indices = index.search(query_vec, k=3)\n",
        "        retrieved_context = \"\\n\".join([metadata[idx]['content'] for idx in indices[0]])\n",
        "\n",
        "        # 2. Gemini RAG Answer\n",
        "        rag_prompt = f\"Context:\\n{retrieved_context}\\n\\nQuestion: {item['question']}\\nAnswer:\"\n",
        "        try:\n",
        "            response = model.generate_content(rag_prompt)\n",
        "            actual_answer = response.text if response.text else \"EMPTY RESPONSE\"\n",
        "        except Exception as e:\n",
        "            actual_answer = f\"ERROR: {e}\"\n",
        "\n",
        "        # 3. LLM-as-a-Judge\n",
        "        judge_prompt = f\"Rate 1-5 how well this answer matches the Ground Truth.\\nQ: {item['question']}\\nTruth: {item['ground_truth']}\\nActual: {actual_answer}\\nOutput ONLY a number.\"\n",
        "\n",
        "        try:\n",
        "            score_text = model.generate_content(judge_prompt).text\n",
        "            score = int(''.join(filter(str.isdigit, score_text))) # Extract only digits\n",
        "            results.append(score)\n",
        "            print(f\"[{i+1}/{len(test_set)}] Scored: {score}/5\")\n",
        "        except:\n",
        "            print(f\"[{i+1}/{len(test_set)}] Judge failed to parse score.\")\n",
        "\n",
        "        # Respect API Rate Limits\n",
        "        time.sleep(15)\n",
        "\n",
        "    if results:\n",
        "        avg_score = sum(results) / len(results)\n",
        "        print(f\"\\n‚úÖ FINAL GENERATION SCORE: {avg_score:.2f} / 5\")\n",
        "    else:\n",
        "        print(\"‚ùå No scores were collected.\")"
      ],
      "metadata": {
        "id": "b9vm-SThnOyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CALL the function here\n",
        "evaluate_generation(test_set, index, chunk_metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "JWr4rYfunR-q",
        "outputId": "1f0ad25f-a901-4311-ce34-be2099a61459",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating and Judging 5 answers...\n",
            "[1/5] Scored: 5/5\n",
            "[2/5] Scored: 5/5\n",
            "[3/5] Scored: 4/5\n",
            "[4/5] Scored: 2/5\n",
            "[5/5] Scored: 5/5\n",
            "\n",
            "‚úÖ FINAL GENERATION SCORE: 4.20 / 5\n"
          ]
        }
      ]
    }
  ]
}